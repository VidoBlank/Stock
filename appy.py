

import tushare as ts
from config import Config as AppConfig
import pandas as pd
import json
import os
import requests
import gradio as gr
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from pandas.tseries.holiday import get_calendar
import logging
from functools import lru_cache
import numpy as np
import concurrent.futures
from typing import List, Tuple, Dict, Optional
from typing import Optional, Tuple, Dict, Any
import time
import threading
from tqdm import tqdm
import concurrent.futures
import traceback
import sys
import appy
from collections import defaultdict
from typing import Set  # æ·»åŠ åˆ°æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥éƒ¨åˆ†
sys.stdout.reconfigure(encoding='utf-8')
import io
import functools  # æ·»åŠ æ­¤è¡Œ

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

from fetch_a_shares_data import API_CONFIG


# å¼ºåˆ¶ stdout/stderr ä½¿ç”¨ UTF-8
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# æ–°å¢é…ç½®é¡¹
IS_BACKTEST = False  # é»˜è®¤éå›æµ‹æ¨¡å¼
CURRENT_TRADE_DATE = None  # å›æµ‹æ—¶è®¾ç½®å½“å‰æ—¥æœŸ


# ===== å…¨å±€å®šä¹‰ =====

STRATEGY_GROUPS = {
    # ===== æ ¸å¿ƒè¶‹åŠ¿ç­–ç•¥ =====
    "è¶‹åŠ¿å‹": [
        "å‡çº¿çªç ´ï¼ˆ5/20/30æ—¥ï¼‰",  
        "å‡çº¿å¤šå¤´æ’åˆ—", 
        "MACDé›¶è½´å…±æŒ¯",          
        "è¶‹åŠ¿çªç ´ç¡®è®¤",         
        "KDJåŒå‘ä¸Šæ¶¨"            
    ],
    
    # ===== é‡ä»·åŠ¨èƒ½ç­–ç•¥ =====
    "åŠ¨é‡å‹": [
        "é‡ä»·é½å‡",              
        "ä¸»åŠ›èµ„é‡‘å…±æŒ¯",          
        "OBVåŠ¨é‡å¼•æ“",           
        "KDJé‡‘å‰",               
        "çŸ­æœŸçªç ´"               
    ],
    
    # ===== åº•éƒ¨åè½¬ç­–ç•¥ =====
    "åè½¬å‹": [
        "è¶…è·Œåå¼¹ï¼ˆRSI+BOLLï¼‰",  
        "åº•éƒ¨åè½¬ç¡®è®¤",          
        "MACDåº•èƒŒç¦»",            
        "KDJè¶…å–åè½¬"            
    ],
    
    # ===== å¯¹å†²ç­–ç•¥ =====
    "å¸‚åœºä¸­æ€§å‹": [
        #"è¡Œä¸šè¶…é¢æ”¶ç›Šï¼ˆRSæ”¹è¿›ç‰ˆï¼‰", 
        #"æ³¢åŠ¨ç‡å¥—åˆ©",
        #"é‡ä»·èƒŒç¦»"
    ],
    
    # ===== é£é™©æ§åˆ¶ =====
    "é£é™©å‹": [
     "è¶‹åŠ¿ç ´ä½ï¼ˆMA60+MACDæ­»å‰ï¼‰", 
     "é«˜ä½æ»æ¶¨é£é™©",
     "MACDé¡¶èƒŒç¦»"
    ],
    
    # ===== æ–°å¢: ç©¿çº¿å‹ç­–ç•¥ =====
    "ç©¿çº¿å‹": [
        "ä¸€é˜³ç©¿ä¸‰çº¿",
        "æ—­æ—¥ä¸œå‡",
        "æ¶¨åœå›è¸©",
        "å¼ºåŠ¿å›è¸©",
        "é«˜å°è·³æ°´ä¼ç¨³",    
        "åº•éƒ¨ç›˜æ•´çªç ´",    
        "é‡ä»·èƒŒç¦»çªç ´"     
    ]
}


# ===== ç­–ç•¥æƒé‡å®šä¹‰ =====
STRATEGY_WEIGHTS = {
    # === è¶‹åŠ¿å‹ ===
    "å‡çº¿çªç ´ï¼ˆ5/20/30æ—¥ï¼‰": 15,
    "å‡çº¿å¤šå¤´æ’åˆ—": 15,
    "MACDé›¶è½´å…±æŒ¯": 18,
    "è¶‹åŠ¿çªç ´ç¡®è®¤": 23,
    "KDJåŒå‘ä¸Šæ¶¨": 18,

    # === åŠ¨é‡å‹ ===
    "é‡ä»·é½å‡": 18,
    "ä¸»åŠ›èµ„é‡‘å…±æŒ¯": 18,
    "OBVåŠ¨é‡å¼•æ“": 18,
    "KDJé‡‘å‰": 15,
    "çŸ­æœŸçªç ´": 21,

    # === åè½¬å‹ ===
    "è¶…è·Œåå¼¹ï¼ˆRSI+BOLLï¼‰": 18,
    "åº•éƒ¨åè½¬ç¡®è®¤": 21,
    "MACDåº•èƒŒç¦»": 21,
    "KDJè¶…å–åè½¬": 18,

    # === é£é™©å‹ ===
    "è¶‹åŠ¿ç ´ä½ï¼ˆMA60+MACDæ­»å‰ï¼‰": -30,
    "é«˜ä½æ»æ¶¨é£é™©": -25,
    "MACDé¡¶èƒŒç¦»": -30,

    # === ç©¿çº¿å‹ ===
    "ä¸€é˜³ç©¿ä¸‰çº¿": 23,
    "æ—­æ—¥ä¸œå‡": 27,
    "æ¶¨åœå›è¸©": 30,
    "å¼ºåŠ¿å›è¸©": 24,
    "é«˜å°è·³æ°´ä¼ç¨³": 25,     
    "åº•éƒ¨ç›˜æ•´çªç ´": 22,     
    "é‡ä»·èƒŒç¦»çªç ´": 26      
}




# ===== æ¿å—/å¸‚åœºæ˜ å°„ =====
MARKET_SECTORS = {
    "ä¸»æ¿": ["ä¸»æ¿"],
    "åˆ›ä¸šæ¿": ["åˆ›ä¸šæ¿"],
    "ç§‘åˆ›æ¿": ["ç§‘åˆ›æ¿"],
    "ä¸­è¯ç™½é…’": [],
    "ä¸­è¯æ¶ˆè´¹": [],
    "å›½è¯ETF": [],
    "ä¸­è¯500": [],
    "æ·±è¯100": [],
    "åŒ—è¯50": [],
    "ç§‘åˆ›50": [],
    "æ²ªæ·±300": [],
    "ä¸Šè¯50": []
}

STRATEGY_TYPE_WEIGHTS = {
    "è¶‹åŠ¿å‹": 1.0,  
    "åŠ¨é‡å‹": 1.0,
    "åè½¬å‹": 1.0,   
    "é£é™©å‹": -1.0,  
    "å¸‚åœºä¸­æ€§å‹": 1.0,
    "ç©¿çº¿å‹": 1.0
}









# =====å„ä¸ªå¯ç”¨æ¥å£åŠå…¶è°ƒç”¨æ–¹æ³• =====
from typing import List
from datetime import datetime, timedelta

# Helperï¼šå¯¹å•ä¸ªæ¥å£çš„æ—¥æœŸå‚æ•°åšå›é€€å°è¯•ï¼Œç›´åˆ°æ‹¿åˆ°éç©ºç»“æœæˆ–ç”¨å°½å¤©æ•°
def _fetch_with_fallback(
    api_func,
    date_field: str,
    base_date: datetime,
    max_back_days: int,
    extra_params: dict
) -> pd.DataFrame:
    for delta in range(max_back_days + 1):
        d = (base_date - timedelta(days=delta)).strftime('%Y%m%d')
        params = extra_params.copy()
        params[date_field] = d
        df = safe_api_call(api_func, **params)
        if not df.empty:
            return df
    return pd.DataFrame()
# ã€è¡Œä¸š&æ¦‚å¿µã€‘åˆå§‹åŒ–æ‰¹é‡ç¼“å­˜
def initialize_industry_and_concept(ts_codes: List[str]):
    global industry_cache, concept_cache
    logger.info("ğŸš€ åˆå§‹åŒ–è¡Œä¸šä¸æ¦‚å¿µç¼“å­˜...")

    # 1. å…¨é‡è·å–è¡Œä¸šä¿¡æ¯ï¼ˆä¸éœ€è¦å›é€€ï¼‰
    try:
        info_df = safe_api_call(
            pro.stock_basic,
            exchange='',
            list_status='L',
            fields='ts_code,industry'
        )
        if not info_df.empty:
            industry_cache.update(
                dict(zip(
                    info_df['ts_code'],
                    info_df['industry'].fillna('æœªçŸ¥è¡Œä¸š')
                ))
            )
            logger.info(f"âœ… è¡Œä¸šä¿¡æ¯ç¼“å­˜å®Œæˆï¼Œå…± {len(industry_cache)} æ¡")
        else:
            logger.warning("âš ï¸ è¡Œä¸šä¿¡æ¯ä¸ºç©º")
    except Exception as e:
        logger.warning(f"è¡Œä¸šæ‰¹é‡è·å–å¤±è´¥: {e}")

    # 2. æ¦‚å¿µæ‰¹é‡ç¼“å­˜ï¼šåˆ†æ‰¹ï¼ˆ200/æ‰¹ï¼‰æŸ¥è¯¢ï¼Œé¿å…å•æ¬¡ä¼ å‚è¿‡é•¿å¯¼è‡´æ¥å£è¿”å›ç©º
    batch_size = 200
    for i in range(0, len(ts_codes), batch_size):
        batch = ts_codes[i : i + batch_size]
        ts_str = ",".join(batch)
        try:
            df = safe_api_call(
                pro.concept_detail,
                ts_code=ts_str,
                fields='ts_code,concept_name'
            )
            if not df.empty:
                grouped = df.groupby('ts_code')['concept_name'].apply(list)
                concept_cache.update(grouped.to_dict())
        except Exception as e:
            logger.warning(f"æ¦‚å¿µæ‰¹é‡è·å–å¤±è´¥ï¼ˆæ‰¹æ¬¡ {i // batch_size + 1}ï¼‰: {e}")

    logger.info(f"âœ… æ¦‚å¿µä¿¡æ¯ç¼“å­˜å®Œæˆï¼Œè¦†ç›–è‚¡ç¥¨æ•°ï¼š{len(concept_cache)}")
        
# ã€å¸‚å€¼æ‰“åˆ†ã€‘å°å¸‚å€¼åŠ åˆ†ï¼Œå¤§å¸‚å€¼æ‰£åˆ†        
def apply_market_cap_penalty(ts_code: str, score: float) -> float:
    try:
        df = safe_api_call(pro.daily_basic, ts_code=ts_code, trade_date=datetime.today().strftime('%Y%m%d'), fields='ts_code,total_mv')
        if df.empty:
            return score
        market_cap = df.iloc[0]['total_mv'] / 10000  # æ¢ç®—ä¸ºäº¿å…ƒ

        if market_cap < 30:
            logger.debug(f"{ts_code} å°å¸‚å€¼ï¼ˆ{market_cap:.1f}äº¿ï¼‰ï¼ŒåŠ 5åˆ†")
            return score + 5
        elif market_cap > 1000:
            penalty = min(10, (market_cap - 1000) * 0.01)
            logger.debug(f"{ts_code} è¶…å¤§å¸‚å€¼ï¼ˆ{market_cap:.1f}äº¿ï¼‰ï¼Œæ‰£{penalty:.1f}åˆ†")
            return score - penalty
        return score
    except Exception as e:
        logger.warning(f"{ts_code} å¸‚å€¼æ‰£åˆ†å¤±è´¥: {str(e)}")
        return score
  
    


# ã€è´¢åŠ¡è¯„åˆ†ã€‘æ ¹æ®ROEã€æ¯›åˆ©ç‡ã€è´Ÿå€ºç‡ç­‰æ‰“åˆ†    
def evaluate_financials(ts_code: str) -> float:
    try:
        # è·å–å½“å‰å¹´ä»½çš„æœ€åä¸€å¤©ï¼ˆ12æœˆ31æ—¥ï¼‰
        current_year = datetime.today().year
        period = f"{current_year - 1}1231"  # ä½¿ç”¨å»å¹´çš„12æœˆ31æ—¥ä½œä¸ºæŠ¥å‘ŠæœŸ

        # ä½¿ç”¨ fina_indicator_vip è·å–è´¢åŠ¡æ•°æ®
        df = safe_api_call(pro.fina_indicator_vip, 
                           ts_code=ts_code, 
                           start_date='20230101',  # è®¾ç½®èµ·å§‹æ—¥æœŸä¸º2023å¹´1æœˆ1æ—¥
                           end_date=datetime.today().strftime('%Y%m%d'),  # æˆªæ­¢åˆ°ä»Šå¤©
                           period=period, 
                           fields='roe,roe_dt,grossprofit_margin,netprofit_yoy,debt_to_assets')
        
        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè®°å½•å¹¶è¿”å› 0
        if df.empty:
            logger.warning(f"{ts_code} æœªè·å–åˆ°è´¢åŠ¡æ•°æ®")
            return 0
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ŒæŸ¥çœ‹è¿”å›çš„æ•°æ®å†…å®¹
        logger.debug(f"{ts_code} è·å–åˆ°çš„è´¢åŠ¡æ•°æ®: {df.head()}")
        
        data = df.iloc[0]  # è·å–ç¬¬ä¸€æ¡æ•°æ®
        score = 0

        # ç¡®ä¿è´¢åŠ¡æ•°æ®ä¸ºæœ‰æ•ˆæ•°å­—ï¼Œå¦åˆ™è®¾ä¸º 0
        roe = data['roe'] if isinstance(data['roe'], (int, float)) else 0
        grossprofit_margin = data['grossprofit_margin'] if isinstance(data['grossprofit_margin'], (int, float)) else 0
        netprofit_yoy = data['netprofit_yoy'] if isinstance(data['netprofit_yoy'], (int, float)) else 0
        debt_to_assets = data['debt_to_assets'] if isinstance(data['debt_to_assets'], (int, float)) else 0

        # æ‰“åˆ†é€»è¾‘
        if roe > 25:
            score += 10  
        elif roe > 20:
            score += 7
        elif roe > 15:
            score += 5
        elif roe > 12:
            score += 3

        if grossprofit_margin > 40:
            score += 7  
        elif grossprofit_margin > 30:
            score += 5
        elif grossprofit_margin > 20:
            score += 3

        if netprofit_yoy > 30:
            score += 7  
        elif netprofit_yoy > 20:
            score += 5
        elif netprofit_yoy > 10:
            score += 3
        elif netprofit_yoy > 0:
            score += 2
        else:
            score -= 10  # è´Ÿå¢é•¿

        if debt_to_assets < 30:
            score += 5  
        elif debt_to_assets < 40:
            score += 3
        elif debt_to_assets > 70:
            score -= 10
        
        # æ–°å¢è·å–ç°é‡‘æµé‡æ•°æ®
        cash_flow = safe_api_call(pro.cashflow_vip, ts_code=ts_code, 
                                  fields="n_cashflow_act, free_cashflow")  # æ›¿æ¢å­—æ®µ
        
        # æ–°å¢ç›ˆåˆ©èƒ½åŠ›è´¨é‡è¯„åˆ†
        profit_quality = 0
        if not cash_flow.empty:
            if cash_flow['n_cashflow_act'].iloc[-1] > 1.2:  # ä½¿ç”¨ n_cashflow_act æ›¿ä»£ ocf_to_operate_income
                profit_quality += 8
            if cash_flow['free_cashflow'].iloc[-1] > 0:
                profit_quality += 6
                
        # æ–°å¢ä¼°å€¼æŒ‡æ ‡
        valuation = safe_api_call(pro.daily_basic, ts_code=ts_code,
                                  fields="pe_ttm,pb")
        val_score = 0
        if not valuation.empty:
            if valuation['pe_ttm'].iloc[-1] < 15:
                val_score += 5
            if valuation['pb'].iloc[-1] < 1.5:
                val_score += 5
        
        # å°†è´¢åŠ¡å¾—åˆ†ä¸æ–°å¢çš„ç›ˆåˆ©èƒ½åŠ›è´¨é‡å’Œä¼°å€¼æŒ‡æ ‡å¾—åˆ†åˆå¹¶
        total_score = score + profit_quality + val_score
        logger.debug(f"{ts_code} è´¢åŠ¡å¥åº·å¾—åˆ†: {total_score}")
        
        return total_score

    except Exception as e:
        logger.debug(f"{ts_code} è´¢åŠ¡æŒ‡æ ‡è·å–å¤±è´¥: {str(e)}")
        return 0






def initialize_top_inst():
    """åˆå§‹åŒ–é¾™è™æ¦œæœºæ„å¸­ä½æ•°æ®ï¼Œè·å–æœ€è¿‘å‡ ä¸ªäº¤æ˜“æ—¥ä¸Šæ¦œçš„è‚¡ç¥¨"""
    global top_inst_cache
    logger.info("ğŸš¨ åˆå§‹åŒ–é¾™è™æ¦œæœºæ„å¸­ä½æ•°æ®...")
    
    # åˆå§‹åŒ–ç¼“å­˜ï¼Œç¡®ä¿æ˜¯ç©ºé›†åˆ
    top_inst_cache = set()
    
    # è·å–æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥çš„æ—¥æœŸ
    today = datetime.today()
    date_list = []
    
    # è·å–æœ€è¿‘10ä¸ªè‡ªç„¶æ—¥ï¼Œé€šå¸¸åŒ…å«5ä¸ªäº¤æ˜“æ—¥
    for i in range(10):
        check_date = today - timedelta(days=i)
        # æ’é™¤å‘¨æœ«
        if check_date.weekday() < 5:  # 0-4 è¡¨ç¤ºå‘¨ä¸€è‡³å‘¨äº”
            date_list.append(check_date.strftime('%Y%m%d'))
        if len(date_list) >= 5:
            break
    
    logger.info(f"æŸ¥è¯¢æœ€è¿‘äº¤æ˜“æ—¥é¾™è™æ¦œæ•°æ®: {date_list}")
    
    # æŸ¥è¯¢æ¯ä¸€å¤©çš„é¾™è™æ¦œæ•°æ®
    for trade_date in date_list:
        try:
            # æ ¹æ®æ–‡æ¡£ï¼Œtop_inst æ¥å£éœ€è¦ trade_date å‚æ•°
            df = safe_api_call(pro.top_inst, trade_date=trade_date)
            
            if df is not None and not df.empty and 'ts_code' in df.columns:
                # è·å–è¯¥æ—¥ä¸Šæ¦œçš„è‚¡ç¥¨ä»£ç 
                day_stocks = set(df['ts_code'].unique())
                top_inst_cache.update(day_stocks)  # åˆå¹¶åˆ°æ€»é›†åˆä¸­
                
                logger.info(f"âœ… {trade_date} é¾™è™æ¦œä¸Šæ¦œ {len(day_stocks)} æ”¯è‚¡ç¥¨")
                
                # å¦‚æœè¯¥æ—¥æœ‰æ•°æ®ï¼Œå¯ä»¥æå‰é€€å‡ºå¾ªç¯ï¼ˆå¯é€‰ï¼Œå¦‚æœæƒ³è·å–å¤šæ—¥æ•°æ®åˆ™æ³¨é‡Šæ­¤è¡Œï¼‰
                # break
            else:
                logger.warning(f"âš ï¸ {trade_date} é¾™è™æ¦œæ•°æ®ä¸ºç©ºæˆ–æ ¼å¼å¼‚å¸¸")
                
        except Exception as e:
            logger.warning(f"è·å– {trade_date} é¾™è™æ¦œæ•°æ®å¤±è´¥: {str(e)}")
    
    # æŸ¥è¯¢ç»“æœç»Ÿè®¡
    if top_inst_cache:
        logger.info(f"âœ… æœºæ„å¸­ä½æ•°æ®ç¼“å­˜å®Œæˆï¼šå…± {len(top_inst_cache)} æ”¯ä¸Šæ¦œè‚¡ç¥¨")
        # è¾“å‡ºå‰5æ”¯ä¸Šæ¦œè‚¡ç¥¨ç”¨äºè°ƒè¯•
        sample_stocks = list(top_inst_cache)[:5] if len(top_inst_cache) > 5 else list(top_inst_cache)
        logger.debug(f"ä¸Šæ¦œè‚¡ç¥¨ç¤ºä¾‹: {sample_stocks}")
    else:
        logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æœºæ„å¸­ä½æ•°æ®ï¼Œæ‰€æœ‰æ—¥æœŸæŸ¥è¯¢å‡ä¸ºç©º")
    
    # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰ï¼Œæ–¹ä¾¿è°ƒè¯•å’Œåˆ†æ
    try:
        cache_file = "top_inst_cache.json"
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(list(top_inst_cache), f, ensure_ascii=False, indent=2)
        logger.debug(f"ä¸Šæ¦œè‚¡ç¥¨æ¸…å•å·²ä¿å­˜è‡³ {cache_file}")
    except Exception as e:
        logger.debug(f"ä¿å­˜ä¸Šæ¦œè‚¡ç¥¨æ¸…å•å¤±è´¥: {e}")
        
# ã€é¾™è™æ¦œã€‘å‘½ä¸­æœºæ„å¸­ä½åŠ åˆ†
def check_top_inst(ts_code: str) -> float:
    return 10 if ts_code in top_inst_cache else 0

# ã€èµ„é‡‘æµå‘ã€‘è¿‘5æ—¥ä¸»åŠ›èµ„é‡‘å‡€æµå…¥å¾—åˆ†    
def initialize_moneyflow_scores(ts_codes: List[str]):
    global moneyflow_scores
    logger.info("ğŸš€ åˆå§‹åŒ–èµ„é‡‘æµå‘å¾—åˆ†ç¼“å­˜...")

    start_date = (datetime.today() - timedelta(days=5)).strftime('%Y%m%d')
    try:
        # ä¸ä¼  ts_codeï¼Œè·å–è¿‘5æ—¥å…¨å¸‚åœºæ•°æ®
        df = safe_api_call(pro.moneyflow, start_date=start_date)
        if df.empty:
            logger.warning("âš ï¸ èµ„é‡‘æµå‘æ•°æ®ä¸ºç©º")
            return

        # è¿‡æ»¤ç›®æ ‡è‚¡ç¥¨
        df = df[df['ts_code'].isin(ts_codes)]

        # åˆ†ç»„æ±‡æ€»
        grouped = df.groupby('ts_code')['net_mf_amount'].sum()

        # è®¡ç®—å¾—åˆ†
        raw_scores = {}  # ç”¨äºå­˜å‚¨åŸå§‹èµ„é‡‘é¢å¾—åˆ†
        for ts_code in ts_codes:
            net_inflow = grouped.get(ts_code, 0)
            if net_inflow > 0:
                bonus = min(5, net_inflow / 1000)
            else:
                bonus = max(-5, net_inflow / 1000)
            raw_scores[ts_code] = bonus  # å­˜å‚¨åŸå§‹å¾—åˆ†

        # æ ‡å‡†åŒ–å¾—åˆ†ï¼šmin-max æ ‡å‡†åŒ–
        min_score = min(raw_scores.values())
        max_score = max(raw_scores.values())

        # è®¾ç½®ç›®æ ‡å¾—åˆ†èŒƒå›´ [0, 10]
        target_min = 0
        target_max = 10

        # å¯¹æ¯åªè‚¡ç¥¨çš„èµ„é‡‘é¢å¾—åˆ†è¿›è¡Œæ ‡å‡†åŒ–
        for ts_code in ts_codes:
            raw_score = raw_scores[ts_code]
            # ä½¿ç”¨min-maxæ ‡å‡†åŒ–å…¬å¼å°†å¾—åˆ†æ˜ å°„åˆ°[0, 10]çš„èŒƒå›´
            normalized_score = (raw_score - min_score) / (max_score - min_score) * (target_max - target_min) + target_min
            
            # å°†æ ‡å‡†åŒ–åçš„å¾—åˆ†å››èˆäº”å…¥ä¸ºæ•´æ•°
            moneyflow_scores[ts_code] = round(normalized_score)  # å››èˆäº”å…¥ä¸ºæ•´æ•°
        
        logger.info(f"âœ… èµ„é‡‘æµå‘ç¼“å­˜å®Œæˆï¼Œè¦†ç›– {len(moneyflow_scores)} æ”¯è‚¡ç¥¨")
    except Exception as e:
        logger.warning(f"èµ„é‡‘æµå‘æ‰¹é‡è·å–å¤±è´¥: {str(e)}")

        
# ã€èµ„é‡‘æµå‘ã€‘è¿”å›å•ç¥¨èµ„é‡‘å¾—åˆ†        
def evaluate_moneyflow(ts_code: str) -> float:
    return moneyflow_scores.get(ts_code, 0)


# ã€æ¶¨è·Œåœã€‘æ‰¹é‡è·å–æ¶¨è·Œåœä»·æ ¼åŒºé—´
def initialize_stk_limit(ts_codes: List[str]):
    logger.info("ğŸš¨ åˆå§‹åŒ–æ¶¨è·Œåœä»·æ•°æ®...")
    try:
        df = safe_api_call(pro.stk_limit, trade_date=datetime.today().strftime('%Y%m%d'))
        if not df.empty:
            filtered = df[df['ts_code'].isin(ts_codes)]
            stk_limit_cache.update(filtered.set_index('ts_code')[['up_limit', 'down_limit']].to_dict('index'))
            logger.info(f"âœ… æ¶¨è·Œåœä»·ç¼“å­˜å®Œæˆï¼š{len(stk_limit_cache)} æ”¯è‚¡ç¥¨")
        else:
            logger.warning("âš ï¸ æ¶¨è·Œåœæ•°æ®ä¸ºç©º")
    except Exception as e:
        logger.warning(f"æ¶¨è·Œåœä»·è·å–å¤±è´¥: {str(e)}")

# ã€å¤§å®—äº¤æ˜“ã€‘ç»Ÿè®¡è¿‘30æ—¥æ´»è·ƒåº¦ï¼Œé€‚å½“åŠ åˆ†        
def initialize_block_trade(ts_codes: List[str]):
    logger.info("ğŸš¨ åˆå§‹åŒ–å¤§å®—äº¤æ˜“æ•°æ®...")
    try:
        start_date = (datetime.today() - timedelta(days=30)).strftime('%Y%m%d')
        df = safe_api_call(pro.block_trade, start_date=start_date)
        if not df.empty:
            filtered = df[df['ts_code'].isin(ts_codes)]
            grouped = filtered.groupby('ts_code').size()
            block_trade_cache.update(grouped.to_dict())
            logger.info(f"âœ… å¤§å®—äº¤æ˜“ç¼“å­˜å®Œæˆï¼š{len(block_trade_cache)} æ”¯è‚¡ç¥¨")
        else:
            logger.warning("âš ï¸ å¤§å®—äº¤æ˜“æ•°æ®ä¸ºç©º")
    except Exception as e:
        logger.warning(f"å¤§å®—äº¤æ˜“è·å–å¤±è´¥: {str(e)}")


def save_to_local_cache(data, filename):
    """å°†æ•°æ®ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜æ–‡ä»¶"""
    with open(filename, 'w') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def load_from_local_cache(filename):
    """ä»æœ¬åœ°ç¼“å­˜æ–‡ä»¶åŠ è½½æ•°æ®"""
    if os.path.exists(filename):
        with open(filename, 'r') as f:
            return json.load(f)
    return None

def fetch_stock_data(ts_code, trade_date_str, retries=3, timeout=30):
    """è·å–æ¯ä¸ªæ¦‚å¿µæ¿å—çš„æ•°æ®ï¼Œå¹¶å¤„ç†è¶…æ—¶"""
    for attempt in range(retries):
        try:
            stock_data = StockAnalyzer.pro.daily(ts_code=ts_code, trade_date=trade_date_str, fields='ts_code,close', timeout=timeout)
            if not stock_data.empty:
                return stock_data.to_dict(orient='records')
            else:
                logger.warning(f"è·å– {ts_code} çš„æ•°æ®ä¸ºç©º")
                return None
        except Exception as e:
            logger.warning(f"è·å– {ts_code} çš„æ•°æ®æ—¶å‡ºé”™: {e}")
            if attempt < retries - 1:
                logger.info(f"é‡è¯• {ts_code} (å°è¯• {attempt + 1} æ¬¡)")
                time.sleep(1)
    return None

def get_concept_trends(trade_date: str):
    """
    è·å–åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æ•°æ®å¹¶è®¡ç®—æ¯ä¸ªæ¦‚å¿µæ¿å—çš„è¶‹åŠ¿ã€‚
    """
    if IS_BACKTEST:  # å¦‚æœæ˜¯å›æµ‹æ¨¡å¼ï¼Œè·³è¿‡è·å–åŒèŠ±é¡ºæ¦‚å¿µæ•°æ®
        logger.info("å›æµ‹æ¨¡å¼ä¸‹ï¼Œè·³è¿‡è·å–åŒèŠ±é¡ºæ¦‚å¿µæ•°æ®")
        return pd.DataFrame()  # è¿”å›ä¸€ä¸ªç©ºçš„DataFrame

    cache_filename = f'concept_data_{trade_date}.json'  # ä½¿ç”¨æ—¥æœŸä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†æ¥åŒºåˆ†ä¸åŒçš„ç¼“å­˜

    # å°è¯•ä»æœ¬åœ°ç¼“å­˜åŠ è½½æ•°æ®
    cached_data = load_from_local_cache(cache_filename)
    if cached_data:
        logger.info(f"åŠ è½½æœ¬åœ°ç¼“å­˜æ•°æ®ï¼Œå…±{len(cached_data)}ä¸ªæ¦‚å¿µæ¿å—")
        return cached_data

    try:
        # å°† trade_date è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        trade_date_str = trade_date.strftime('%Y%m%d') if isinstance(trade_date, datetime) else trade_date

        # è·å–æ‰€æœ‰æ¦‚å¿µæ¿å—æ•°æ®ï¼ˆä¸€æ¬¡æ€§è·å–ï¼Œå°½é‡é¿å…åˆ†é¡µï¼‰
        df = StockAnalyzer.pro.ths_index(type='N')  # è·å–æ¦‚å¿µæŒ‡æ•°ï¼Œtype='N'è¡¨ç¤ºæ¦‚å¿µæŒ‡æ•°

        if df is not None and not df.empty:
            df = df[['ts_code', 'name', 'count']]  # åªæå–è‚¡ç¥¨ä»£ç ã€æ¿å—åç§°å’Œæˆåˆ†è‚¡æ•°
            logger.info(f"è·å–åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æ•°æ®æˆåŠŸï¼Œå…±{len(df)}ä¸ªæ¿å—")

            # å°†æ‰€æœ‰æ¦‚å¿µæ¿å—çš„æ¶¨å¹…æ•°æ®ä¸€æ¬¡æ€§è·å–
            concept_data = []

            # ä½¿ç”¨å¹¶å‘å¤„ç†è·å–æ¯ä¸ªæ¿å—çš„æ¶¨å¹…æ•°æ®
            def fetch_stock_data_for_row(row):
                """å°è£… row è·å–æ•°æ®çš„é€»è¾‘"""
                ts_code = row['ts_code']
                result = fetch_stock_data(ts_code, trade_date_str)
                return result

            with concurrent.futures.ThreadPoolExecutor() as executor:
                future_to_ts_code = {executor.submit(fetch_stock_data_for_row, row): row for _, row in df.iterrows()}

                # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
                for future in tqdm(concurrent.futures.as_completed(future_to_ts_code), total=len(future_to_ts_code), desc="è·å–æ¦‚å¿µæ¿å—æ¶¨å¹…æ•°æ®"):
                    result = future.result()
                    if result:
                        concept_data.append(result)

            logger.info(f"æˆåŠŸè·å– {len(concept_data)} ä¸ªæ¦‚å¿µæ¿å—çš„æ¶¨å¹…æ•°æ®")

            # ç¼“å­˜æ•°æ®åˆ°æœ¬åœ°
            save_to_local_cache(concept_data, cache_filename)

            # è½¬æ¢ä¸º DataFrame
            concept_data_df = pd.DataFrame(concept_data)
            return concept_data_df
        else:
            logger.warning("æ— æ³•è·å–åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æ•°æ®")
    except Exception as e:
        logger.error(f"è·å–åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æ•°æ®å‡ºé”™: {str(e)}")
    return pd.DataFrame()

def calculate_concept_trend_score(concept_data: pd.DataFrame, trade_date: str):
    """
    æ ¹æ®æ¦‚å¿µæ¿å—çš„æ•°æ®ï¼Œè®¡ç®—æ¯ä¸ªæ¦‚å¿µçš„è¶‹åŠ¿è¯„åˆ†ã€‚
    """
    total_pct_change = 0
    valid_count = 0

    # ç¡®ä¿ concept_data æ˜¯ DataFrame æ ¼å¼
    if isinstance(concept_data, list):
        concept_data = pd.DataFrame(concept_data)

    trade_date_str = trade_date.strftime('%Y%m%d') if isinstance(trade_date, datetime) else trade_date

    for index, row in tqdm(concept_data.iterrows(), total=len(concept_data), desc="è®¡ç®—æ¦‚å¿µæ¿å—è¶‹åŠ¿å¾—åˆ†"):
        concept_ts_code = row['ts_code']
        concept_name = row['name']
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„è¶‹åŠ¿è¯„åˆ†
        cached_score = load_trend_score_from_cache(concept_name)
        if cached_score:
            logger.info(f"åŠ è½½ç¼“å­˜çš„è¶‹åŠ¿è¯„åˆ†ï¼š{concept_name} - {cached_score['trend_score']}")
            total_pct_change += cached_score['trend_score']
            valid_count += 1
            continue
        
        # è·å–æ¿å—ä¸­æ¯åªè‚¡ç¥¨çš„æ¶¨å¹…
        try:
            stock_data = StockAnalyzer.pro.daily(ts_code=concept_ts_code, trade_date=trade_date_str, fields='ts_code,close')
            if not stock_data.empty:
                pct_change = stock_data['pct_chg'].mean()  # è®¡ç®—å¹³å‡æ¶¨å¹…
                total_pct_change += pct_change
                valid_count += 1
                # ç¼“å­˜è®¡ç®—çš„è¶‹åŠ¿è¯„åˆ†
                save_trend_score_to_cache(concept_name, pct_change)
        except Exception as e:
            logger.warning(f"è·å– {concept_name} æ¿å—çš„æ¶¨å¹…æ•°æ®å‡ºé”™: {str(e)}")

    # è¿”å›è®¡ç®—åçš„è¶‹åŠ¿è¯„åˆ†
    if valid_count > 0:
        avg_pct_change = total_pct_change / valid_count
        logger.info(f"æ¦‚å¿µæ¿å—å¹³å‡æ¶¨å¹…: {avg_pct_change:.2f}%")
        return avg_pct_change
    return 0.0


def save_trend_score_to_cache(concept_name, trend_score):
    """ä¿å­˜è¶‹åŠ¿è¯„åˆ†åˆ°ç¼“å­˜"""
    filename = f'trend_score_{concept_name}.json'
    data = {'concept_name': concept_name, 'trend_score': trend_score}
    save_to_local_cache(data, filename)

def load_trend_score_from_cache(concept_name):
    """åŠ è½½ç¼“å­˜çš„è¶‹åŠ¿è¯„åˆ†"""
    filename = f'trend_score_{concept_name}.json'
    return load_from_local_cache(filename)






SECTOR_SCORE_CACHE = "sector_scores_cache.json"
CONCEPT_STOCK_MAP_FILE = "concept_to_stock_map.json"
CONCEPT_NAME_TO_CODE_FILE = "concept_name_to_code.json"

# === è·å–æ¦‚å¿µæ¿å—çƒ­åº¦è¯„åˆ† ===
def get_sector_strength_scores(trade_date: str) -> Dict[str, float]:
    """æ ¹æ®é€šè¾¾ä¿¡æ¿å—æ•°æ®æ‰“åˆ†æ¯ä¸ªæ¦‚å¿µæ¿å—"""
        # å›æµ‹æ¨¡å¼ä¸‹ï¼Œè·³è¿‡æ¿å—è¯„åˆ†
    if IS_BACKTEST:
        logger.info(f"ğŸ”™ å›æµ‹æ¨¡å¼ï¼šè·³è¿‡é€šè¾¾ä¿¡æ¿å—è¯„åˆ†")
        return {}
    logger.info(f"ğŸ” å¼€å§‹è·å– {trade_date} çš„æ¿å—æ•°æ®...")
    
    try:
        # ä½¿ç”¨ safe_api_call ç¡®ä¿ä¸€è‡´çš„é”™è¯¯å¤„ç†
        df = safe_api_call(
            pro.tdx_daily,
            trade_date=trade_date,
            fields="ts_code,3day,5day,bm_buy_ratio,turnover_rate,idx_type"
        )
        
        if df.empty:
            logger.warning(f"âš ï¸ {trade_date} æ— æ¿å—æ•°æ®è¿”å›")
            return {}
            
        logger.info(f"ğŸ“Š åŸå§‹æ¿å—æ•°æ®æ•°é‡: {len(df)}")
        
        # æ£€æŸ¥è¿”å›çš„å­—æ®µ
        logger.info(f"ğŸ“Š è¿”å›çš„å­—æ®µ: {df.columns.tolist()}")
        
        # æ£€æŸ¥idx_typeå­—æ®µæ˜¯å¦å­˜åœ¨
        if 'idx_type' not in df.columns:
            logger.error(f"âŒ è¿”å›æ•°æ®ç¼ºå°‘ idx_type å­—æ®µï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
            # å°è¯•è·å–æ‰€æœ‰é€šè¾¾ä¿¡æ¦‚å¿µæ¿å—ä»£ç ï¼ˆä»¥880å¼€å¤´çš„ä»£ç ï¼‰
            df_filtered = df[df['ts_code'].str.startswith('880')]
            logger.info(f"ğŸ“Š ä½¿ç”¨ä»£ç å‰ç¼€ç­›é€‰ï¼Œæ‰¾åˆ° {len(df_filtered)} ä¸ªæ¿å—")
        else:
            logger.info(f"ğŸ“Š åŒ…å«çš„æ¿å—ç±»å‹: {df['idx_type'].unique()}")
            # ç­›é€‰æ¦‚å¿µæ¿å—
            df_filtered = df[df['idx_type'] == 'æ¦‚å¿µæ¿å—']
            logger.info(f"ğŸ“Š ç­›é€‰åæ¦‚å¿µæ¿å—æ•°é‡: {len(df_filtered)}")
        
        if df_filtered.empty:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ¦‚å¿µæ¿å—æ•°æ®")
            return {}
            
    except Exception as e:
        logger.error(f"âŒ æ¿å—è¯„åˆ†è·å–å¤±è´¥ï¼š{e}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {type(e).__name__}: {str(e)}")
        import traceback
        logger.error(f"å †æ ˆä¿¡æ¯:\n{traceback.format_exc()}")
        return {}
    
    scores = {}
    for _, row in df_filtered.iterrows():
        try:
            # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
            required_fields = ['3day', '5day', 'bm_buy_ratio', 'turnover_rate']
            missing_fields = [f for f in required_fields if f not in row or pd.isna(row[f])]
            
            if missing_fields:
                logger.warning(f"âš ï¸ æ¿å— {row['ts_code']} ç¼ºå°‘å­—æ®µ: {missing_fields}")
                continue
            
            score = (
                row['3day'] * 0.2 +
                row['5day'] * 0.3 +
                row['bm_buy_ratio'] * 0.3 +
                row['turnover_rate'] * 0.2
            )
            scores[row['ts_code']] = round(score, 2)
        except Exception as e:
            logger.warning(f"âš ï¸ è®¡ç®—æ¿å— {row['ts_code']} è¯„åˆ†å¤±è´¥: {e}")
            continue
    
    logger.info(f"âœ… æˆåŠŸè®¡ç®— {len(scores)} ä¸ªæ¿å—çš„è¯„åˆ†")
    if scores:
        # æ‰“å°è¯„åˆ†æœ€é«˜çš„5ä¸ªæ¿å—
        top_5 = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:5]
        logger.info(f"ğŸ† è¯„åˆ†TOP5æ¿å—: {top_5}")
    
    # å¯é€‰ï¼šå†™å…¥ç¼“å­˜
    try:
        with open(SECTOR_SCORE_CACHE, 'w', encoding='utf-8') as f:
            json.dump(scores, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ æ¿å—è¯„åˆ†å·²ç¼“å­˜åˆ° {SECTOR_SCORE_CACHE}")
    except Exception as e:
        logger.warning(f"âš ï¸ æ¿å—è¯„åˆ†ç¼“å­˜å¤±è´¥: {e}")
    
    return scores

# === è‚¡ç¥¨æ‰€å±æ¦‚å¿µæ˜ å°„è¡¨ ===
def load_concept_to_stock_map() -> Dict[str, List[str]]:
    logger.info(f"ğŸ“š å¼€å§‹åŠ è½½æ¦‚å¿µè‚¡ç¥¨æ˜ å°„æ–‡ä»¶: {CONCEPT_STOCK_MAP_FILE}")
    
    if os.path.exists(CONCEPT_STOCK_MAP_FILE):
        try:
            with open(CONCEPT_STOCK_MAP_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(data)} ä¸ªæ¦‚å¿µçš„è‚¡ç¥¨æ˜ å°„")
            
            # æ‰“å°ä¸€äº›ç»Ÿè®¡ä¿¡æ¯
            total_stocks = sum(len(stocks) for stocks in data.values())
            logger.info(f"ğŸ“Š æ€»è®¡åŒ…å« {total_stocks} ä¸ªè‚¡ç¥¨æ˜ å°„å…³ç³»")
            
            # æ‰“å°å‰3ä¸ªæ¦‚å¿µçš„ä¿¡æ¯
            for i, (concept, stocks) in enumerate(data.items()):
                if i >= 3:
                    break
                logger.debug(f"  æ¦‚å¿µæ ·ä¾‹ {i+1}: {concept} -> {len(stocks)} åªè‚¡ç¥¨")
            
            return data
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ¦‚å¿µè‚¡ç¥¨æ˜ å°„å¤±è´¥: {e}")
            return {}
    else:
        logger.warning(f"âš ï¸ æ¦‚å¿µè‚¡ç¥¨æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {CONCEPT_STOCK_MAP_FILE}")
        return {}

def load_concept_name_to_code() -> Dict[str, str]:
    """åŠ è½½æ¦‚å¿µåç§°åˆ°ä»£ç çš„æ˜ å°„"""
    logger.info(f"ğŸ”— å¼€å§‹åŠ è½½æ¦‚å¿µä»£ç æ˜ å°„æ–‡ä»¶: {CONCEPT_NAME_TO_CODE_FILE}")
    
    if os.path.exists(CONCEPT_NAME_TO_CODE_FILE):
        try:
            with open(CONCEPT_NAME_TO_CODE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(data)} ä¸ªæ¦‚å¿µä»£ç æ˜ å°„")
            
            # æ‰“å°å‰5ä¸ªæ˜ å°„æ ·ä¾‹
            sample_items = list(data.items())[:5]
            for name, code in sample_items:
                logger.debug(f"  æ˜ å°„æ ·ä¾‹: {name} -> {code}")
            
            return data
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ¦‚å¿µä»£ç æ˜ å°„å¤±è´¥: {e}")
            return {}
    else:
        logger.warning(f"âš ï¸ æ¦‚å¿µåç§°æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {CONCEPT_NAME_TO_CODE_FILE}")
        return {}

def get_stock_concepts(stock_code: str, concept_map: Dict[str, List[str]]) -> List[str]:
    """è·å–æŸä¸ªè‚¡ç¥¨æ‰€å±æ¦‚å¿µåç§°åˆ—è¡¨"""
    result = []
    for concept, stocks in concept_map.items():
        if stock_code in stocks:
            result.append(concept)
    
    if result:
        logger.debug(f"ğŸ·ï¸ {stock_code} æ‰€å±æ¦‚å¿µ: {result}")
    else:
        logger.debug(f"âš ï¸ {stock_code} æœªæ‰¾åˆ°æ‰€å±æ¦‚å¿µ")
    
    return result

def inject_sector_score(final_score: float, stock_code: str, 
                        concept_name_to_ts_code: Dict[str, str], 
                        sector_scores: Dict[str, float], 
                        concept_map: Dict[str, List[str]],
                        weight: float = 0.3) -> float:
    """å¯¹å•åªè‚¡ç¥¨ final_score æ·»åŠ æ¿å—çƒ­åº¦åŠ æˆ"""
    # å›æµ‹æ¨¡å¼ä¸‹ç›´æ¥è¿”å›åŸåˆ†æ•°
    if IS_BACKTEST:
        logger.debug(f"ğŸ”™ å›æµ‹æ¨¡å¼ï¼š{stock_code} è·³è¿‡æ¿å—çƒ­åº¦åŠ åˆ†")
        return final_score
    
    # å¦‚æœæ²¡æœ‰æ¿å—è¯„åˆ†æ•°æ®ï¼Œä¹Ÿç›´æ¥è¿”å›
    if not sector_scores:
        logger.debug(f"âš ï¸ æ— æ¿å—è¯„åˆ†æ•°æ®ï¼Œ{stock_code} è·³è¿‡æ¿å—çƒ­åº¦åŠ åˆ†")
        return final_score
    logger.debug(f"ğŸ’‰ å¼€å§‹è®¡ç®— {stock_code} çš„æ¿å—çƒ­åº¦åŠ åˆ†...")
    
    concepts = get_stock_concepts(stock_code, concept_map)
    if not concepts:
        logger.debug(f"âš ï¸ {stock_code} æ— æ‰€å±æ¦‚å¿µï¼Œæ¿å—åŠ åˆ†ä¸º0")
        return final_score
    
    logger.debug(f"ğŸ·ï¸ {stock_code} æ‰€å±æ¦‚å¿µ: {concepts}")
    
    score_boost = 0.0
    detail_boosts = []
    
    for c in concepts:
        ts_code = concept_name_to_ts_code.get(c)
        logger.debug(f"ğŸ” æ¦‚å¿µ '{c}' å¯¹åº”ä»£ç : {ts_code}")
        
        if ts_code:
            sector_score = sector_scores.get(ts_code, 0.0)
            logger.debug(f"ğŸ“Š {c} ({ts_code}) æ¿å—è¯„åˆ†: {sector_score}")
            score_boost += sector_score
            detail_boosts.append(f"{c}({sector_score})")
        else:
            logger.debug(f"âš ï¸ æ¦‚å¿µ '{c}' æœªæ‰¾åˆ°å¯¹åº”ä»£ç ")
    
    weighted_boost = score_boost * weight
    logger.debug(f"ğŸ’° {stock_code} æ¿å—çƒ­åº¦æ€»åˆ†: {score_boost:.2f} Ã— {weight} = {weighted_boost:.2f}")
    logger.debug(f"ğŸ“Š å„æ¿å—è´¡çŒ®: {', '.join(detail_boosts)}")
    
    return final_score + weighted_boost








# æ–°å¢å¤åˆä¿¡å·æ£€æµ‹å‡½æ•°
def detect_composite_signals(df: pd.DataFrame) -> dict:
    signals = {}
    
    # ä¸šç»©çªç ´+é‡ä»·é½å‡
    earnings_growth = (df['revenue_yoy'].iloc[-1] > 0.3) & (df['netprofit_yoy'].iloc[-1] > 0.5)
    volume_spike = df['vol'].iloc[-1] > df['vol'].rolling(20).mean().iloc[-1] * 1.5
    signals["ä¸šç»©çªç ´+é‡ä»·é½å‡"] = earnings_growth & volume_spike
    
    # æœºæ„å¢æŒ+ä¼°å€¼ä¿®å¤
    inst_holding = (df['holder_num'].iloc[-1] < df['holder_num'].iloc[-2]) & \
                  (df['inst_holding_ratio'].iloc[-1] > df['inst_holding_ratio'].iloc[-2])
    valuation_improve = (df['pe_ttm'].iloc[-1] < df['pe_ttm'].rolling(20).mean().iloc[-1]) & \
                       (df['pb'].iloc[-1] < df['pb'].rolling(20).mean().iloc[-1])
    signals["æœºæ„å¢æŒ+ä¼°å€¼ä¿®å¤"] = inst_holding & valuation_improve
    
    return signals










def initialize_share_float_data(ts_codes: List[str], days_ahead: int = 30):
    """ç»Ÿè®¡æœªæ¥ days_ahead å¤©å†…å°†è¦è§£ç¦çš„è‚¡ä»½æ€»é‡"""
    logger.info(f"ğŸš¨ åˆå§‹åŒ–é™å”®è§£ç¦æ•°æ®ï¼ˆæœªæ¥ {days_ahead} å¤©ï¼‰...")
    batch_size = 200
    today = datetime.today()
    
    # è®¡ç®—æ—¶é—´èŒƒå›´
    end_date = (today + timedelta(days=days_ahead)).strftime('%Y%m%d')
    today_str = today.strftime('%Y%m%d')
    
    # é¢„å¡«å……é»˜è®¤å€¼
    for code in ts_codes:
        share_float_cache.setdefault(code, 0)
    
    # è®°å½•æˆåŠŸè·å–æ•°æ®çš„æ‰¹æ¬¡å’Œæœ‰æ•ˆè§£ç¦æ•°é‡
    success_batches = 0
    total_batches = (len(ts_codes) + batch_size - 1) // batch_size
    unlocked_count = 0
    
    for i in range(0, len(ts_codes), batch_size):
        batch = ts_codes[i:i + batch_size]
        ts_str = ",".join(batch)
        
        try:
            # æ ¹æ®æ–‡æ¡£ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨start_dateå’Œend_dateï¼Œä¸éœ€è¦ann_date
            # ç›´æ¥æŸ¥è¯¢æœªæ¥days_aheadå¤©å†…å°†è¦è§£ç¦çš„æ•°æ®
            df = safe_api_call(
                pro.share_float,
                ts_code=ts_str,
                start_date=today_str,  # ä»ä»Šå¤©å¼€å§‹
                end_date=end_date      # åˆ°æœªæ¥days_aheadå¤©
            )
            
            if df.empty or 'ts_code' not in df.columns:
                logger.warning(f"âš ï¸ share_float æ‰¹æ¬¡ {i//batch_size + 1}/{total_batches} æ•°æ®ä¸ºç©ºæˆ–å­—æ®µç¼ºå¤±")
                continue
            
            # ç»Ÿè®¡æœªæ¥days_aheadå¤©å†…å°†è§£ç¦çš„æ€»è‚¡æ•°
            success_batches += 1
            valid_codes = set(df['ts_code'].unique())
            
            for code in batch:
                if code in valid_codes:
                    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è¦ç»Ÿè®¡çš„æ˜¯float_dateåœ¨æœªæ¥days_aheadå¤©å†…çš„æ•°æ®
                    sub_df = df[(df['ts_code'] == code) & 
                                (df['float_date'] >= today_str) & 
                                (df['float_date'] <= end_date)]
                    
                    if not sub_df.empty and 'float_share' in sub_df.columns:
                        # ç¡®ä¿float_shareå­—æ®µä¸ºæ•°å€¼ç±»å‹
                        sub_df['float_share'] = pd.to_numeric(sub_df['float_share'], errors='coerce')
                        future_unlock = sub_df['float_share'].sum()
                        
                        if future_unlock > 0:
                            share_float_cache[code] = future_unlock
                            unlocked_count += 1
                            logger.info(f"âœ… {code} æœªæ¥{days_ahead}å¤©å°†è§£ç¦ï¼š{future_unlock:.1f} ä¸‡è‚¡")
                        else:
                            share_float_cache[code] = 0
                    else:
                        share_float_cache[code] = 0
                else:
                    share_float_cache[code] = 0
            
        except Exception as e:
            logger.error(f"âŒ share_float æ‰¹æ¬¡ {i//batch_size + 1}/{total_batches} å¤„ç†å¤±è´¥ï¼š{str(e)}")
            for code in batch:
                share_float_cache[code] = 0
    
    logger.info(f"âœ… é™å”®è§£ç¦æ•°æ®åˆå§‹åŒ–å®Œæˆ | æˆåŠŸæ‰¹æ¬¡: {success_batches}/{total_batches} | æœ‰è§£ç¦è‚¡ç¥¨æ•°ï¼š{unlocked_count}/{len(ts_codes)}")


def evaluate_share_float(ts_code: str) -> float:
    """æœªæ¥è§£ç¦è¯„åˆ†"""
    try:
        unlock_amount = share_float_cache.get(ts_code, 0)

        if not isinstance(unlock_amount, (int, float)):
            logger.warning(f"{ts_code} è§£ç¦æ•°æ®å¼‚å¸¸ï¼š{unlock_amount}ï¼ŒæŒ‰0å¤„ç†")
            return 0

        # æœªæ¥è§£ç¦é£é™©è¯„åˆ†
        if unlock_amount > 10000:
            logger.debug(f"{ts_code} æœªæ¥è§£ç¦ {unlock_amount:.1f} ä¸‡è‚¡ï¼Œæ‰£6åˆ†")
            return -6
        elif unlock_amount > 5000:
            return -4
        elif unlock_amount > 2000:
            return -2
        return 0

    except Exception as e:
        logger.error(f"{ts_code} è§£ç¦è¯„åˆ†å¤±è´¥ï¼š{str(e)}")
        return 0


def initialize_holdernumber_data(ts_codes: List[str]):
    """åˆå§‹åŒ–è‚¡ä¸œäººæ•°æ•°æ®ï¼Œè®¡ç®—æœ€è¿‘ä¸¤æ¬¡å…¬å‘Šä¹‹é—´çš„å˜åŒ–"""
    logger.info("ğŸš¨ åˆå§‹åŒ–è‚¡ä¸œäººæ•°æ•°æ®...")
    batch_size = 200
    today = datetime.today()
    one_year_ago = (today - timedelta(days=365)).strftime('%Y%m%d')
    
    # è·Ÿè¸ªå¤„ç†è¿›åº¦ä¸ç»“æœ
    total_batches = (len(ts_codes) + batch_size - 1) // batch_size
    success_count = 0
    uncached_codes = [code for code in ts_codes if code not in holdernumber_cache]
    
    logger.info(f"å¾…å¤„ç†è‚¡ç¥¨ï¼š{len(uncached_codes)}/{len(ts_codes)} æ”¯")
    
    for i in range(0, len(uncached_codes), batch_size):
        batch = uncached_codes[i:i + batch_size]
        ts_str = ",".join(batch)
        
        try:
            # æ ¹æ®æ–‡æ¡£ï¼Œç¡®è®¤æ­£ç¡®çš„APIè°ƒç”¨å‚æ•°ï¼Œä½¿ç”¨start_dateå’Œend_dateå‚æ•°æŸ¥è¯¢æ—¶é—´èŒƒå›´å†…çš„æ•°æ®
            df = safe_api_call(
                pro.stk_holdernumber, 
                ts_code=ts_str, 
                start_date=one_year_ago, 
                end_date=today.strftime('%Y%m%d')
            )
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦è·å–æˆåŠŸ
            if df.empty:
                logger.warning(f"âš ï¸ æ‰¹æ¬¡ {i//batch_size + 1}/{total_batches} è‚¡ä¸œäººæ•°æ•°æ®ä¸ºç©º")
                continue
                
            if 'ts_code' not in df.columns or 'holder_num' not in df.columns or 'end_date' not in df.columns:
                logger.warning(f"âš ï¸ æ‰¹æ¬¡ {i//batch_size + 1}/{total_batches} è‚¡ä¸œäººæ•°æ•°æ®å­—æ®µç¼ºå¤± - å®é™…å­—æ®µ: {df.columns.tolist()}")
                continue
            
            # è®¡ç®—æ¯æ”¯è‚¡ç¥¨æœ€è¿‘ä¸¤æ¬¡å…¬å‘Šçš„è‚¡ä¸œäººæ•°å˜åŒ–
            batch_success = 0
            for code in batch:
                try:
                    # ç­›é€‰å¹¶æŒ‰end_dateæ’åºï¼ˆä»æ–°åˆ°æ—§ï¼‰
                    sub_df = df[df['ts_code'] == code].sort_values('end_date', ascending=False)
                    
                    if len(sub_df) < 2:
                        # æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—å˜åŒ–
                        holdernumber_cache[code] = 0
                        logger.debug(f"{code} è‚¡ä¸œäººæ•°æ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦2æ¡è®°å½•ï¼Œå®é™…: {len(sub_df)}")
                    else:
                        # è®¡ç®—æœ€è¿‘ä¸¤æ¬¡çš„å˜åŒ–ï¼šå‰ä¸€æœŸ - æœ€æ–°æœŸï¼ˆæ­£å€¼è¡¨ç¤ºå‡å°‘ï¼Œè´Ÿå€¼è¡¨ç¤ºå¢åŠ ï¼‰
                        latest_date = sub_df.iloc[0]['end_date']
                        latest_num = int(sub_df.iloc[0]['holder_num'])
                        prev_date = sub_df.iloc[1]['end_date']
                        prev_num = int(sub_df.iloc[1]['holder_num'])
                        
                        change = prev_num - latest_num
                        holdernumber_cache[code] = change
                        
                        # è®°å½•æ˜¾è‘—å˜åŒ–
                        if abs(change) > 100:
                            logger.debug(f"{code} è‚¡ä¸œäººæ•°å˜åŒ–: {prev_num}({prev_date}) â†’ {latest_num}({latest_date}), å‡€å˜åŒ–: {change}")
                        
                        batch_success += 1
                except Exception as e:
                    holdernumber_cache[code] = 0
                    logger.warning(f"{code} å¤„ç†å¤±è´¥: {str(e)}")
            
            logger.info(f"æ‰¹æ¬¡ {i//batch_size + 1}/{total_batches} å¤„ç†å®Œæˆ: {batch_success}/{len(batch)} æ”¯è‚¡ç¥¨å¤„ç†æˆåŠŸ")
            success_count += batch_success
            
        except Exception as e:
            logger.error(f"è‚¡ä¸œäººæ•°æ•°æ®å¤„ç†å¤±è´¥ï¼ˆæ‰¹æ¬¡ {i//batch_size + 1}/{total_batches}ï¼‰: {str(e)}")
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            for code in batch:
                holdernumber_cache[code] = 0
    
    # æ€»ç»“å¤„ç†ç»“æœ
    valid_changes = sum(1 for v in holdernumber_cache.values() if v != 0)
    logger.info(f"âœ… è‚¡ä¸œäººæ•°æ•°æ®ç¼“å­˜å®Œæˆï¼šæˆåŠŸå¤„ç† {success_count}/{len(uncached_codes)} æ”¯è‚¡ç¥¨ï¼Œæœ‰æ•ˆå˜åŒ–æ•°æ® {valid_changes} æ¡")


def evaluate_holdernumber(ts_code: str) -> float:
    diff = holdernumber_cache.get(ts_code, 0)
    if diff > 500:
        logger.debug(f"{ts_code} è‚¡ä¸œäººæ•°å¤§å¹…å‡å°‘ {diff}ï¼ŒåŠ 5åˆ†")
        return 5
    elif diff > 100:
        return 3
    return 0


def initialize_express_data(period: str = None, ts_codes: List[str] = None):
    """åˆå§‹åŒ–ä¸šç»©å¿«æŠ¥æ•°æ®ï¼Œè·å–æœ€æ–°ä¸€æœŸçš„ä¸šç»©åŒæ¯”å¢é•¿ç‡
    
    Args:
        period: æŠ¥å‘ŠæœŸ(æ¯ä¸ªå­£åº¦æœ€åä¸€å¤©çš„æ—¥æœŸ,æ¯”å¦‚20231231è¡¨ç¤ºå¹´æŠ¥)ï¼Œå¦‚æœä¸ºNoneåˆ™è·å–æœ€è¿‘çš„æŠ¥å‘ŠæœŸ
        ts_codes: éœ€è¦æŸ¥è¯¢çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸è¿‡æ»¤
    """
    logger.info("ğŸš¨ åˆå§‹åŒ–ä¸šç»©å¿«æŠ¥æ•°æ®...")
    
    # ç¡®å®šæŸ¥è¯¢å‚æ•°
    if period is None:
        # è‡ªåŠ¨è®¡ç®—æœ€è¿‘çš„æŠ¥å‘ŠæœŸï¼ˆæ¯ä¸ªå­£åº¦æœ€åä¸€ä¸ªæœˆçš„æœ€åä¸€å¤©ï¼‰
        today = datetime.today()
        year = today.year
        # ç¡®å®šæœ€è¿‘çš„å­£åº¦ç»“æŸæœˆä»½ï¼ˆ3,6,9,12ï¼‰
        month = (today.month - 1) // 3 * 3 + 3
        if month > today.month:
            # å¦‚æœè®¡ç®—çš„æœˆä»½è¶…è¿‡å½“å‰æœˆä»½ï¼Œåˆ™ä½¿ç”¨ä¸Šä¸€ä¸ªå­£åº¦
            if month == 3:  
                month = 12
                year -= 1
            else:
                month -= 3
                
        # æ„å»ºæŠ¥å‘ŠæœŸå­—ç¬¦ä¸²ï¼šå¦‚ 20231231 è¡¨ç¤º2023å¹´å¹´æŠ¥
        if month == 12:
            period = f"{year}1231"  # å¹´æŠ¥
        elif month == 9:
            period = f"{year}0930"  # ä¸‰å­£æŠ¥
        elif month == 6:
            period = f"{year}0630"  # åŠå¹´æŠ¥
        elif month == 3:
            period = f"{year}0331"  # ä¸€å­£æŠ¥
            
        logger.info(f"è‡ªåŠ¨è®¡ç®—æœ€è¿‘æŠ¥å‘ŠæœŸ: {period}")
    
    try:
        # æ„å»ºæŸ¥è¯¢å­—æ®µï¼Œç¡®ä¿åŒ…å«åŒæ¯”å¢é•¿ç‡å­—æ®µ
        fields = 'ts_code,ann_date,end_date,revenue,operate_profit,total_profit,n_income,total_assets,yoy_net_profit,yoy_sales,yoy_op'
        
        # æ ¹æ®æ–‡æ¡£ï¼Œexpress_vipæ¥å£å¯ä»¥è·å–æŸä¸€æŠ¥å‘ŠæœŸå…¨éƒ¨è‚¡ç¥¨æ•°æ®
        df = safe_api_call(pro.express_vip, period=period, fields=fields)
        
        # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {period} æœŸé—´çš„ä¸šç»©å¿«æŠ¥æ•°æ®ä¸ºç©º")
            
            # å°è¯•è·å–å‰ä¸€ä¸ªå­£åº¦çš„æ•°æ®
            try:
                prev_period = get_previous_period(period)
                logger.info(f"å°è¯•è·å–å‰ä¸€æœŸæŠ¥å‘ŠæœŸæ•°æ®: {prev_period}")
                df = safe_api_call(pro.express_vip, period=prev_period, fields=fields)
                
                if df is None or df.empty:
                    logger.warning(f"âš ï¸ å‰ä¸€æœŸ {prev_period} çš„æ•°æ®ä¹Ÿä¸ºç©ºï¼Œæ”¾å¼ƒè·å–")
                    return
                    
                logger.info(f"âœ… æˆåŠŸè·å–å‰ä¸€æœŸ {prev_period} çš„ä¸šç»©å¿«æŠ¥æ•°æ®, åŒ…å« {len(df)} æ”¯è‚¡ç¥¨")
            except Exception as e:
                logger.error(f"è·å–å‰ä¸€æœŸæ•°æ®å¤±è´¥: {e}")
                return
        
        # è¿‡æ»¤æŒ‡å®šçš„è‚¡ç¥¨ä»£ç ï¼ˆå¦‚æœæä¾›äº†ï¼‰
        if ts_codes is not None:
            ts_codes_set = set(ts_codes)
            df = df[df['ts_code'].isin(ts_codes_set)]
            logger.info(f"è¿‡æ»¤æŒ‡å®šçš„ {len(ts_codes)} æ”¯è‚¡ç¥¨ï¼Œè¿‡æ»¤åå‰©ä½™ {len(df)} æ”¯")
        
        # å¤„ç†æ•°æ®ï¼Œæå–åŒæ¯”å¢é•¿ç‡
        processed_count = 0
        for index, row in df.iterrows():
            try:
                ts_code = row['ts_code']
                
                # ä¼˜å…ˆä½¿ç”¨ yoy_net_profit (å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡)
                # å¦‚æœæ²¡æœ‰ï¼Œåˆ™å°è¯•ä½¿ç”¨ yoy_sales (è¥æ”¶åŒæ¯”å¢é•¿ç‡)
                # å¦‚æœéƒ½æ²¡æœ‰ï¼Œåˆ™å°è¯•ä½¿ç”¨ yoy_op (è¥ä¸šåˆ©æ¶¦åŒæ¯”å¢é•¿ç‡)
                profit_yoy = (
                    row.get('yoy_net_profit', None) or 
                    row.get('net_profit_yoy', None) or 
                    row.get('yoy_sales', None) or 
                    row.get('yoy_op', None) or 
                    0
                )
                
                # ç¡®ä¿è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                try:
                    profit_yoy = float(profit_yoy)
                except (ValueError, TypeError):
                    profit_yoy = 0
                
                # ä¿å­˜åˆ°ç¼“å­˜
                express_cache[ts_code] = profit_yoy
                
                # å¯¹äºæ˜¾è‘—çš„å¢é•¿æˆ–ä¸‹æ»‘ï¼Œè®°å½•æ—¥å¿—
                if abs(profit_yoy) > 30:
                    if profit_yoy > 0:
                        logger.info(f"{ts_code} ä¸šç»©å¿«æŠ¥å‡€åˆ©åŒæ¯”å¤§å¹…å¢é•¿ï¼š+{profit_yoy:.1f}%")
                    else:
                        logger.warning(f"{ts_code} ä¸šç»©å¿«æŠ¥å‡€åˆ©åŒæ¯”å¤§å¹…ä¸‹æ»‘ï¼š{profit_yoy:.1f}%")
                        
                processed_count += 1
                
            except Exception as e:
                logger.warning(f"å¤„ç†è‚¡ç¥¨ {row.get('ts_code', 'æœªçŸ¥')} çš„ä¸šç»©æ•°æ®å¤±è´¥: {e}")
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        logger.info(f"âœ… ä¸šç»©å¿«æŠ¥æ•°æ®ç¼“å­˜å®Œæˆï¼šå…±è·å– {len(df)} æ”¯è‚¡ç¥¨æ•°æ®ï¼ŒæˆåŠŸå¤„ç† {processed_count} æ”¯")
        
        # è¾“å‡ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
        if processed_count > 0:
            # è®¡ç®—ä¸šç»©å¢é•¿è‚¡ç¥¨æ¯”ä¾‹
            growth_stocks = sum(1 for v in express_cache.values() if v > 0)
            decline_stocks = sum(1 for v in express_cache.values() if v < 0)
            growth_ratio = growth_stocks / processed_count if processed_count > 0 else 0
            
            logger.info(f"ğŸ“Š ä¸šç»©ç»Ÿè®¡: å¢é•¿ {growth_stocks} æ”¯ ({growth_ratio:.1%}), ä¸‹æ»‘ {decline_stocks} æ”¯ ({1-growth_ratio:.1%})")
        
    except Exception as e:
        logger.error(f"è·å–ä¸šç»©å¿«æŠ¥æ•°æ®å¤±è´¥ for {period}: {e}")
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")


def get_previous_period(period: str) -> str:
    """è·å–ä¸Šä¸€ä¸ªæŠ¥å‘ŠæœŸ
    
    ä¾‹å¦‚ï¼š20231231 -> 20230930, 20230930 -> 20230630, ç­‰
    """
    year = int(period[:4])
    month = int(period[4:6])
    
    if month == 12:  # å¹´æŠ¥
        return f"{year}0930"  # è¿”å›åŒå¹´ä¸‰å­£æŠ¥
    elif month == 9:  # ä¸‰å­£æŠ¥
        return f"{year}0630"  # è¿”å›åŒå¹´åŠå¹´æŠ¥
    elif month == 6:  # åŠå¹´æŠ¥
        return f"{year}0331"  # è¿”å›åŒå¹´ä¸€å­£æŠ¥
    elif month == 3:  # ä¸€å­£æŠ¥
        return f"{year-1}1231"  # è¿”å›ä¸Šä¸€å¹´å¹´æŠ¥
    else:
        # ä¸è§„èŒƒçš„æŠ¥å‘ŠæœŸï¼Œè¿”å›åŸå€¼
        return period


def evaluate_express(ts_code: str) -> float:
    profit_yoy = express_cache.get(ts_code, 0)
    if profit_yoy > 50:
        logger.debug(f"{ts_code} ä¸šç»©å¿«æŠ¥å‡€åˆ©åŒæ¯” +{profit_yoy:.1f}%ï¼ŒåŠ 6åˆ†")
        return 6
    elif profit_yoy > 20:
        return 4
    elif profit_yoy > 0:
        return 2
    elif profit_yoy < -30:
        return -4
    return 0



def initialize_risk_data(ts_codes: List[str]):
    today = datetime.today()
    batch_size = 200
    three_years_ago = (today - timedelta(days=3*365)).strftime('%Y%m%d')
    one_year_ago = (today - timedelta(days=365)).strftime('%Y%m%d')

    # ç»Ÿä¸€ä¸ºçŸ­ä»£ç æ ¼å¼ï¼ˆå¦‚600000ï¼‰
    ts_codes = [c.split('.')[0] for c in list(set(ts_codes))]
    uncached_codes = [
        c for c in ts_codes
        if c not in pledge_stat_cache 
        or c not in pledge_detail_cache 
        or c not in holder_trade_cache
    ]

    if not uncached_codes:
        logger.info("âœ… é£é™©æ•°æ®å·²å…¨ç¼“å­˜ï¼Œè·³è¿‡åˆå§‹åŒ–")
        return

    for i in range(0, len(uncached_codes), batch_size):
        batch = uncached_codes[i:i + batch_size]
        # è¡¥å…¨äº¤æ˜“æ‰€ä»£ç ï¼ˆ600000 -> 600000.SHï¼‰
        ts_str = ",".join([
            f"{c}.SH" if c.startswith(('6', '9')) else f"{c}.SZ" 
            for c in batch
        ])

        # ================== è´¨æŠ¼ç‡ç»Ÿè®¡ ==================
        try:
            # ä»èµ„äº§è´Ÿå€ºè¡¨è·å–æœ€æ–°è´¨æŠ¼ç‡
            df_stat = safe_api_call(
                pro.balancesheet,
                ts_code=ts_str,
                period='20231231',  # ä½¿ç”¨æœ€æ–°å¹´æŠ¥
                fields='ts_code,pledge_ratio'
            )
            if not df_stat.empty:
                for _, row in df_stat.iterrows():
                    code = row['ts_code'].split('.')[0]
                    pledge_stat_cache[code] = float(row['pledge_ratio'])
        except Exception as e:
            logger.error(f"è´¨æŠ¼ç‡è·å–å¤±è´¥ï¼š{str(e)}")

        # ================== è´¨æŠ¼æ¬¡æ•°ç»Ÿè®¡ ==================
        try:
            df_pledge = pd.DataFrame()
            three_years_ago = (today - timedelta(days=3*365)).strftime('%Y%m%d')
            for offset in range(0, 5000, 1000):
                chunk = safe_api_call(
                    pro.pledge_detail,
                    ts_code=ts_str,
                    limit=1000,
                    offset=offset
                )
                df_pledge = pd.concat([df_pledge, chunk])
            
            if not df_pledge.empty:
                df_pledge['base_code'] = df_pledge['ts_code'].str.split('.').str[0]
                df_pledge = df_pledge[df_pledge['ann_date'] >= three_years_ago]
                df_pledge = df_pledge.drop_duplicates(['base_code', 'ann_date'])
                pledge_counts = df_pledge.groupby('base_code').size()
                
                for code in batch:
                    pledge_detail_cache[code] = pledge_counts.get(code, 0)
        except Exception as e:
            logger.error(f"è´¨æŠ¼æ¬¡æ•°è·å–å¤±è´¥ï¼š{str(e)}")

        # ================== å‡æŒæ¬¡æ•°ç»Ÿè®¡ ==================
        try:
            df_holders = safe_api_call(
                pro.top10_holders,
                ts_code=ts_str,
                start_date=one_year_ago,
                end_date=today.strftime('%Y%m%d'),
                fields='ts_code,hold_change'
            )
            if not df_holders.empty:
                df_holders['hold_change'] = pd.to_numeric(df_holders['hold_change'], errors='coerce')
                reduce_df = df_holders[df_holders['hold_change'] < 0]
                reduce_counts = reduce_df.groupby('ts_code').size()
                
                for code in batch:
                    short_code = code.split('.')[0] if '.' in code else code
                    holder_trade_cache[code] = reduce_counts.get(f"{short_code}.SH", reduce_counts.get(f"{short_code}.SZ", 0))
        except Exception as e:
            logger.error(f"å‡æŒæ¬¡æ•°è·å–å¤±è´¥ï¼š{str(e)}")

    logger.info(f"âœ… é£é™©æ•°æ®åˆå§‹åŒ–å®Œæˆ | è´¨æŠ¼ç‡:{len(pledge_stat_cache)} è´¨æŠ¼æ¬¡æ•°:{sum(pledge_detail_cache.values())} å‡æŒ:{sum(holder_trade_cache.values())}")

def evaluate_risk_factors(ts_code: str) -> float:
    # ç¡®ä¿ä½¿ç”¨çŸ­ä»£ç æ ¼å¼è¿›è¡ŒæŸ¥æ‰¾
    short_code = ts_code.split('.')[0] if '.' in ts_code else ts_code
    
    penalty = 0
    
    # ä½¿ç”¨çŸ­ä»£ç æ ¼å¼æŸ¥è¯¢ç¼“å­˜
    pledg_ratio = pledge_stat_cache.get(short_code, 0)
    if pledg_ratio >= 60:
        penalty -= 12
    elif pledg_ratio >= 40:
        penalty -= 8
    elif pledg_ratio >= 30:
        penalty -= 5
        
    pledge_times = pledge_detail_cache.get(short_code, 0)
    if pledge_times >= 5:
        penalty -= 4
    elif pledge_times >= 2:
        penalty -= 2
        
    reduce_times = holder_trade_cache.get(short_code, 0)
    if reduce_times >= 3:
        penalty -= 6
    elif reduce_times >= 1:
        penalty -= 3
        
    if penalty != 0:
        logger.debug(f"{ts_code} é£é™©æ‰£åˆ†ï¼š{penalty} (è´¨æŠ¼ç‡: {pledg_ratio}%, è´¨æŠ¼æ¬¡æ•°: {pledge_times}, å‡æŒæ¬¡æ•°: {reduce_times})")
    else:
        # å¢åŠ é›¶åˆ†è°ƒè¯•ä¿¡æ¯
        logger.debug(f"{ts_code} é£é™©è¯„ä¼°: è´¨æŠ¼ç‡:{pledg_ratio}% è´¨æŠ¼æ¬¡æ•°:{pledge_times} å‡æŒæ¬¡æ•°:{reduce_times}")
    
    return penalty


    
# ===== æ‰¹é‡ç¼“å­˜æ•°æ® =====
industry_cache = {}          # è¡Œä¸šä¿¡æ¯ç¼“å­˜ï¼šts_code -> è¡Œä¸šåç§°
concept_cache = {}           # æ¦‚å¿µé¢˜æç¼“å­˜ï¼šts_code -> æ¦‚å¿µåˆ—è¡¨
moneyflow_scores = {}        # èµ„é‡‘æµå‘å¾—åˆ†ç¼“å­˜ï¼šts_code -> å¾—åˆ†
concept_list_cache = {}      # æ¦‚å¿µåç§°ä¸IDæ˜ å°„ç¼“å­˜ï¼šconcept_name -> concept_id
concept_detail_cache = {}    # æ¦‚å¿µæ¶¨å¹…ç¼“å­˜ï¼šconcept_id -> å¹³å‡æ¶¨å¹…
pledge_stat_cache = {}       # è´¨æŠ¼ç‡ç¼“å­˜ï¼šts_code -> è´¨æŠ¼ç‡(%)
pledge_detail_cache = {}     # è´¨æŠ¼æ¬¡æ•°ç¼“å­˜ï¼šts_code -> æ¬¡æ•°
holder_trade_cache = {}      # è‚¡ä¸œå‡æŒæ¬¡æ•°ç¼“å­˜ï¼šts_code -> æ¬¡æ•°
block_trade_cache = {}       # å¤§å®—äº¤æ˜“æ¬¡æ•°ç¼“å­˜ï¼šts_code -> æ¬¡æ•°
stk_limit_cache = {}         # æ¶¨è·Œåœä»·ç¼“å­˜ï¼šts_code -> {'up_limit': x, 'down_limit': y}
share_float_cache = {}      # é™å”®è§£ç¦ç¼“å­˜
holdernumber_cache = {}     # è‚¡ä¸œäººæ•°ç¼“å­˜
express_cache = {}          # ä¸šç»©å¿«æŠ¥ç¼“å­˜

# ===== å·¥å…·å‡½æ•° =====
def get_strategy_type(strategy_name: str) -> str:
    for group_name, strategy_list in STRATEGY_GROUPS.items():
        if strategy_name in strategy_list:
            return group_name
    return "æœªçŸ¥"

# ===== è·å–è¡Œä¸šä¸é¢˜æä¿¡æ¯ =====
def get_industry(ts_code: str) -> str:
    return industry_cache.get(ts_code, "æœªçŸ¥è¡Œä¸š")

def get_concepts(ts_code: str) -> List[str]:
    return concept_cache.get(ts_code, [])

# ===== åˆ†æ•£åº¦ç®—æ³• =====
def diversify_recommendations(scored_stocks: List[Tuple], max_recommend=10, min_score_threshold=0) -> List[Tuple]:
    # â­ å¾—åˆ†ä»é«˜åˆ°ä½æ’åº
    scored_stocks = sorted(scored_stocks, key=lambda x: x[0], reverse=True)

    industry_count = {}
    concept_count = {}
    final_selection = []
    dynamic_industry_limit = 3
    dynamic_concept_limit = 2

    for stock in scored_stocks:
        score, ts_code, name, matched, pct_change, df, score_details = stock

        if score < min_score_threshold:
            continue

        # å‰ä¸‰åä¸å—è¡Œä¸šå’Œé¢˜æé™åˆ¶ï¼Œå¿…é¡»æ”¾åœ¨æœ€å‰é¢
        if len(final_selection) < 3:
            final_selection.append(stock)
            industry = get_industry(ts_code)
            concepts = get_concepts(ts_code)
            industry_count[industry] = industry_count.get(industry, 0) + 1
            for c in concepts:
                concept_count[c] = concept_count.get(c, 0) + 1
            continue

        industry = get_industry(ts_code)
        concepts = get_concepts(ts_code)

        if len(final_selection) >= max_recommend:
            break

        remaining_slots = max_recommend - len(final_selection)
        if remaining_slots <= 3:
            dynamic_industry_limit = 4
            dynamic_concept_limit = 3

        # è¡Œä¸šé™åˆ¶
        if industry and industry_count.get(industry, 0) >= dynamic_industry_limit:
            continue

        # é¢˜æé™åˆ¶
        if concepts and any(concept_count.get(c, 0) >= dynamic_concept_limit for c in concepts):
            continue

        final_selection.append(stock)
        industry_count[industry] = industry_count.get(industry, 0) + 1
        for c in concepts:
            concept_count[c] = concept_count.get(c, 0) + 1

    # âœ… æœ€åä¿é™©å†æ’ä¸€æ¬¡å¾—åˆ†
    final_selection = sorted(final_selection, key=lambda x: x[0], reverse=True)

    return final_selection





# ===== æ ¹æ®å¸‚åœºè¡Œæƒ…åŠ¨æ€è°ƒæ•´ç­–ç•¥æƒé‡ =====

def adjust_strategy_weights_by_market(trade_date: str = None) -> Dict[str, float]:
    """æ ¹æ®å¸‚åœºè¡Œæƒ…åŠ¨æ€è°ƒæ•´ç­–ç•¥æƒé‡ï¼ˆæ”¯æŒå›æµ‹æ¨¡å¼ï¼‰"""
    if IS_BACKTEST and CURRENT_TRADE_DATE:
        trade_date = CURRENT_TRADE_DATE  # å¼ºåˆ¶ä½¿ç”¨å›æµ‹æ—¥æœŸ
    try:
        # ===== æ—¥æœŸå¤„ç†å¢å¼ºç‰ˆ =====
        current_trade_date_str = get_valid_trade_date(
            api_func=pro.daily,  # æ˜ç¡®æŒ‡å®šæ¥å£å‡½æ•°
            date_field='trade_date',  # æ˜ç¡®æ—¥æœŸå­—æ®µåç§°
            base_date=datetime.strptime(trade_date, "%Y%m%d") if trade_date else datetime.today(),
            max_back_days=5
        )
        
        if not current_trade_date_str:
            logger.error("âŒ æ— æ³•è·å–æœ‰æ•ˆäº¤æ˜“æ—¥")
            return STRATEGY_TYPE_WEIGHTS.copy()
            
        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡
        current_trade_date = datetime.strptime(current_trade_date_str, "%Y%m%d")
        logger.info(f"ğŸ“† æœ€ç»ˆå¤„ç†æ—¥æœŸï¼š{current_trade_date.strftime('%Y%m%d')}")

        # ===== å¸‚åœºæŒ‡æ ‡è®¡ç®— =====
        market_data = _get_market_indicators(current_trade_date)
        if market_data is None:
            return STRATEGY_TYPE_WEIGHTS.copy()

        pct_change, volatility, market_momentum, market_status, ma20 = market_data
        
        # ===== å¸‚åœºç»“æœæ—¥å¿— =====
        logger.info(f"å½“å‰å¸‚åœºçŠ¶æ€ï¼š{market_status} (æ¶¨è·Œå¹…: {pct_change:.2%}, æ³¢åŠ¨ç‡: {volatility:.2%}, åŠ¨é‡: {market_momentum:.2%}, 20æ—¥å‡çº¿: {ma20:.2f})")
        
        # ===== åŠ¨æ€æƒé‡è°ƒæ•´æ ¸å¿ƒé€»è¾‘ =====
        adjusted = STRATEGY_TYPE_WEIGHTS.copy()
    
        # æ ¹æ®å¸‚åœºçŠ¶æ€è°ƒæ•´
        adjustment_rules = {
            "æç«¯ç†Šå¸‚": {
                "è¶‹åŠ¿å‹": 0.9,
                "åè½¬å‹": 1.2,
                "å¸‚åœºä¸­æ€§å‹": 1.2,
                "é£é™©å‹": 1.3
            },
            "ç†Šå¸‚": {
                "è¶‹åŠ¿å‹": 0.95,
                "åŠ¨é‡å‹": 0.9,
                "åè½¬å‹": 1.1,
                "å¸‚åœºä¸­æ€§å‹": 1.1,
                "é£é™©å‹": 1.1
            },
            "æ¸©å’Œç†Šå¸‚": {
                "è¶‹åŠ¿å‹": 1.0,
                "åè½¬å‹": 1.05,
                "å¸‚åœºä¸­æ€§å‹": 1.0,
                "é£é™©å‹": 1.0
            },
            "éœ‡è¡å¸‚": {
                "è¶‹åŠ¿å‹": 1.05,  
                "åŠ¨é‡å‹": 1.05,  
                "å¸‚åœºä¸­æ€§å‹": 1.0,  
                "åè½¬å‹": 1.05,  
                "é£é™©å‹": 1.0
            },
            "æ¸©å’Œç‰›å¸‚": {
                "è¶‹åŠ¿å‹": 1.1,
                "åŠ¨é‡å‹": 1.15
            },
            "ç‰›å¸‚": {
                "è¶‹åŠ¿å‹": 1.15,
                "åŠ¨é‡å‹": 1.2
            },
            "æç«¯ç‰›å¸‚": {
                "è¶‹åŠ¿å‹": 1.2,
                "åŠ¨é‡å‹": 1.25
            }
        }
        
        # åº”ç”¨åŸºç¡€è°ƒæ•´è§„åˆ™
        if market_status in adjustment_rules:
            for key, factor in adjustment_rules[market_status].items():
                adjusted[key] *= factor
                
        # æ³¢åŠ¨ç‡åŠ¨æ€è°ƒæ•´ï¼ˆçº¿æ€§æ’å€¼ï¼‰
        volatility_factor = np.interp(volatility, [0.10, 0.40], [0.7, 1.3])
        adjusted.update({
            "å¸‚åœºä¸­æ€§å‹": min(adjusted.get("å¸‚åœºä¸­æ€§å‹", 1.0) * volatility_factor, 2.0),
            "é£é™©å‹": np.clip(adjusted.get("é£é™©å‹", -1.0) * (1.5 - 0.7 * volatility_factor), -2.0, 0.0)
        })
        
        # åŠ¨é‡è¡¥å¿è°ƒæ•´
        momentum_bonus = market_momentum * max(0.5 - 0.2 * abs(market_momentum), 0.3)
        adjusted["åŠ¨é‡å‹"] = np.clip(adjusted["åŠ¨é‡å‹"] + momentum_bonus, 0.6, 2.5)
        adjusted["è¶‹åŠ¿å‹"] = np.clip(adjusted["è¶‹åŠ¿å‹"] + momentum_bonus * 0.7, 0.5, 2.0)
        
        risk_weight = adjusted["é£é™©å‹"]
        if market_status in ["ç‰›å¸‚", "æç«¯ç‰›å¸‚"]:
            risk_weight = max(risk_weight, -1.5)  # ç‰›å¸‚ä¸­æƒ©ç½šä¸Šé™-1.5
        elif market_status == "æç«¯ç†Šå¸‚":
            risk_weight = max(risk_weight, -3.0)  # æç«¯ç†Šå¸‚å…è®¸-3.0
        adjusted["é£é™©å‹"] = risk_weight
        
        # é£é™©æƒé‡è¾¹ç•Œæ§åˆ¶
        weight_limits = {
            "è¶‹åŠ¿å‹": (0.5, 1.5),
            "åŠ¨é‡å‹": (0.6, 1.6),
            "åè½¬å‹": (0.7, 1.8),
            "å¸‚åœºä¸­æ€§å‹": (0.8, 2.0),
            "é£é™©å‹": (-3.0, 0.0)
        }
        
        # åº”ç”¨è¾¹ç•Œé™åˆ¶
        for strategy_type in adjusted:
            if strategy_type in weight_limits:
                min_val, max_val = weight_limits[strategy_type]
                adjusted[strategy_type] = np.clip(adjusted[strategy_type], min_val, max_val)
        
        
        return adjusted

    except Exception as e:
        logger.error(f"âŒ æƒé‡è°ƒæ•´è¿‡ç¨‹å¼‚å¸¸ï¼š{str(e)}\n{traceback.format_exc()}")
        return STRATEGY_TYPE_WEIGHTS.copy()




def _get_market_indicators(trade_date: datetime) -> Optional[Tuple[float, float, float, str, float]]:
    """è·å–ä¸‰å¤§å¸‚åœºæŒ‡æ ‡ï¼šæ¶¨è·Œå¹…ã€æ³¢åŠ¨ç‡ã€åŠ¨é‡ï¼Œå¹¶è®¡ç®—20æ—¥å‡çº¿ï¼ˆMA20ï¼‰åŠåˆ¤æ–­å¸‚åœºçŠ¶æ€"""
    try:
        # è·å–æ²ªæ·±300æ•°æ®
        hs300 = safe_api_call(
            pro.index_daily,
            ts_code="000300.SH",
            start_date=(trade_date - timedelta(days=60)).strftime('%Y%m%d'),
            end_date=trade_date.strftime('%Y%m%d'),
            fields="trade_date,close"
        )
        
        if len(hs300) < 20:
            logger.warning("âš ï¸ æ•°æ®ä¸è¶³20ä¸ªäº¤æ˜“æ—¥")
            return None
        
        # è®¡ç®—å¸‚åœºæŒ‡æ ‡
        closes = hs300['close'].astype(float)
        returns = closes.pct_change().dropna()
        
        # è®¡ç®—æ¶¨è·Œå¹…
        pct_change = (closes.iloc[-1] - closes.iloc[0]) / closes.iloc[0]
        
        # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–ï¼‰
        volatility = returns.std() * np.sqrt(252)
        
        # è®¡ç®—åŠ¨é‡
        momentum = closes[-20:].mean() / closes[:-20].mean() - 1
        
        # è®¡ç®—20æ—¥å‡çº¿ï¼ˆMA20ï¼‰
        ma20 = closes.rolling(20).mean().iloc[-1]
        
        # è·å–å¸‚åœºçŠ¶æ€
        market_status = _determine_market_status(pct_change, volatility, ma20, closes.iloc[-1], momentum)
        
        return pct_change, volatility, momentum, market_status, ma20
        
    except Exception as e:
        logger.error(f"âŒ è·å–å¸‚åœºæŒ‡æ ‡å¤±è´¥ï¼š{str(e)}")
        return None


def _determine_market_status(pct_change: float, volatility: float, ma20: float, last_close: float, momentum: float) -> str:
    """ç»¼åˆåˆ¤æ–­å¸‚åœºçŠ¶æ€"""
    # é¦–å…ˆæ ¹æ®æ³¢åŠ¨ç‡åˆ¤æ–­æ˜¯å¦ä¸ºé«˜æ³¢åŠ¨éœ‡è¡å¸‚
    if volatility > 0.25:
        return "é«˜æ³¢åŠ¨éœ‡è¡å¸‚"
    
    # æ ¹æ®æ¶¨è·Œå¹…å’Œ20æ—¥å‡çº¿å…±åŒåˆ¤æ–­å¸‚åœºçŠ¶æ€
    if pct_change < -0.15:
        return "æç«¯ç†Šå¸‚"
    elif pct_change < -0.05:
        return "ç†Šå¸‚"
    elif pct_change > 0.15:
        # åŠ¨é‡æ­£ä¸”è¾ƒé«˜ï¼Œæç«¯ç‰›å¸‚
        if momentum > 0.1 and last_close > ma20 * 1.08:
            return "æç«¯ç‰›å¸‚"
        # åŠ¨é‡æ­£ä½†è¾ƒä½ï¼Œç‰›å¸‚
        elif momentum > 0.05:
            return "ç‰›å¸‚"
        # æ¶¨å¹…å¤§äº15%ï¼Œä½†æ”¶ç›˜ä»·ä¸å¤§äºMA20çš„1.08å€ï¼Œç‰›å¸‚
        else:
            return "ç‰›å¸‚"
    elif pct_change > 0.05:
        # åŠ¨é‡æ­£ä¸”è¾ƒé«˜ï¼Œç‰›å¸‚
        if momentum > 0.05 and last_close > ma20 * 1.08:
            return "ç‰›å¸‚"
        # åŠ¨é‡è´Ÿä¸”è¾ƒä½ï¼Œç†Šå¸‚
        elif momentum < -0.05 or last_close < ma20 * 0.92:
            return "ç†Šå¸‚"
    
    # é»˜è®¤éœ‡è¡å¸‚
    return "éœ‡è¡å¸‚"





def get_valid_trade_date(
        api_func, 
        date_field: str, 
        base_date: Optional[datetime] = None, 
        max_back_days: int = 5, 
        **api_kwargs
    ) -> Optional[str]:
    """
    ä¿®å¤ç‚¹1ï¼šç¡®ä¿è¿”å›ç»Ÿä¸€æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²
    æ–°å¢æœ‰æ•ˆæ€§æ£€æŸ¥é€»è¾‘
    """
    if appy.IS_BACKTEST:
        return base_date.strftime('%Y%m%d') 
    base_date = base_date or datetime.today()
    for delta in range(max_back_days + 1):
        current_date = base_date - timedelta(days=delta)
        d = current_date.strftime('%Y%m%d')
        df = safe_api_call(api_func, **api_kwargs, **{date_field: d})
        
        # æ–°å¢æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
        if not df.empty and 'ts_code' in df.columns and len(df['ts_code'].unique()) > 10:
            logger.info(f"âœ… éªŒè¯æœ‰æ•ˆäº¤æ˜“æ—¥: {d} | åŒ…å«è‚¡ç¥¨æ•°: {len(df)}")
            return d
    logger.error(f"âŒ æœªæ‰¾åˆ°æœ‰æ•ˆäº¤æ˜“æ—¥ï¼ˆæœ€è¿‘ {max_back_days} å¤©ï¼‰")
    return None


# ===== å…¨å±€å®šä¹‰ï¼šQueryç±»æ¥å£åå• =====
QUERY_INTERFACE_NAMES = [
    # åŸºç¡€è¡Œæƒ…ç±»
    'daily', 'daily_basic', 'moneyflow', 
    # è´¢åŠ¡æŒ‡æ ‡ç±»
    'fina_indicator_vip', 'express', 'forecast',
    # å¸‚åœºå‚è€ƒç±»
    'stk_limit', 'limit_list_d', 'suspend_d', 'block_trade',
    # è‚¡ä¸œè‚¡æƒç±»
    'stk_holdernumber', 'stk_holdertrade', 'pledge_stat', 'pledge_detail',
    # åŸºç¡€ä¿¡æ¯ç±» 
    'stock_basic', 'concept_detail', 'index_weight', 'index_member',
    # æŒ‡æ•°æ•°æ®ç±»
    'index_daily',
    # ç‰¹è‰²æ•°æ®ç±»
    'share_float', 'anns_d',
    # åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æ•°æ®ç±»ï¼ˆæ–°æ·»åŠ çš„æ¥å£ï¼‰
    'ths_index'  # åŒèŠ±é¡ºæ¦‚å¿µæ¿å—æ¥å£
]

def safe_api_call(func, *args, retries=3, delay=2, **kwargs):
    """ å°è£…æ¥å£è°ƒç”¨ï¼Œè‡ªåŠ¨é€‰æ‹©é™é€Ÿå™¨ï¼Œå¤„ç†å¼‚å¸¸ï¼Œä¿è¯è¿”å› DataFrame """
    
    # å¦‚æœ func æ˜¯ functools.partial å¯¹è±¡ï¼Œè·å–å…¶åŸå§‹å‡½æ•°
    if isinstance(func, functools.partial):
        api_name = func.args[0] if func.args else kwargs.get('api_name')  # è·å– api_name
    else:
        api_name = func.__name__  # è·å–å‡½æ•°åç§°ä½œä¸º API å
    
    # ç¡®ä¿ api_name ä¸ API_CONFIG ä¸­çš„é”®ä¸€è‡´
    if api_name not in API_CONFIG:
        api_name = kwargs.get('api_name', api_name)  # å¦‚æœ API_CONFIG ä¸­æ²¡æœ‰è¯¥æ¥å£ï¼Œä½¿ç”¨ kwargs ä¸­ä¼ é€’çš„ api_name
    
    # è¯¦ç»†æ—¥å¿—è®°å½•
    logger.debug(f"å‡†å¤‡è°ƒç”¨æ¥å£: {api_name} å‚æ•°: {kwargs}")

    # é™é€Ÿå™¨
    if api_name in QUERY_INTERFACE_NAMES or 'query' in api_name.lower():
        query_rate_limiter.wait(interface_type="QUERYæ¥å£")
        logger.debug(f"âœ… å·²åº”ç”¨QUERYæ¥å£é™é€Ÿ: {api_name}")
    else:
        normal_rate_limiter.wait(interface_type="æ™®é€šæ¥å£")
        logger.debug(f"âœ… å·²åº”ç”¨æ™®é€šæ¥å£é™é€Ÿ: {api_name}")

    # è·å–APIé…ç½®ä¿¡æ¯
    api_config = API_CONFIG.get(api_name, {})  # è·å–æ¥å£é…ç½®ï¼Œé»˜è®¤ç©ºå­—å…¸
    fields = api_config.get('fields', [])       # è·å–å­—æ®µåˆ—è¡¨ï¼Œé»˜è®¤ç©ºåˆ—è¡¨
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸ºæ¥å£æ·»åŠ  trade_date å‚æ•°
    if 'trade_date' in fields:
        kwargs['trade_date'] = appy.CURRENT_TRADE_DATE
        logger.debug(f"âœ… ä¸º {api_name} æ·»åŠ  trade_date å‚æ•°: {appy.CURRENT_TRADE_DATE}")
    else:
        logger.debug(f"â© {api_name} æœªé…ç½® trade_date å­—æ®µ")
    
    # å°è¯•è°ƒç”¨æ¥å£ï¼Œæœ€å¤šé‡è¯• retries æ¬¡
    for attempt in range(1, retries + 1):
        try:
            result = func(*args, **kwargs)
            if isinstance(result, pd.DataFrame):
                logger.debug(f"âœ… æ¥å£è°ƒç”¨æˆåŠŸ: {api_name} è¿”å› {len(result)} è¡Œæ•°æ®")
                return result
            else:
                # è¿”å›ç±»å‹ä¸æ˜¯ DataFrame æ—¶å¤„ç†
                logger.warning(f"âš ï¸ {api_name} è¿”å›é DataFrame ç±»å‹: {type(result)}")
                # å¦‚æœè¿”å›ä¸æ˜¯ DataFrameï¼Œå¯ä»¥è¿”å›ç©º DataFrame æˆ–åšå…¶ä»–å¤„ç†
                return pd.DataFrame()  
        except Exception as e:
            error_msg = str(e)
            if "è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å" in error_msg or "parameter" in error_msg.lower():
                logger.error(f"âŒ {api_name} å‚æ•°é”™è¯¯æˆ–æ¥å£åé”™è¯¯: {error_msg}")
                break
            logger.warning(f"âš ï¸ è°ƒç”¨ {api_name} å¤±è´¥ï¼ˆç¬¬{attempt}æ¬¡ï¼‰: {error_msg}")
            time.sleep(delay * attempt)  # æŒ‡æ•°é€€é¿

    logger.error(f"ğŸš« è°ƒç”¨ {api_name} å®Œå…¨å¤±è´¥ï¼Œè¿”å›ç©º DataFrame")
    return pd.DataFrame()  # å¦‚æœè°ƒç”¨å¤±è´¥ï¼Œè¿”å›ç©º DataFrame









# ===== é…ç½®æ—¥å¿—ç³»ç»Ÿ =====
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# ===== ç³»ç»Ÿé…ç½® =====
class Config:
    MAX_STOCKS_TO_ANALYZE = 5500         # ä¿æŒä¸å˜ï¼Œæœ€å¤§åˆ†æè‚¡ç¥¨æ•°é‡
    MIN_DATA_DAYS = 30

    
    POINTS = 10000
    MAX_CALLS_PER_MIN = 1000             # æ¯åˆ†é’Ÿ1000æ¬¡
    MAX_WORKERS = 24                 


# ===== åŠ¨æ€é™é€Ÿæ§åˆ¶å™¨ =====
class RateLimiter:
    def __init__(self, max_calls: int, period: int):
        self.max_calls = max_calls
        self.period = period
        self.lock = threading.Lock()
        self.calls = []

    def wait(self, interface_type=None) -> None:
        # æ™ºèƒ½åˆ¤æ–­æ¥å£ç±»å‹
        if interface_type is None:
            if self.max_calls == 1000:
                interface_type = "QUERYæ¥å£"
            elif self.max_calls == 1000:
                interface_type = "æ™®é€šæ¥å£"
            else:
                interface_type = "æ¥å£"

        with self.lock:
            now = time.time()
            self.calls = [call for call in self.calls if now - call < self.period]

            if len(self.calls) >= self.max_calls:
                sleep_time = self.period - (now - self.calls[0])
                sleep_time = max(sleep_time, 0)
                if sleep_time > 0:
                    logger.info(f"â³ [{interface_type}] é™é€Ÿä¸­ï¼šç­‰å¾… {sleep_time:.1f}s  (é™é¢ {self.max_calls}/{self.period}s)")
                    time.sleep(sleep_time)

            self.calls.append(time.time())


# åˆå§‹åŒ–ä¸¤ä¸ªé™é€Ÿå™¨
normal_rate_limiter = RateLimiter(1000, 60)
query_rate_limiter = RateLimiter(1000, 60)





# ===== API é…ç½® =====


# éªŒè¯é…ç½®
AppConfig.validate()
AppConfig.create_dirs()

# åˆå§‹åŒ–API
ts.set_token(AppConfig.TUSHARE_TOKEN)
pro = ts.pro_api()
DEEPSEEK_API_KEY = AppConfig.DEEPSEEK_API_KEY
# ===== DeepSeek API äº¤äº’ç±» =====
class DeepSeekAPI:
    @staticmethod
    def call_deepseek(prompt: str) -> str:
        """è°ƒç”¨DeepSeek APIè·å–ç­–ç•¥åˆ†æ"""
        try:
            headers = {
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æAIåŠ©æ‰‹ã€‚è¯·ä»ç”¨æˆ·è¾“å…¥ä¸­è¯†åˆ«è‚¡ç¥¨æŠ€æœ¯åˆ†æç­–ç•¥ï¼Œ"
                                  "åªè¿”å›JSONæ ¼å¼çš„ç­–ç•¥åˆ—è¡¨å’Œè§£é‡Šã€‚"
                    },
                    {
                        "role": "user",
                        "content": f"ä»ä»¥ä¸‹æ–‡æœ¬ä¸­è¯†åˆ«è‚¡ç¥¨æŠ€æœ¯åˆ†æç­–ç•¥: {prompt}"
                    }
                ],
                "temperature": 0.3
            }
            
            response = requests.post(
                "https://api.deepseek.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]
        except Exception as e:
            logger.error(f"è°ƒç”¨DeepSeek APIå¤±è´¥: {str(e)}")
            return ""

    @staticmethod
    def parse_strategies(response: str) -> Tuple[List[str], str, Dict[str, int]]:
        """è§£æDeepSeek APIè¿”å›çš„ç­–ç•¥"""
        try:
            # ç®€å•å®ç° - å®é™…åº”æ ¹æ®APIè¿”å›æ ¼å¼è°ƒæ•´
            if not response:
                return [], "æ— æ³•è§£æç­–ç•¥", {}
                
            # è¿™é‡Œå‡è®¾APIè¿”å›çš„æ˜¯ç­–ç•¥åˆ—è¡¨
            # å®é™…å®ç°éœ€è¦æ ¹æ®APIå®é™…è¿”å›æ ¼å¼è°ƒæ•´
            strategies = []
            explanation = "è¯†åˆ«åˆ°çš„ç­–ç•¥:\n"
            custom_weights = {}
            
            for strategy in STRATEGY_WEIGHTS.keys():
                if strategy in response:
                    strategies.append(strategy)
                    explanation += f"- {strategy}\n"
                    custom_weights[strategy] = STRATEGY_WEIGHTS[strategy]
            
            return strategies, explanation, custom_weights
        except Exception as e:
            logger.error(f"è§£æç­–ç•¥å¤±è´¥: {str(e)}")
            return [], "è§£æç­–ç•¥æ—¶å‡ºé”™", {}
# ===== è‚¡ç¥¨åˆ†ææ ¸å¿ƒç±» =====
class StockAnalyzer:
    pro = ts.pro_api(AppConfig.TUSHARE_TOKEN) 
    @staticmethod
    def get_valid_daily_data(
        api_func: Any,
        fields: str,
        max_days_back: int = 10,
        extra_kwargs: Optional[Dict[str, Any]] = None,
        base_date: Optional[datetime] = None   # â­ æ–°å¢å‚æ•°
    ) -> Tuple[pd.DataFrame, Optional[str]]:
        extra_kwargs = extra_kwargs or {}
        func_name = getattr(api_func, '__name__', None)
        if func_name is None and hasattr(api_func, 'func'):
            func_name = getattr(api_func.func, '__name__', str(api_func))
        if func_name is None:
            func_name = str(api_func)

        valid_date = get_valid_trade_date(
            api_func,
            date_field='trade_date',
            base_date=base_date or datetime.today(),
            max_back_days=max_days_back,
            fields=fields,
            **extra_kwargs
        )
        if valid_date is None:
            logger.error(f"âŒ è¿ç»­ {max_days_back} å¤©æ— æœ‰æ•ˆæ•°æ® ({func_name})")
            return pd.DataFrame(), None

        df = safe_api_call(
            api_func,
            trade_date=valid_date,
            fields=fields,
            **extra_kwargs
        )
        if df.empty:
            logger.error(f"âŒ æ‰¾åˆ°äº¤æ˜“æ—¥ {valid_date}ï¼Œä½†æ‹‰å–æ•°æ®ä»ä¸ºç©º ({func_name})")
            return pd.DataFrame(), None

        logger.info(f"âœ… æˆåŠŸè·å– {valid_date} çš„æ•°æ® ({func_name})")
        return df, valid_date

    @staticmethod
    def get_single_stock_info(ts_code: str) -> Optional[Dict]:
        try:
            if not ts_code.endswith(('.SH', '.SZ')):
                ts_code = f"{ts_code}.SZ" if ts_code.startswith(('00', '30')) else f"{ts_code}.SH"
            basic = safe_api_call(pro.stock_basic, ts_code=ts_code, fields='ts_code,name,industry,list_date,market')
            daily = safe_api_call(pro.daily, ts_code=ts_code,
                                  start_date=(datetime.now() - timedelta(days=30)).strftime('%Y%m%d'),
                                  end_date=datetime.now().strftime('%Y%m%d'))
            if basic.empty or daily.empty:
                return None
            daily = daily.sort_values('trade_date')
            daily.index = pd.to_datetime(daily['trade_date'])

            indicators, _ = StockAnalyzer.calculate_technical_indicators(daily)
            latest_signals = {strategy: bool(values.iloc[-1]) for strategy, values in indicators.items()}

            return {
                'basic_info': basic.iloc[0].to_dict(),
                'price_info': daily.iloc[-1].to_dict(),
                'technical_signals': latest_signals
            }
        except Exception as e:
            logger.error(f"æŸ¥è¯¢è‚¡ç¥¨ {ts_code} å¤±è´¥: {str(e)}")
            return None

    @staticmethod
    def get_stock_list(
        selected_markets: Tuple[str, ...], 
        max_count: Optional[int] = None, 
        strategy_mode: str = "é»˜è®¤", 
        trade_date: Optional[str] = None
    ) -> Tuple[List[Tuple[str, str]], Dict[str, float]]:
        """ä¼˜åŒ–ç‚¹ï¼š
        1. æ‰¹é‡è·å–æ‰€æœ‰æŒ‡æ•°æˆåˆ†è‚¡ï¼ˆå‡å°‘APIè°ƒç”¨æ¬¡æ•°ï¼‰
        2. åˆå¹¶è¡Œæƒ…æ•°æ®æŸ¥è¯¢ï¼ˆåŸ2æ¬¡â†’1æ¬¡ï¼‰
        3. ä¼˜åŒ–å¸‚åœºç­›é€‰é€»è¾‘ï¼ˆå‡å°‘å¾ªç¯æ¬¡æ•°ï¼‰
        4. æ·»åŠ LRUç¼“å­˜è£…é¥°å™¨
        """
        from market_utils import get_market_status
        try:
            # 1. è·å–å…¨é‡è‚¡ç¥¨æ•°æ®ï¼ˆå•æ¬¡APIè°ƒç”¨ï¼‰
            df = safe_api_call(
                pro.stock_basic,
                exchange='',
                list_status='L',
                fields='ts_code,name,market,list_date,industry'
            )
            if df.empty:
                logger.error("âŒ è·å–è‚¡ç¥¨åŸºç¡€æ•°æ®å¤±è´¥")
                return [], {}

            # 2. è·å–åˆå¹¶åçš„è¡Œæƒ…æ•°æ®ï¼ˆå•æ¬¡APIè°ƒç”¨ï¼‰
            base_date = datetime.strptime(trade_date, '%Y%m%d') if trade_date else None
            valid_date = get_valid_trade_date(
                pro.daily,
                date_field='trade_date',
                base_date=base_date,
                max_back_days=5
            )
            if not valid_date:
                logger.error("âŒ æ— æ³•è·å–æœ‰æ•ˆäº¤æ˜“æ—¥")
                return [], {}

            # æ‰¹é‡è·å–æ‰€æœ‰è¡Œæƒ…æ•°æ®
            daily_data = safe_api_call(
                pro.daily,
                trade_date=valid_date,
                fields='ts_code,open,close,high,low,pct_chg,vol,amount'  # ç¡®ä¿åŒ…å«openå­—æ®µç”¨äºåˆ¤æ–­é˜³çº¿
            )
            daily_basic = safe_api_call(
                pro.daily_basic,
                trade_date=valid_date,
                fields='ts_code,total_mv,turnover_rate'
            )

            # 3. åˆå¹¶æ•°æ®
            df = df.merge(daily_basic, on='ts_code', how='left').merge(
                daily_data, on='ts_code', how='left'
            )
            total_before_filter = len(df)

            # è·å–å½“å¤©åœç‰Œè‚¡ç¥¨åˆ—è¡¨
            suspend_df = pro.suspend_d(suspend_type='S', trade_date=valid_date)
            suspend_stocks = set(suspend_df['ts_code'])  # åœç‰Œè‚¡ç¥¨çš„ TS ä»£ç é›†åˆ

            # ç¡®ä¿åœç‰Œè‚¡ç¥¨ä¿¡æ¯æ­£ç¡®
            logger.info(f"åœç‰Œè‚¡ç¥¨æ•°ï¼š{len(suspend_stocks)}")  # è¾“å‡ºåœç‰Œè‚¡ç¥¨çš„æ•°é‡ï¼Œä¾¿äºè°ƒè¯•
            logger.info(f"åœç‰Œè‚¡ç¥¨ç¤ºä¾‹ï¼š{list(suspend_stocks)[:5]}")  # è¾“å‡ºä¸€äº›åœç‰Œè‚¡ç¥¨ç¤ºä¾‹ï¼ŒæŸ¥çœ‹æ•°æ®æ˜¯å¦æ­£ç¡®

            # 4. ç­›é™¤åœç‰Œè‚¡ç¥¨
            df = df[~df['ts_code'].isin(suspend_stocks)]
            logger.info(f"ğŸš« ç­›é™¤åœç‰Œè‚¡ï¼š{total_before_filter} âœ {len(df)}")

            # 5. å¤„ç†å¸‚åœº/æ¿å—é€‰æ‹©
            index_map = {
                "ä¸­è¯500": "000905.SH", "æ²ªæ·±300": "000300.SH", "ä¸Šè¯50": "000016.SH",
                "ä¸­è¯ç™½é…’": "399997.SZ", "ä¸­è¯æ¶ˆè´¹": "000932.SH", "ç§‘åˆ›50": "000688.SH",
                "æ·±è¯100": "399330.SZ", "åŒ—è¯50": "899050.BJ", "å›½è¯ETF": "399380.SZ"
            }

            # æ‰¹é‡è·å–æ‰€æœ‰éœ€è¦çš„æŒ‡æ•°æˆåˆ†è‚¡
            needed_indexes = [index_map[m] for m in selected_markets if m in index_map]
            index_members = {}  # å¦‚æœä¸éœ€è¦ `_get_index_members`ï¼Œç›´æ¥ä½¿ç”¨è¿™ä¸ªç©ºå­—å…¸

            # æ„å»ºç­›é€‰æ¡ä»¶
            market_filters = []
            hs300_set = set()

            for m in selected_markets:
                if m in ["ä¸»æ¿", "åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿"]:
                    market_filters.append(df['market'] == m)
                elif m in index_map:
                    codes = index_members.get(index_map[m], set())
                    if m == "æ²ªæ·±300":
                        hs300_set = codes
                    market_filters.append(df['ts_code'].isin(codes))

            if market_filters:
                df = df[np.logical_or.reduce(market_filters)]
            else:
                logger.warning("âš ï¸ æœªåº”ç”¨ä»»ä½•å¸‚åœºç­›é€‰æ¡ä»¶")

            # 6. æ•°å€¼è½¬æ¢
            for col in ['close', 'open', 'high', 'low', 'total_mv', 'turnover_rate', 'pct_chg']:
                if col not in df.columns:
                    logger.warning(f"âš ï¸ åˆ— {col} ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†è¯¥åˆ—")
                    continue
                df[col] = pd.to_numeric(df[col], errors='coerce')

            # 7. ç­›é€‰æ¡ä»¶é…ç½®
            mode_config = {
                "æ¿€è¿›å‹": {"mv": (100_000, 3_000_000), "turnover": (1, 35), "pct": (-6, 12), "pe": (15, 45), "pb": (0.8, 8), "roe": 6},
                "ç¨³å¥å‹": {"mv": (300_000, 6_000_000), "turnover": (0.5, 20), "pct": (-4, 8), "pe": (8, 35), "pb": (1.0, 5), "roe": 10},
                "ç©¿çº¿å‹": {"mv": (50_000, 10_000_000), "turnover": (0.2, 50), "pct": (-20, 30), "pe": (0, 200), "pb": (0.1, 20), "roe": 0},  # æ–°å¢ç©¿çº¿å‹ç­–ç•¥å‚æ•°
                "é»˜è®¤":   {"mv": (300_000, 3_000_000), "turnover": (1.5, 25), "pct": (-9, 28), "pe": (5, 50), "pb": (0.8, 8), "roe": 8}
            }
            cfg = mode_config.get(strategy_mode, mode_config["é»˜è®¤"])

            # 8. æ–°å¢è·å–åŸºæœ¬é¢æ•°æ®å¹¶è¿›è¡Œç­›é€‰
            fundamental_basic = safe_api_call(
                pro.daily_basic,
                trade_date=valid_date,
                fields='ts_code,pe_ttm,pb'
            )

            # è·å– fina_indicator_vip ä¸­çš„å‡€èµ„äº§æ”¶ç›Šç‡ï¼ˆroeï¼‰
            fundamental_fina = safe_api_call(
                pro.fina_indicator_vip,
                trade_date=valid_date,
                fields='ts_code,roe'
            )

            # åˆå¹¶æ•°æ®ï¼Œä½¿ç”¨ ts_code ä½œä¸ºè¿æ¥é”®
            df = df.merge(fundamental_basic, on='ts_code', how='left')
            df = df.merge(fundamental_fina, on='ts_code', how='left')

            # 9. æ·»åŠ åŸºæœ¬é¢ç­›é€‰æ¡ä»¶ï¼šå¸‚ç›ˆç‡ã€å‡€èµ„äº§æ”¶ç›Šç‡ã€å‡€èµ„äº§æ”¶ç›Šç‡ç­‰
            filtered = df[
                (df['pe_ttm'].between(cfg['pe'][0], cfg['pe'][1])) &  # åŠ¨æ€å¸‚ç›ˆç‡èŒƒå›´
                (df['pb'].between(cfg['pb'][0], cfg['pb'][1])) &  # åŠ¨æ€å¸‚å‡€ç‡èŒƒå›´
                (df['roe'] >= cfg['roe'])  # åŠ¨æ€ROEæ¡ä»¶
            ]
            logger.info(f"ğŸ“Š åŸºæœ¬é¢è¿‡æ»¤ï¼š{len(filtered)}")

            # 10. æ·»åŠ ç©¿çº¿å‹ç‰¹æ®Šç­›é€‰ï¼ˆæ›´ä¸¥æ ¼ç‰ˆæœ¬ï¼‰
            if strategy_mode == "ç©¿çº¿å‹":
                # è®¡ç®—éœ€è¦çš„å†å²æ—¥æœŸ
                end_date = datetime.strptime(valid_date, '%Y%m%d')
                start_date = (end_date - timedelta(days=30)).strftime('%Y%m%d')  # è·å–30å¤©çš„æ•°æ®

                # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
                filtered_stats = {
                    "å½“æ—¥æ¶¨åœè¿‡æ»¤": 0,
                    "è¿ç»­æ¶¨åœè¿‡æ»¤": 0,
                    "æ¶¨å¹…è¿‡å¤§è¿‡æ»¤": 0,
                    "é‡èƒ½ä¸è¶³è¿‡æ»¤": 0,
                    "T+1å‹å¥½å½¢æ€": 0
                }

                # åˆå§‹åŒ–
                not_overbought_stocks = []
                limit_up_stocks = []  # ä¸“é—¨è®°å½•æ¶¨åœè‚¡ç¥¨
                t1_quality_stocks = []  # T+1äº¤æ˜“è´¨é‡é«˜çš„è‚¡ç¥¨

                # åˆ†æ‰¹å¤„ç†è‚¡ç¥¨ï¼Œæ¯æ‰¹æœ€å¤š100æ”¯
                batch_size = 100
                stock_codes = filtered['ts_code'].unique()[:max_count if max_count else len(filtered)]  # é™åˆ¶æ•°é‡

                logger.info(f"ğŸ“Š ç©¿çº¿å‹ç­–ç•¥ï¼šå¼€å§‹ç­›é€‰ {len(stock_codes)} æ”¯è‚¡ç¥¨")

                # å­˜å‚¨æœ€ç»ˆè¿‡æ»¤ç»“æœ
                filtered_stocks = []

                for i in range(0, len(stock_codes), batch_size):
                    batch_codes = stock_codes[i:i + batch_size]
                    batch_str = ','.join(batch_codes)  # å¤šä¸ªè‚¡ç¥¨ç”¨é€—å·åˆ†éš”

                    try:
                        # ä½¿ç”¨ pro.daily è·å–æ‰¹é‡è‚¡ç¥¨çš„å†å²æ•°æ®
                        hist_daily = pro.daily(
                            ts_code=batch_str,
                            start_date=start_date,
                            end_date=valid_date
                        )

                        if hist_daily is not None and not hist_daily.empty:
                            # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„å¤„ç†
                            for ts_code in batch_codes:
                                stock_data = hist_daily[hist_daily['ts_code'] == ts_code].sort_values('trade_date')

                                if len(stock_data) >= 5:
                                    try:
                                        # è®¡ç®—ç´¯è®¡æ¶¨å¹…
                                        pct_3d = stock_data['pct_chg'].tail(3).sum()
                                        pct_5d = stock_data['pct_chg'].tail(5).sum()
                                        pct_10d = stock_data['pct_chg'].tail(10).sum() if len(stock_data) >= 10 else pct_5d
                                        pct_20d = stock_data['pct_chg'].tail(20).sum() if len(stock_data) >= 20 else pct_10d
                                        pct_30d = stock_data['pct_chg'].sum()
                                        pct_chg_today = stock_data['pct_chg'].iloc[-1]  # å½“æ—¥æ¶¨å¹…

                                        # è®¡ç®—å•æ—¥æœ€å¤§æ¶¨å¹…
                                        max_single_day = stock_data['pct_chg'].tail(10).max() if len(stock_data) >= 10 else stock_data['pct_chg'].max()

                                        # ğŸ” æˆäº¤é¢é‡èƒ½è¿‡æ»¤ + æ¶¨åœæ—¥è±å…
                                        avg_amount = stock_data['amount'].tail(5).mean()
                                        curr_amount = stock_data['amount'].iloc[-1]
                                        vol_pass = (curr_amount > 1.5 * avg_amount) or (pct_chg_today >= 9.8)  # æ¶¨åœæ—¥è±å…

                                        # æ£€æŸ¥æ˜¯å¦æœ‰æ¶¨åœ
                                        has_limit_up = (stock_data['pct_chg'] >= 9.5).any()
                                        limit_up_count = (stock_data['pct_chg'] >= 9.5).sum()
                                        
                                        # æ¡ä»¶åˆ†æ”¯ï¼šæœ‰æ¶¨åœçš„èµ°ç‹¬ç«‹åˆ†æ”¯åˆ¤æ–­
                                        if has_limit_up:
                                            # è®°å½•æ¶¨åœæ—¥æœŸ
                                            limit_up_dates = stock_data[stock_data['pct_chg'] >= 9.5]['trade_date'].tolist()
                                            latest_limit_up = max(limit_up_dates) if limit_up_dates else None
                                            
                                            # æ£€æŸ¥æ˜¯å¦å½“å¤©æ¶¨åœ - T+1æ ¸å¿ƒä¼˜åŒ–ç‚¹
                                            if latest_limit_up == valid_date:
                                                filtered_stats["å½“æ—¥æ¶¨åœè¿‡æ»¤"] += 1
                                                logger.debug(f"{ts_code}: å½“æ—¥æ¶¨åœï¼Œä¸é€‚åˆT+1äº¤æ˜“ï¼Œè·³è¿‡")
                                                continue  # è·³è¿‡å½“å¤©æ¶¨åœçš„è‚¡ç¥¨
                                            
                                            # æ£€æŸ¥æ˜¯å¦è¿ç»­æ¶¨åœ
                                            is_consecutive_limit = False
                                            for j in range(1, len(stock_data) - 1):
                                                if (stock_data['pct_chg'].iloc[-j] >= 9.5 and 
                                                    stock_data['pct_chg'].iloc[-(j+1)] >= 9.5):
                                                    is_consecutive_limit = True
                                                    break
                                            
                                            if is_consecutive_limit:
                                                filtered_stats["è¿ç»­æ¶¨åœè¿‡æ»¤"] += 1
                                                logger.debug(f"{ts_code}: è¿ç»­æ¶¨åœï¼Œæ³¢åŠ¨é£é™©è¾ƒå¤§ï¼Œè·³è¿‡")
                                                continue  # è·³è¿‡è¿ç»­æ¶¨åœçš„è‚¡ç¥¨
                                            
                                            # æ˜¨æ—¥æ¶¨åœç‰¹æ®Šå¤„ç† - T+1ä¼˜åŒ–ç‚¹
                                            days_since_last_limit = (end_date - datetime.strptime(latest_limit_up, '%Y%m%d')).days
                                            if days_since_last_limit == 1:
                                                # æ˜¨æ—¥æ¶¨åœè‚¡å¦‚æœä¸ç¬¦åˆç‰¹å®šæ¡ä»¶åˆ™è·³è¿‡ï¼Œé™ä½é«˜å¼€é£é™©
                                                if pct_chg_today < -2:  # ä»Šæ—¥æœ‰æ˜æ˜¾å›è°ƒå¯ä»¥è€ƒè™‘
                                                    # åˆ†æKçº¿å½¢æ€åˆ¤æ–­æ¬¡æ—¥æ˜¯å¦é€‚åˆT+1
                                                    if 'open' in stock_data.columns and 'close' in stock_data.columns:
                                                        last_open = stock_data['open'].iloc[-1]
                                                        last_close = stock_data['close'].iloc[-1]
                                                        last_high = stock_data['high'].iloc[-1]
                                                        last_low = stock_data['low'].iloc[-1]
                                                        
                                                        # ä¸‹å½±çº¿é•¿+æ”¶é˜³ï¼Œæ”¯æ’‘ç¡®è®¤ï¼Œé€‚åˆT+1
                                                        has_support = (last_close > last_open) and ((last_open - last_low) / (last_high - last_low + 0.001) > 0.3)
                                                        
                                                        if not has_support:
                                                            logger.debug(f"{ts_code}: æ˜¨æ—¥æ¶¨åœä»Šæ—¥å›è°ƒï¼Œä½†ç¼ºä¹æ”¯æ’‘ç¡®è®¤ï¼ŒT+1é£é™©è¾ƒé«˜")
                                                            continue
                                            
                                            # æ¶¨åœè‚¡ç‰¹æ®Šæ¡ä»¶ï¼šä¿ç•™æœ‰1-3æ¬¡æ¶¨åœä¸”é‡èƒ½æ¡ä»¶æ»¡è¶³
                                            should_keep = (limit_up_count <= 3 and vol_pass)
                                            
                                            if should_keep:
                                                not_overbought_stocks.append(ts_code)
                                                limit_up_stocks.append((ts_code, limit_up_count, latest_limit_up))
                                                logger.debug(f"{ts_code}: æœ‰{limit_up_count}æ¬¡æ¶¨åœ, æœ€è¿‘æ¶¨åœæ—¥æœŸ:{latest_limit_up}, selected=True")
                                        else:
                                            # æ— æ¶¨åœè‚¡èµ°æ›´ä¸¥æ ¼çš„åˆ¤æ–­é€»è¾‘ - T+1ä¼˜åŒ–ç‚¹
                                            is_not_overbought = (
                                                pct_3d < 15 and        # ä»20%é™è‡³15%
                                                pct_5d < 10 and       
                                                pct_10d < 15 and
                                                pct_20d < 20 and
                                                pct_30d < 30 and
                                                max_single_day < 6 and  # ä»7%é™è‡³6%
                                                pct_chg_today < 5      # æ–°å¢å½“æ—¥æ¶¨å¹…é™åˆ¶
                                            )
                                            
                                            if not is_not_overbought:
                                                filtered_stats["æ¶¨å¹…è¿‡å¤§è¿‡æ»¤"] += 1
                                                continue
                                            
                                            # é‡èƒ½ä¸è¶³è¿‡æ»¤
                                            if not vol_pass:
                                                filtered_stats["é‡èƒ½ä¸è¶³è¿‡æ»¤"] += 1
                                                continue
                                            
                                            recent_pullback = stock_data['pct_chg'].tail(5).min() < -3
                                            
                                            # åˆ†æT+1å‹å¥½å½¢æ€ - T+1ä¼˜åŒ–ç‚¹
                                            if 'open' in stock_data.columns and 'close' in stock_data.columns:
                                                last_open = stock_data['open'].iloc[-1]
                                                last_close = stock_data['close'].iloc[-1]
                                                last_high = stock_data['high'].iloc[-1]
                                                last_low = stock_data['low'].iloc[-1]
                                                
                                                # è®¡ç®—ä¸‹å½±çº¿æ¯”ä¾‹
                                                min_price = min(last_open, last_close)
                                                lower_shadow_ratio = (min_price - last_low) / (last_high - last_low + 0.001)
                                                
                                                # å®ä½“ç›¸å¯¹å¤§å°
                                                body_size = abs(last_close - last_open) / (last_high - last_low + 0.001)
                                                
                                                # æ˜¯å¦æ”¶é˜³
                                                is_yang = last_close > last_open
                                                
                                                # T+1é«˜èƒœç‡å½¢æ€åˆ¤æ–­
                                                t1_favorable = (
                                                    (lower_shadow_ratio > 0.3 and is_yang) or  # å¸¦é•¿ä¸‹å½±é˜³çº¿
                                                    (body_size > 0.7 and is_yang) or           # å¤§å®ä½“é˜³çº¿
                                                    (is_yang and last_close > last_high * 0.98)  # æ”¶ç›˜æ¥è¿‘æœ€é«˜ä»·
                                                )
                                                
                                                if t1_favorable:
                                                    filtered_stats["T+1å‹å¥½å½¢æ€"] += 1
                                                    t1_quality_stocks.append(ts_code)
                                            
                                            if (is_not_overbought or (recent_pullback and pct_5d < 20)):
                                                not_overbought_stocks.append(ts_code)
                                                
                                            if len(not_overbought_stocks) <= 20:
                                                logger.debug(f"{ts_code}: 3d={pct_3d:.1f}%, 5d={pct_5d:.1f}%, "
                                                             f"10d={pct_10d:.1f}%, 20d={pct_20d:.1f}%, "
                                                             f"max_single={max_single_day:.1f}%, vol_pass={vol_pass}, "
                                                             f"pullback={recent_pullback}, selected={ts_code in not_overbought_stocks}")

                                    except Exception as e:
                                        logger.warning(f"å¤„ç†{ts_code}æ—¶å‡ºé”™: {e}")
                        else:
                            logger.debug(f"æ‰¹æ¬¡ {i // batch_size + 1} æ— æ•°æ®è¿”å›")

                    except Exception as e:
                        logger.warning(f"è·å–å†å²æ•°æ®å¤±è´¥ï¼ˆæ‰¹æ¬¡ {i // batch_size + 1}ï¼‰: {e}")
                        for ts_code in batch_codes:
                            stock_row = filtered[filtered['ts_code'] == ts_code]
                            if not stock_row.empty:
                                if stock_row.iloc[0]['pct_chg'] <= 5:
                                    not_overbought_stocks.append(ts_code)

                # è®°å½•æ¶¨åœè‚¡ç¥¨æƒ…å†µ
                if limit_up_stocks:
                    logger.info(f"ğŸš€ æ‰¾åˆ°{len(limit_up_stocks)}æ”¯è¿‘æœŸæœ‰æ¶¨åœçš„è‚¡ç¥¨")
                    for ts_code, count, latest_date in limit_up_stocks[:10]:  # åªæ˜¾ç¤ºå‰10æ”¯
                        logger.info(f"  - {ts_code}: {count}æ¬¡æ¶¨åœ, æœ€è¿‘æ¶¨åœ: {latest_date}")
                else:
                    logger.info("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¶¨åœè‚¡ç¥¨")
                
                # è¾“å‡ºT+1ç­›é€‰ç»Ÿè®¡
                logger.info(f"ğŸ“Š ç©¿çº¿å‹T+1ç­›é€‰ç»Ÿè®¡: {filtered_stats}")
                
                # ä¼˜å…ˆè€ƒè™‘T+1å‹å¥½å½¢æ€çš„è‚¡ç¥¨
                if t1_quality_stocks:
                    logger.info(f"ğŸŒŸ æ‰¾åˆ°{len(t1_quality_stocks)}æ”¯T+1å‹å¥½å½¢æ€è‚¡ç¥¨")
                    # ç¡®ä¿è¿™äº›è‚¡ç¥¨è¢«ä¿ç•™
                    for ts_code in t1_quality_stocks:
                        if ts_code not in not_overbought_stocks:
                            not_overbought_stocks.append(ts_code)

                # è¿‡æ»¤å‡ºæ¶¨å¹…é€‚ä¸­çš„è‚¡ç¥¨
                filtered = filtered.copy()
                filtered['is_not_overbought'] = filtered['ts_code'].isin(not_overbought_stocks)
                filtered_before = len(filtered)
                filtered = filtered[filtered['is_not_overbought']]

                logger.info(f"ğŸ“ˆ æ¶¨å¹…ç­›é€‰ï¼š{filtered_before} â†’ {len(filtered)} æ”¯ï¼ˆè¿‡æ»¤{filtered_before - len(filtered)}æ”¯ï¼‰")

                if len(filtered) < 20:
                    logger.warning("âš ï¸ ç­›é€‰åè‚¡ç¥¨è¿‡å°‘ï¼Œä½¿ç”¨å½“æ—¥æ¶¨å¹…ä½œä¸ºç­›é€‰æ¡ä»¶")
                    filtered = df[
                        (df['pe_ttm'].between(cfg['pe'][0], cfg['pe'][1])) &
                        (df['pb'].between(cfg['pb'][0], cfg['pb'][1])) &
                        (df['roe'] >= cfg['roe']) &
                        (df['pct_chg'] <= 6) &
                        (df['pct_chg'] >= -5)  # é˜²æ­¢é€‰å…¥å¤§å¹…ä¸‹è·Œè‚¡
                    ]
                    logger.info(f"ğŸ“ˆ æ”¾å®½æ¡ä»¶åï¼š{len(filtered)} æ”¯")

            # 11. æ‰§è¡Œå…¶ä»–ç­›é€‰å’Œæœ€ç»ˆå¤„ç†
            filtered = filtered[~filtered['name'].str.contains('ST|é€€', na=False)]
            logger.info(f"ğŸš« è¿‡æ»¤STåŠé€€å¸‚è‚¡ï¼š {len(filtered)}")

            filtered = filtered[
                ((filtered['market'] == 'ä¸»æ¿') & (filtered['close'] >= 1.5)) |
                ((filtered['market'].isin(['åˆ›ä¸šæ¿', 'ç§‘åˆ›æ¿'])) & (filtered['close'] >= 2))
            ]
            logger.info(f"ğŸ’° æ”¶ç›˜ä»·è¿‡æ»¤ï¼š{len(filtered)}")

            filtered = filtered[filtered['total_mv'].between(*cfg['mv'])]
            logger.info(f"ğŸ¦ å¸‚å€¼åŒºé—´è¿‡æ»¤ï¼š{len(filtered)}")

            filtered = filtered[
                (filtered['turnover_rate'] >= cfg['turnover'][0]) &
                (filtered['turnover_rate'] <= cfg['turnover'][1])
            ]
            logger.info(f"ğŸ”„ æ¢æ‰‹ç‡è¿‡æ»¤ï¼š{len(filtered)}")

            filtered = filtered[filtered['pct_chg'].between(*cfg['pct'])]
            logger.info(f"ğŸ“ˆ æ¶¨è·Œå¹…è¿‡æ»¤ï¼š{len(filtered)}")

            # 12. æœ€ç»ˆå¤„ç†
            filtered = filtered.sort_values('list_date', ascending=False)
            if max_count:
                filtered = filtered.head(max_count)

            logger.info(f"âœ… æœ€ç»ˆç­›é€‰è‚¡ç¥¨æ•°: {len(filtered)}")
            stock_list = list(filtered[['ts_code', 'name']].itertuples(index=False, name=None))
            turnover_map = filtered.set_index('ts_code')['turnover_rate'].to_dict()

            return stock_list, turnover_map

        except Exception as e:
            logger.error(f"get_stock_list error: {e}")
            logger.error(traceback.format_exc())
            return [], {}

    @staticmethod
    def get_k_data(ts_code: str, days: int = 180, end_date: Optional[str] = None) -> Optional[pd.DataFrame]:
        try:
            normal_rate_limiter.wait()
            today = end_date or datetime.today().strftime("%Y%m%d")
            past = (datetime.strptime(today, '%Y%m%d') - timedelta(days=days)).strftime('%Y%m%d')

            df = ts.pro_bar(
                ts_code=ts_code,
                start_date=past,
                end_date=today,
                freq='D',
                asset='E',
                adj='qfq',
                factors=['tor'],
                fields='ts_code,trade_date,open,high,low,close,vol'
            )

            if df is None or df.empty:
                return None

            # âœ… ä¸»åŠ¨æ£€æŸ¥ vol æ˜¯å¦å­˜åœ¨
            if 'vol' not in df.columns:
                logger.warning(f"{ts_code} ç¼ºå¤± vol å­—æ®µï¼Œè·³è¿‡")
                return None

            df = df.sort_values("trade_date")
            df['trade_date'] = pd.to_datetime(df['trade_date'])
            df.set_index("trade_date", inplace=True)

            # âœ… é‡å‘½å vol â†’ volumeï¼Œç»Ÿä¸€ç”¨æ³•
            df.rename(columns={'vol': 'volume'}, inplace=True)

            if len(df) < Config.MIN_DATA_DAYS:
                return None

            return df
        except Exception as e:
            logger.error(f"è·å– {ts_code} æ•°æ®å¤±è´¥: {str(e)}")
            return None

    @staticmethod
    def calculate_technical_indicators(df: pd.DataFrame) -> Tuple[Dict[str, pd.Series], pd.DataFrame]:
        result = {}
        try:
            # === åŸºç¡€æŒ‡æ ‡ ===
            close = df["close"]
            high = df["high"]
            low = df["low"]
            open_price = df["open"]
            vol = df["volume"]

            # åŠ¨æ€å‡çº¿ç³»ç»Ÿ
            windows = [5, 10, 20, 30, 60]
            for w in windows:
                df[f'ma{w}'] = close.rolling(w).mean()

            df['vol_ratio'] = vol / vol.rolling(20).mean()

            # === MACDæŒ‡æ ‡ ===
            ema12 = close.ewm(span=12, adjust=False).mean()
            ema26 = close.ewm(span=26, adjust=False).mean()
            dif = ema12 - ema26
            dea = dif.ewm(span=9, adjust=False).mean()
            macd = (dif - dea) * 2

            # === å¸ƒæ—å¸¦æŒ‡æ ‡ ===
            df['boll_mid'] = close.rolling(20).mean()
            df['boll_std'] = close.rolling(20).std()
            df['boll_upper'] = df['boll_mid'] + 2 * df['boll_std']
            df['boll_lower'] = df['boll_mid'] - 2 * df['boll_std']

            # === RSIæŒ‡æ ‡ ===
            delta = close.diff()
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)
            avg_gain = gain.rolling(14).mean()
            avg_loss = loss.rolling(14).mean()
            rs = avg_gain / (avg_loss + 1e-6)
            df['rsi'] = 100 - (100 / (1 + rs))

            # === KDJæŒ‡æ ‡ ===
            period = 9
            low_min = low.rolling(period).min()
            high_max = high.rolling(period).max()
            rsv = 100 * ((close - low_min) / (high_max - low_min + 1e-6))
            df['kdj_k'] = rsv.ewm(alpha=1/3, adjust=False).mean()
            df['kdj_d'] = df['kdj_k'].ewm(alpha=1/3, adjust=False).mean()
            df['kdj_j'] = 3 * df['kdj_k'] - 2 * df['kdj_d']

            kdj_golden_cross = (df['kdj_k'].shift(1) < df['kdj_d'].shift(1)) & (df['kdj_k'] > df['kdj_d'])
            kdj_oversold = df['kdj_j'] < 0
            kdj_k_up = df['kdj_k'] > df['kdj_k'].shift(1)
            kdj_d_up = df['kdj_d'] > df['kdj_d'].shift(1)
            kdj_j_up = df['kdj_j'] > df['kdj_j'].shift(1)
            kdj_all_up = kdj_k_up & kdj_d_up & kdj_j_up
            kdj_oversold_reversal = kdj_oversold & kdj_k_up & (df['kdj_k'] > df['kdj_d'])

            # === ç›¸å¯¹ä½ç½®åˆ¤æ–­ ===
            high_20d = high.rolling(20).max()
            low_20d = low.rolling(20).min()
            position_20d = (close - low_20d) / (high_20d - low_20d + 0.001)
            is_low_position = position_20d < 0.65
            oversold = df['rsi'] < 55
            below_boll_mid = close < df['boll_mid']
            at_bottom = is_low_position | oversold | below_boll_mid

            # === ä¸€é˜³ç©¿ä¸‰çº¿ ===
            is_yang = close > open_price
            cross_today = (close > df['ma5']) & (close > df['ma10']) & (close > df['ma20'])
            prev_below_ma = (
                (close.shift(1) < df['ma5'].shift(1)) |
                (close.shift(1) < df['ma10'].shift(1)) |
                (close.shift(1) < df['ma20'].shift(1))
            )
            volume_increase = vol > vol.rolling(5).mean() * 1.05
            yang_cross_three_line = is_yang & cross_today & prev_below_ma & at_bottom & volume_increase

            # === æ—­æ—¥ä¸œå‡ ===
            body_size = (close - open_price) / (high - low + 0.001)
            is_big_yang = is_yang & (body_size > 0.6)
            prev_high_10d = high.shift(1).rolling(10).max()
            break_resistance = close > prev_high_10d
            vol_increase_significant = vol > vol.rolling(5).mean() * 1.8
            prev_trend = close.pct_change(5).shift(1)
            has_consolidation = (prev_trend < 0) | (prev_trend < 0.03)
            rising_sun = is_big_yang & break_resistance & vol_increase_significant & has_consolidation

            # === æ¶¨åœå›è¸© ===
            was_limit_up = (close.shift(1) / close.shift(2) - 1) > 0.08
            pullback_today = (low / close.shift(1)) < 0.97
            recover_intraday = (close / low - 1) > 0.02
            vol_confirm = vol > vol.shift(1) * 0.7
            limit_up_pullback = was_limit_up & pullback_today & recover_intraday & vol_confirm

            # === å¼ºåŠ¿è‚¡å›è¸© ===
            strong_trend = (close > df['ma5']) & (df['ma5'] > df['ma10']) & (df['ma10'] > df['ma20'])
            was_above_upper = (close.shift(1) > df['boll_upper'].shift(1)) | (close.shift(2) > df['boll_upper'].shift(2))
            pullback_to_ma5 = (low <= df['ma5'] * 1.02) & (close > df['ma5'] * 0.98)
            small_vol_pullback = vol < vol.rolling(5).mean()
            strong_ma5_pullback = strong_trend & was_above_upper & pullback_to_ma5 & small_vol_pullback
            
             # === é«˜å°è·³æ°´åä¼ç¨³åå¼¹ ===
            big_drop_yesterday = (close.shift(1) / close.shift(2) - 1) < -0.05  # å‰ä¸€å¤©å¤§è·Œè¶…è¿‡5%
            gap_down_today = open_price < close.shift(1)  # ä»Šå¤©ä½å¼€
            recover_today = close > open_price  # ä»Šå¤©æ”¶é˜³
            volume_active = vol > vol.shift(1) * 0.8  # ä»Šå¤©é‡èƒ½ä»ç„¶æ´»è·ƒ
            price_hold = low > low.shift(1) * 0.99  # ä»Šå¤©æœªåˆ›æ–°ä½æˆ–ä»…å¾®åˆ›æ–°ä½
            skydiving_rebound = big_drop_yesterday & gap_down_today & recover_today & volume_active & price_hold
        
            # === åº•éƒ¨ç›˜æ•´çªç ´å½¢æ€ ===
            price_range_tight = close.rolling(5).std() / close.rolling(5).mean() < 0.015  # 5æ—¥ä»·æ ¼æ³¢åŠ¨å°
            volume_breakout = vol > vol.rolling(5).mean() * 1.5  # æˆäº¤é‡æ˜æ˜¾æ”¾å¤§
            price_breakout = close > close.rolling(5).max().shift(1)  # ä»·æ ¼çªç ´5æ—¥æ–°é«˜
            consolidation_breakout = price_range_tight.shift(1) & volume_breakout & price_breakout & is_yang
        
            # === é‡ä»·èƒŒç¦»çªç ´ ===
            price_new_low_recently = close.shift(1) < close.rolling(10).min().shift(2)  # æ˜¨å¤©åˆ›10æ—¥æ–°ä½
            volume_not_new_low = vol.shift(1) > vol.rolling(10).min().shift(2) * 1.5  # æ˜¨å¤©æˆäº¤é‡ä¸åˆ›æ–°ä½
            today_breakout = close > close.shift(1) * 1.02  # ä»Šå¤©çªç ´ä¸Šæ¶¨è¶…è¿‡2%
            today_volume_confirm = vol > vol.shift(1) * 1.2  # ä»Šå¤©æˆäº¤é‡è¿›ä¸€æ­¥æ”¾å¤§
            volume_price_divergence = price_new_low_recently & volume_not_new_low & today_breakout & today_volume_confirm

            # === OBVåŠ¨é‡ ===
            df['obv'] = (np.sign(close.diff()) * vol).fillna(0).cumsum()
            df['obv_ma'] = df['obv'].rolling(20).mean()

            # === çŸ­æœŸçªç ´ ===
            short_term_high = high.rolling(3).max().shift(1)
            short_term_breakout = (close > short_term_high) & (vol > vol.rolling(3).mean() * 1.3)

            # === èƒŒç¦» ===
            price_new_high = close > close.rolling(20).max().shift(1)
            macd_not_new_high = macd <= macd.rolling(20).max().shift(1)
            bearish_divergence = price_new_high & macd_not_new_high & (macd > 0)
            price_new_low = close < close.rolling(20).min().shift(1)
            macd_not_new_low = macd >= macd.rolling(20).min().shift(1)
            bullish_divergence = price_new_low & macd_not_new_low & (macd < 0)

            # === æœ€ç»ˆä¿¡å·é›†æˆ ===
            result = {
                # è¶‹åŠ¿å‹
                "å‡çº¿çªç ´ï¼ˆ5/20/30æ—¥ï¼‰": (close > df[['ma5', 'ma20', 'ma30']].max(axis=1)),
                "å‡çº¿å¤šå¤´æ’åˆ—": (df['ma5'] > df['ma20']) & (df['ma20'] > df['ma30']),
                "MACDé›¶è½´å…±æŒ¯": (dif > 0) & (dea > 0) & (dif > dea),
                "è¶‹åŠ¿çªç ´ç¡®è®¤": (close > high.rolling(5).max()) & (vol > vol.rolling(5).mean() * 1.5),
                "KDJåŒå‘ä¸Šæ¶¨": kdj_all_up & (df['kdj_j'] < 80),

                # åŠ¨é‡å‹
                "é‡ä»·é½å‡": (df['vol_ratio'].between(1.5, 3)) & (close > close.shift(3) * 1.05),
                "ä¸»åŠ›èµ„é‡‘å…±æŒ¯": (macd > 0) & (df['vol_ratio'] > 1.8),
                "OBVåŠ¨é‡å¼•æ“": (df['obv'] > df['obv_ma']) & (close > close.shift(5) * 1.03),
                "KDJé‡‘å‰": kdj_golden_cross & (df['kdj_j'] < 80),
                "çŸ­æœŸçªç ´": short_term_breakout,

                # åè½¬å‹
                "è¶…è·Œåå¼¹ï¼ˆRSI+BOLLï¼‰": (close < df['boll_lower']) & (df['rsi'] < 30),
                "åº•éƒ¨åè½¬ç¡®è®¤": (close < df['boll_lower'] * 0.98) & (vol > vol.rolling(5).mean() * 1.2) & (df['rsi'] < 35),
                "MACDåº•èƒŒç¦»": bullish_divergence,
                "KDJè¶…å–åè½¬": kdj_oversold_reversal,

                # é£é™©å‹
                "è¶‹åŠ¿ç ´ä½ï¼ˆMA60+MACDæ­»å‰ï¼‰": (close < df['ma60']) & (dif < dea),
                "é«˜ä½æ»æ¶¨é£é™©": (close > df['boll_upper']) & (df['rsi'] > 70) & (vol < vol.rolling(5).mean() * 0.8),
                "MACDé¡¶èƒŒç¦»": bearish_divergence,

                # ç©¿çº¿å‹
                "ä¸€é˜³ç©¿ä¸‰çº¿": yang_cross_three_line,
                "æ—­æ—¥ä¸œå‡": rising_sun,
                "æ¶¨åœå›è¸©": limit_up_pullback,
                "å¼ºåŠ¿å›è¸©": strong_ma5_pullback,
                "é«˜å°è·³æ°´ä¼ç¨³": skydiving_rebound,  
                "åº•éƒ¨ç›˜æ•´çªç ´": consolidation_breakout, 
                "é‡ä»·èƒŒç¦»çªç ´": volume_price_divergence, 
            }

            return result, df

        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"æŒ‡æ ‡è®¡ç®—é”™è¯¯: {str(e)}")
            return {}, df

    @staticmethod
    def check_risk(df: pd.DataFrame) -> bool:
        return True

class MarketNeutralAnalyzer:
    @staticmethod
    def calculate_relative_strength(ts_code, trade_date, lookback=20):
        """è®¡ç®—ç›¸å¯¹å¼ºå¼±å¾—åˆ†(-50åˆ°50)"""
        try:
            # è·å–è‚¡ç¥¨å’ŒåŸºå‡†æŒ‡æ•°è¿‡å»lookbackå¤©çš„æ”¶ç›Šç‡
            stock_ret = MarketNeutralAnalyzer._get_stock_returns(ts_code, trade_date, lookback)
            bench_ret = MarketNeutralAnalyzer._get_benchmark_returns(trade_date, lookback)
            
            # è®¡ç®—ç›¸å¯¹å¼ºå¼±
            relative_strength = (stock_ret - bench_ret).mean()
            return min(max(relative_strength * 100, -50), 50)  # é™åˆ¶åœ¨-50åˆ°50ä¹‹é—´
        except Exception as e:
            logger.error(f"è®¡ç®—ç›¸å¯¹å¼ºå¼±å¤±è´¥ {ts_code}: {str(e)}")
            return 0

    @staticmethod
    def _get_stock_returns(ts_code, trade_date, lookback):
        """è·å–è‚¡ç¥¨æ”¶ç›Šç‡"""
        end_date = datetime.strptime(trade_date, '%Y%m%d')
        start_date = end_date - timedelta(days=lookback)
        
        df = safe_api_call(
            pro.daily,
            ts_code=ts_code,
            start_date=start_date.strftime('%Y%m%d'),
            end_date=end_date.strftime('%Y%m%d'),
            fields='trade_date,pct_chg'
        )
        return df['pct_chg'] / 100 if not df.empty else pd.Series([0]*lookback)

    @staticmethod
    def _get_benchmark_returns(trade_date, lookback, benchmark='000300.SH'):
        """è·å–åŸºå‡†æŒ‡æ•°æ”¶ç›Šç‡"""
        end_date = datetime.strptime(trade_date, '%Y%m%d')
        start_date = end_date - timedelta(days=lookback)
        
        df = safe_api_call(
            pro.index_daily,
            ts_code=benchmark,
            start_date=start_date.strftime('%Y%m%d'),
            end_date=end_date.strftime('%Y%m%d'),
            fields='trade_date,pct_chg'
        )
        return df['pct_chg'] / 100 if not df.empty else pd.Series([0]*lookback)


class RecommendationTracker:
    def __init__(self):
        self.data_file = "recommendations.pkl"
        try:
            self.recommendations = pd.read_pickle(self.data_file)
            logger.info(f"âœ… æˆåŠŸåŠ è½½æ¨èå†å²ï¼Œå…± {len(self.recommendations)} æ¡è®°å½•")
        except:
            logger.info("ğŸ“‚ æ— å†å²è®°å½•ï¼Œåˆ›å»ºæ–°æ–‡ä»¶")
            self.recommendations = pd.DataFrame()

    def add_recommendation(self, stock_data: dict, recommend_date: Optional[str] = None):
        if self.stock_exists(stock_data['ts_code']):
            logger.info(f"âš ï¸ {stock_data['ts_code']} å·²å­˜åœ¨æ¨èè®°å½•")
            return False

        stock_data['recommend_date'] = recommend_date or datetime.today().strftime('%Y-%m-%d')

        # ç¡®ä¿æ‰€æœ‰å¿…è¦å­—æ®µéƒ½å­˜åœ¨ï¼Œé˜²æ­¢åç»­è®¿é—®å‡ºé”™
        required_fields = ['pattern_type', 'operation_advice', 'risk_level']
        for field in required_fields:
            if field not in stock_data:
                stock_data[field] = 'æœªçŸ¥'

        new_record = pd.DataFrame([stock_data])
        self.recommendations = pd.concat([self.recommendations, new_record], ignore_index=True)
        self._save_data()
        logger.info(
            f"âœ… å·²æ·»åŠ æ¨è: {stock_data['ts_code']} ({stock_data['recommend_date']}) - "
            f"ä¹°ç‚¹ç±»å‹: {stock_data.get('pattern_type', 'æœªåˆ†ç±»')} - "
            f"é£é™©ç­‰çº§: {stock_data.get('risk_level', 'æœªçŸ¥')}"
        )
        return True

    def export_to_watchlist(self):
        # åˆ é™¤å¯¼å‡ºwatchlistæ–‡ä»¶çš„åŠŸèƒ½
        logger.info("ğŸ“ å¯¼å‡ºwatchliståŠŸèƒ½å·²ç¦ç”¨")
        return

    def stock_exists(self, ts_code: str) -> bool:
        if self.recommendations.empty:
            return False
        return ts_code in self.recommendations['ts_code'].values

    def remove_stock(self, ts_code: str):
        if self.recommendations.empty:
            logger.info("âš ï¸ å½“å‰æ— è®°å½•å¯åˆ é™¤")
            return
        before_count = len(self.recommendations)
        self.recommendations = self.recommendations[self.recommendations['ts_code'] != ts_code]
        self._save_data()
        after_count = len(self.recommendations)
        logger.info(f"ğŸ—‘ï¸ åˆ é™¤å®Œæˆï¼Œè®°å½•æ•°: {before_count} -> {after_count}")

    def clear(self):
        self.recommendations = pd.DataFrame()
    def add_recommendation(self, stock_data: dict, recommend_date: Optional[str] = None):
        if self.stock_exists(stock_data['ts_code']):
            logger.info(f"âš ï¸ {stock_data['ts_code']} å·²å­˜åœ¨æ¨èè®°å½•")
            return False

        stock_data['recommend_date'] = recommend_date or datetime.today().strftime('%Y-%m-%d')

        new_record = pd.DataFrame([stock_data])
        self.recommendations = pd.concat([self.recommendations, new_record], ignore_index=True)
        self._save_data()
        logger.info(f"âœ… å·²æ·»åŠ æ¨è: {stock_data['ts_code']} ({stock_data['recommend_date']}) - ä¹°ç‚¹ç±»å‹: {stock_data.get('pattern_type', 'æœªåˆ†ç±»')}")
        return True
    def _save_data(self):
        self.recommendations.to_pickle(self.data_file)


# =====================
# å®ä¾‹åŒ– tracker
# =====================

tracker = RecommendationTracker()

def calculate_position(score: float, pct_change: float = 0.0, risk_warnings: List[str] = None, strategy_mode: str = "ç¨³å¥å‹") -> str:
    if risk_warnings is None:
        risk_warnings = []

    # âŒ å¼ºåˆ¶è¿‡æ»¤æç«¯æ¶¨å¹…
    # æ ¹æ®ç­–ç•¥ç±»å‹è°ƒæ•´æ¶¨å¹…é™åˆ¶
    if strategy_mode == "ç¨³å¥å‹":
        max_pct_change = 9.5  # ç¨³å¥å‹é™åˆ¶æ›´ä¸¥æ ¼
    elif strategy_mode == "ç©¿çº¿å‹":
        max_pct_change = 12.0  # ç©¿çº¿å‹å…è®¸è¾ƒé«˜æ¶¨å¹…
    else:
        max_pct_change = 15.0  # æ¿€è¿›å‹å…è®¸æ›´é«˜çš„æ¶¨å¹…
        
    if pct_change >= max_pct_change:
        return "âŒ ä¸å»ºè®®ä¹°å…¥"

    # ğŸš¨ é«˜æ³¢åŠ¨è­¦å‘Šå‡ä»“æˆ–å‰”é™¤
    volatility_penalty = 0.5 if "é«˜æ³¢åŠ¨" in risk_warnings else 1.0
    if volatility_penalty < 1.0:
        return "âŒ ä¸å»ºè®®ä¹°å…¥"  # æ³¢åŠ¨è¿‡å¤§ï¼Œç›´æ¥å‰”é™¤

    # æ¶¨åœè­¦å‘Šé™ä½ä»“ä½
    has_limit_up_warning = any("æ¶¨åœ" in warning and "è¿½é«˜é£é™©" in warning for warning in risk_warnings)
    if has_limit_up_warning:
        return "âš ï¸ è¿½é«˜é£é™©å¤§"

    # ğŸ“ˆ æ ¹æ®ç­–ç•¥è°ƒæ•´ä»“ä½åˆ†é…
    if strategy_mode == "ç¨³å¥å‹":
        # ç¨³å¥å‹ç­–ç•¥è¾ƒä½çš„ä»“ä½åˆ†é…
        if score >= 150:
            base_position = 0.12
        elif score >= 145:
            base_position = 0.10
        elif score >= 140:
            base_position = 0.09
        elif score >= 135:
            base_position = 0.08
        elif score >= 130:
            base_position = 0.07
        elif score >= 125:
            base_position = 0.06
        elif score >= 120:
            base_position = 0.05
        elif score >= 115:
            base_position = 0.04
        elif score >= 110:
            base_position = 0.03
        else:
            return "âŒ ä¸å»ºè®®ä¹°å…¥"
    
    elif strategy_mode == "ç©¿çº¿å‹":
        # ç©¿çº¿å‹ç­–ç•¥çš„ä»“ä½åˆ†é…
        if score >= 180:
            base_position = 0.15
        elif score >= 160:
            base_position = 0.13
        elif score >= 150:
            base_position = 0.12
        elif score >= 140:
            base_position = 0.10
        elif score >= 130:
            base_position = 0.08
        elif score >= 120:
            base_position = 0.06
        elif score >= 110:
            base_position = 0.04
        elif score >= 100:
            base_position = 0.03
        else:
            return "âŒ ä¸å»ºè®®ä¹°å…¥"

    elif strategy_mode == "æ¿€è¿›å‹":
        # æ¿€è¿›å‹ç­–ç•¥å…è®¸è¾ƒé«˜çš„ä»“ä½åˆ†é…
        if score >= 200:
            base_position = 0.15
        elif score >= 180:
            base_position = 0.14
        elif score >= 170:
            base_position = 0.13
        elif score >= 160:
            base_position = 0.12
        elif score >= 150:
            base_position = 0.11
        elif score >= 140:
            base_position = 0.10
        elif score >= 130:
            base_position = 0.09
        elif score >= 125:
            base_position = 0.08
        elif score >= 120:
            base_position = 0.07
        elif score >= 115:
            base_position = 0.06
        elif score >= 110:
            base_position = 0.05
        elif score >= 105:
            base_position = 0.04
        elif score >= 100:
            base_position = 0.03
        else:
            return "âŒ ä¸å»ºè®®ä¹°å…¥"

    final_position = base_position * volatility_penalty

    # ğŸ§¾ è½¬æ¢ä¸ºæ–‡æœ¬æ ‡ç­¾ï¼Œé€‚åº”ä¸åŒç­–ç•¥
    if final_position >= 0.15:
        if strategy_mode == "æ¿€è¿›å‹":
            return "15%-20%"
        elif strategy_mode == "ç©¿çº¿å‹":
            return "15%-18%"
        else:
            return "12%-15%"
    elif final_position >= 0.10:
        if strategy_mode == "æ¿€è¿›å‹":
            return "10%-15%" 
        elif strategy_mode == "ç©¿çº¿å‹":
            return "10%-13%"
        else:
            return "8%-12%"
    elif final_position >= 0.05:
        return "5%-8%"
    elif final_position >= 0.01:
        return "â‰¤5%"
    else:
        return "âš ï¸ ä»“ä½è¿‡å°"







# ===== ç•Œé¢ç›¸å…³å‡½æ•° =====
def get_tracking_html():
    html = "<h3>ğŸ“Š æ¨èå†å²è®°å½•</h3>"
    if tracker.recommendations.empty:
        return "<h3>ğŸ“­ æš‚æ— æ¨èè®°å½•</h3>"
    
    # æ·»åŠ CSSæ ·å¼ï¼Œå®šä¹‰å·¥å…·æç¤ºæ•ˆæœ
    html += """
    <style>
    .tooltip {
      position: relative;
      display: inline-block;
      cursor: pointer;
    }
    
    .tooltip .tooltiptext {
      visibility: hidden;
      width: 300px;
      background-color: #555;
      color: #fff;
      text-align: left;
      border-radius: 6px;
      padding: 10px;
      position: absolute;
      z-index: 1;
      bottom: 125%;
      left: 50%;
      margin-left: -150px;
      opacity: 0;
      transition: opacity 0.3s;
      font-size: 14px;
      line-height: 1.4;
    }
    
    .tooltip:hover .tooltiptext {
      visibility: visible;
      opacity: 1;
    }
    
    .risk-high {
      color: #FF4500;
      font-weight: bold;
    }
    
    .risk-medium-high {
      color: #FFA500;
    }
    
    .risk-medium {
      color: #FFD700;
    }
    
    .risk-medium-low {
      color: #3CB371;
    }
    
    .risk-low {
      color: #32CD32;
    }
    </style>
    """
    
    html += "<table style='width:100%;border-collapse:collapse'>"
    html += "<tr style='background-color:#f2f2f2'><th>æ—¥æœŸ</th><th>ä»£ç </th><th>åç§°</th><th>ä¹°ç‚¹ç±»å‹</th><th>é£é™©ç­‰çº§</th><th>æ“ä½œå»ºè®®</th><th>"
    
    for i, row in tracker.recommendations.iterrows():
        pattern_type = row.get('pattern_type', 'æœªåˆ†ç±»')
        operation_advice = row.get('operation_advice', 'æš‚æ— å»ºè®®')
        risk_level = row.get('risk_level', 'æœªçŸ¥')
        
        # æ·»åŠ é£é™©ç­‰çº§çš„é¢œè‰²æ ‡è¯†
        risk_class = ""
        risk_icon = ""
        if risk_level == "é«˜é£é™©":
            risk_class = "risk-high"
            risk_icon = "âš ï¸"
        elif risk_level == "ä¸­é«˜é£é™©":
            risk_class = "risk-medium-high"
            risk_icon = "âš¡"
        elif risk_level == "ä¸­é£é™©":
            risk_class = "risk-medium"
            risk_icon = "ğŸ“Š"
        elif risk_level == "ä¸­ä½é£é™©":
            risk_class = "risk-medium-low"
            risk_icon = "ğŸ”·"
        elif risk_level == "ä½é£é™©":
            risk_class = "risk-low"
            risk_icon = "âœ…"
        
        # é™åˆ¶æ“ä½œå»ºè®®çš„é•¿åº¦ï¼Œä½†ä¿ç•™å®Œæ•´å»ºè®®ä½œä¸ºå·¥å…·æç¤º
        display_advice = operation_advice
        if len(operation_advice) > 60:
            display_advice = operation_advice[:57] + "..."
        
        # æ·»åŠ å”¯ä¸€çš„è‚¡ç¥¨æ ‡è¯†ï¼Œç”¨äºè¯¦æƒ…æŒ‰é’®
        stock_id = f"stock_{row['ts_code'].replace('.', '_')}_{i}"
        
        html += f"<tr style='border-bottom:1px solid #ddd'>"
        html += f"<td style='padding:8px'>{row.get('recommend_date', 'æœªçŸ¥')}</td>"
        html += f"<td style='padding:8px'>{row.get('ts_code', 'æœªçŸ¥')}</td>"
        html += f"<td style='padding:8px'>{row.get('name', 'æœªçŸ¥')}</td>"
        html += f"<td style='padding:8px'>{pattern_type}</td>"
        html += f"<td style='padding:8px' class='{risk_class}'>{risk_icon} {risk_level}</td>"
        
        # æ·»åŠ å·¥å…·æç¤ºï¼Œæ˜¾ç¤ºå®Œæ•´å»ºè®®
        html += f"""
        <td style='padding:8px' class='tooltip'>{display_advice}
          <span class='tooltiptext'>{operation_advice}</span>
        </td>
        """
        

        
        html += "</tr>"
    
    html += "</table>"
    
    # æ·»åŠ JavaScriptï¼Œå¤„ç†è¯¦æƒ…æ˜¾ç¤ºå’Œéšè—
    html += """
    <script>
    function showDetails(id) {
        document.getElementById(id).style.display = 'block';
        document.body.style.overflow = 'hidden';
    }
    
    function hideDetails(id) {
        document.getElementById(id).style.display = 'none';
        document.body.style.overflow = 'auto';
    }
    </script>
    """
    
    return html



HIGH_VOLATILITY_INDUSTRIES = [
    "é€šä¿¡è®¾å¤‡", "åŠå¯¼ä½“", "æ–°èƒ½æº", "ç”Ÿç‰©åŒ»è¯", "å†›å·¥", "æ¸¸æˆ", "åˆ›ä¸šæ¿"
]

@lru_cache(maxsize=5000)
def is_high_volatility_industry(ts_code: str) -> bool:
    try:
        basic_info = safe_api_call(pro.stock_basic, ts_code=ts_code, fields='ts_code,industry')
        if basic_info.empty:
            return False
        industry = basic_info.iloc[0]['industry']
        return industry in HIGH_VOLATILITY_INDUSTRIES
    except Exception as e:
        logger.warning(f"è¡Œä¸šæŸ¥è¯¢å¤±è´¥ {ts_code}: {str(e)}")
        return False

@lru_cache(maxsize=1000)
def check_negative_announcements(ts_code: str) -> bool:
    # æš‚æ— æƒé™ï¼Œç›´æ¥è·³è¿‡
    return False
    try:
        start_date = (datetime.today() - timedelta(days=7)).strftime('%Y%m%d')
        df = safe_api_call(pro.anns_d, ts_code=ts_code, start_date=start_date)
        if df.empty:
            return False
        negative_keywords = ['è¯‰è®¼', 'ä»²è£', 'ç«‹æ¡ˆè°ƒæŸ¥', 'é¡¹ç›®ç»ˆæ­¢', 'æ§åˆ¶æƒå˜æ›´', 'é‡å¤§é£é™©']
        return df['title'].str.contains('|'.join(negative_keywords)).any()
    except Exception as e:
        logger.warning(f"{ts_code} å…¬å‘Šæ£€æŸ¥å¤±è´¥: {str(e)}")
        return False



@lru_cache(maxsize=1000)
def check_earnings_warning(ts_code: str) -> bool:
    try:
        current_year = datetime.today().year
        df = safe_api_call(pro.forecast_vip, ts_code=ts_code, start_date=f"{current_year}0101")
        if df.empty:
            return False
        return df['type'].str.contains("é¢„å‡|é¢„äº|ç»­äº").any()
    except Exception as e:
        logger.warning(f"{ts_code} é¢„è­¦æ£€æŸ¥å¤±è´¥: {str(e)}")
        return False








import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

def get_type_weight_safe(strategy_type: str, type_weights: Dict[str, float]) -> float:
    """å®‰å…¨è·å–ç­–ç•¥ç±»å‹æƒé‡ï¼Œä¸‰é‡å…œåº•"""
    return type_weights.get(strategy_type) if type_weights.get(strategy_type) is not None else STRATEGY_TYPE_WEIGHTS.get(strategy_type, 1.0)


def evaluate_yang_cross_strength(df: pd.DataFrame) -> str:
    close = df['close'].iloc[-1]
    open_price = df['open'].iloc[-1]
    vol = df['volume'].iloc[-1]
    ma5 = df['ma5'].iloc[-1]
    ma10 = df['ma10'].iloc[-1]
    ma20 = df['ma20'].iloc[-1]

    body_pct = (close - open_price) / (open_price + 1e-6)
    trend_order = (ma5 > ma10) and (ma10 > ma20)
    recent_high = df['high'].rolling(10).max().iloc[-1]
    space_pct = (recent_high - close) / (close + 1e-6)
    vol_mean = df['volume'].rolling(5).mean().iloc[-1]
    vol_ratio = vol / (vol_mean + 1e-6)

    score = 0
    if body_pct > 0.02: score += 1
    if trend_order: score += 1
    if space_pct > 0.05: score += 1
    if vol_ratio > 1.5: score += 1

    if score >= 3:
        return "ğŸ”¥é«˜è´¨é‡ç©¿çº¿"
    elif score == 2:
        return "âš ï¸ä¸­ç­‰ç©¿çº¿"
    else:
        return "âŒå¼±ç©¿çº¿"
def evaluate_turnover(ts_code: str, turnover: float, strategy_mode: str) -> Tuple[float, str]:
    """
    æ›´ç»†è‡´çš„æ¢æ‰‹ç‡è¯„åˆ†
    
    è¿”å›: (å¾—åˆ†, è¯„ä»·æè¿°)
    """
    # 1. è·å–å†å²æ¢æ‰‹ç‡æ•°æ®
    try:
        # è·å–è¿‡å»30æ—¥æ¢æ‰‹ç‡æ•°æ®
        end_date = datetime.today().strftime('%Y%m%d')
        start_date = (datetime.today() - timedelta(days=30)).strftime('%Y%m%d')
        
        hist_data = safe_api_call(
            pro.daily_basic, 
            ts_code=ts_code, 
            start_date=start_date, 
            end_date=end_date,
            fields='trade_date,turnover_rate'
        )
        
        # è®¡ç®—å†å²æ•°æ®
        if not hist_data.empty and len(hist_data) > 5:
            # è®¡ç®—å†å²å‡å€¼å’Œæ ‡å‡†å·®
            avg_turnover = hist_data['turnover_rate'].mean()
            max_turnover = hist_data['turnover_rate'].max()
            min_turnover = hist_data['turnover_rate'].min()
            
            # è®¡ç®—æœ€è¿‘5æ—¥æ¢æ‰‹ç‡å˜åŒ–è¶‹åŠ¿çš„æ–œç‡
            recent_data = hist_data.sort_values('trade_date', ascending=True).tail(5)
            
            # ä½¿ç”¨numpyè®¡ç®—è¶‹åŠ¿æ–œç‡
            if len(recent_data) >= 3:
                try:
                    import numpy as np
                    x = np.arange(len(recent_data))
                    y = recent_data['turnover_rate'].values
                    slope, _ = np.polyfit(x, y, 1)
                    # æ–œç‡å¤§äº0è¡¨ç¤ºä¸Šå‡è¶‹åŠ¿
                    trend = slope
                except:
                    # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•æ¯”è¾ƒ
                    trend = 1 if recent_data['turnover_rate'].iloc[-1] > recent_data['turnover_rate'].iloc[0] else -1
            else:
                trend = 1 if recent_data['turnover_rate'].iloc[-1] > recent_data['turnover_rate'].iloc[0] else -1
            
            # è®¡ç®—ç›¸å¯¹äºå†å²çš„ä½ç½®
            if avg_turnover > 0:
                relative_position = turnover / avg_turnover
            else:
                relative_position = 1.0
        else:
            # æ— å†å²æ•°æ®æ—¶çš„é»˜è®¤å€¼
            avg_turnover = turnover
            max_turnover = turnover * 1.5
            min_turnover = turnover * 0.5
            trend = 0
            relative_position = 1.0
    except Exception as e:
        logger.warning(f"æ¢æ‰‹ç‡å†å²æ•°æ®è·å–å¤±è´¥ {ts_code}: {str(e)}")
        # å‡ºé”™æ—¶ä½¿ç”¨é»˜è®¤å€¼
        avg_turnover = turnover
        max_turnover = turnover * 1.5
        min_turnover = turnover * 0.5
        trend = 0
        relative_position = 1.0
    
    # 2. æ ¹æ®ä¸åŒç­–ç•¥è®¾ç½®åŸºç¡€åˆ†å€¼èŒƒå›´
    if strategy_mode == "ç¨³å¥å‹":
        # ç¨³å¥å‹å¯¹åº”çš„æ¢æ‰‹ç‡ç†æƒ³åŒºé—´
        ideal_min, ideal_max = 2.0, 10.0
        too_low = 1.0
        too_high = 15.0
        max_score = 8
    elif strategy_mode == "ç©¿çº¿å‹":
        # ç©¿çº¿å‹éœ€è¦è¶³å¤Ÿçš„æ´»è·ƒåº¦
        ideal_min, ideal_max = 4.0, 15.0
        too_low = 2.0
        too_high = 25.0
        max_score = 12
    else:  # æ¿€è¿›å‹
        # æ¿€è¿›å‹è¿½æ±‚è¾ƒé«˜æ´»è·ƒåº¦
        ideal_min, ideal_max = 3.0, 18.0
        too_low = 1.5
        too_high = 30.0
        max_score = 10
    
    # 3. åŸºäºå¤šç»´åº¦è¯„ä¼°è®¡ç®—æœ€ç»ˆå¾—åˆ†
    
    # åŸºç¡€åˆ†ï¼šåŸºäºæ¢æ‰‹ç‡ç»å¯¹å€¼
    if turnover < too_low:
        base_score = max_score * 0.3  # è¿‡ä½çš„æ¢æ‰‹ç‡ç»™äºˆè¾ƒä½åˆ†æ•°
        eval_text = "æ¢æ‰‹ç‡è¿‡ä½"
    elif turnover > too_high:
        base_score = max_score * 0.4  # è¿‡é«˜çš„æ¢æ‰‹ç‡ä¹Ÿé™ä½è¯„åˆ†
        eval_text = "æ¢æ‰‹ç‡è¿‡é«˜"
    elif ideal_min <= turnover <= ideal_max:
        # åœ¨ç†æƒ³åŒºé—´å†…ï¼Œç»™äºˆæ»¡åˆ†
        base_score = max_score
        eval_text = "æ¢æ‰‹ç‡ç†æƒ³"
    else:
        # åœ¨å¯æ¥å—ä½†éç†æƒ³åŒºé—´ï¼Œçº¿æ€§æ’å€¼
        if turnover < ideal_min:
            base_score = max_score * 0.5 + (turnover - too_low) / (ideal_min - too_low) * max_score * 0.5
            eval_text = "æ¢æ‰‹ç‡åä½"
        else:  # turnover > ideal_max
            base_score = max_score * 0.7 + (too_high - turnover) / (too_high - ideal_max) * max_score * 0.3
            eval_text = "æ¢æ‰‹ç‡åé«˜"
    
    # è¶‹åŠ¿åŠ åˆ†ï¼šæ›´ç²¾ç»†çš„è¶‹åŠ¿è¯„ä¼°
    if isinstance(trend, (int, float)):
        if trend > 0.2:  # æ˜æ˜¾ä¸Šå‡è¶‹åŠ¿
            trend_bonus = 3
            trend_text = "ï¼Œæ¢æ‰‹ç‡æ˜æ˜¾ä¸Šå‡"
        elif trend > 0:  # è½»å¾®ä¸Šå‡è¶‹åŠ¿
            trend_bonus = 1
            trend_text = ""
        elif trend < -0.2:  # æ˜æ˜¾ä¸‹é™è¶‹åŠ¿
            trend_bonus = -1
            trend_text = "ï¼Œæ¢æ‰‹ç‡ä¸‹é™"
        else:  # è½»å¾®ä¸‹é™æˆ–å¹³ç¨³
            trend_bonus = 0
            trend_text = ""
        
        if trend_text:
            eval_text += trend_text
    else:
        # å›é€€åˆ°ç®€å•åˆ¤æ–­
        trend_bonus = 2 if trend > 0 else 0
    
    # ç›¸å¯¹å†å²ä½ç½®åŠ åˆ†ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    if 1.2 <= relative_position <= 2.0:
        relative_bonus = 3  # é«˜äºå†å²å‡å€¼20%-100%æ˜¯ç†æƒ³çš„
        eval_text += "ï¼Œé«˜äºå†å²å‡å€¼"
    elif 2.0 < relative_position <= 3.0:
        relative_bonus = 2  # é«˜äºå‡å€¼2-3å€ä¹Ÿç»™ä¸€å®šåŠ åˆ†
        eval_text += "ï¼Œè¿œé«˜äºå†å²å‡å€¼"
    elif relative_position > 3.0:
        relative_bonus = 0  # è¶…è¿‡3å€å¯èƒ½æ˜¯å¼‚å¸¸æ³¢åŠ¨ï¼Œä¸åŠ åˆ†
        eval_text += "ï¼Œå¼‚å¸¸é«˜äºå†å²æ°´å¹³"
    elif 0.8 <= relative_position < 1.2:
        relative_bonus = 1  # æ¥è¿‘å†å²å‡å€¼ä¹Ÿç»™å°‘é‡åŠ åˆ†
        eval_text += "ï¼Œæ¥è¿‘å†å²å‡å€¼"
    else:  # < 0.8
        relative_bonus = 0
        if relative_position < 0.5:
            eval_text += "ï¼Œæ˜¾è‘—ä½äºå†å²æ°´å¹³"
    
    # è®¡ç®—æœ€ç»ˆå¾—åˆ†ï¼ˆè®¾ç½®ä¸Šé™å¹¶å‘ä¸‹å–æ•´ï¼‰
    final_score = min(15, int(base_score + trend_bonus + relative_bonus))
    
    # è®°å½•è¯¦ç»†ä¿¡æ¯
    logger.debug(f"{ts_code} æ¢æ‰‹ç‡è¯„åˆ†: {final_score} (å½“å‰:{turnover:.2f}%, "
                f"å‡å€¼:{avg_turnover:.2f}%, è¶‹åŠ¿:{'+' if trend > 0 else '-'}, "
                f"ç›¸å¯¹ä½ç½®:{relative_position:.2f})")
    
    return final_score, eval_text
def evaluate_rising_sun_strength(df: pd.DataFrame) -> str:
    """
    è¯„ä¼°æ—­æ—¥ä¸œå‡ä¿¡å·çš„è´¨é‡ï¼Œè¿”å›è¯„çº§æ–‡æœ¬ã€‚
    """
    close = df['close'].iloc[-1]
    open_price = df['open'].iloc[-1]
    high = df['high'].iloc[-1]
    low = df['low'].iloc[-1]
    vol = df['volume'].iloc[-1]
    
    # é˜³çº¿å®ä½“å¼ºåº¦
    body_pct = (close - open_price) / (open_price + 1e-6)
    
    # çªç ´å¼ºåº¦ï¼ˆæ”¶ç›˜ä»·è¶…è¿‡å‰æœŸé«˜ç‚¹çš„ç¨‹åº¦ï¼‰
    prev_high_10d = df['high'].shift(1).rolling(10).max().iloc[-1]
    break_strength = (close - prev_high_10d) / (prev_high_10d + 1e-6)
    
    # æˆäº¤é‡æ”¾å¤§ç¨‹åº¦
    vol_mean = df['volume'].rolling(5).mean().iloc[-1]
    vol_ratio = vol / (vol_mean + 1e-6)
    
    # è®¡ç®—å¾—åˆ†
    score = 0
    if body_pct > 0.04: score += 1  # å¤§é˜³çº¿
    if break_strength > 0.02: score += 1  # æœ‰æ•ˆçªç ´
    if vol_ratio > 2.0: score += 1  # æ˜¾è‘—æ”¾é‡
    if df['close'].pct_change(3).iloc[-1] < 0.08: score += 1  # å‰æœŸéè¿‡åº¦ä¸Šæ¶¨
    
    if score >= 3:
        return "ğŸ”¥å¼ºåŠ¿çªç ´"
    elif score == 2:
        return "âš ï¸ä¸€èˆ¬çªç ´"
    else:
        return "âŒå¼±åŠ¿çªç ´"
def check_recent_limit_up(ts_code: str, days: int = 10) -> Tuple[bool, int, List[str]]:
    """
    æ£€æŸ¥è‚¡ç¥¨æœ€è¿‘nå¤©å†…æ˜¯å¦å‡ºç°è¿‡æ¶¨åœ
    
    Args:
        ts_code: è‚¡ç¥¨ä»£ç 
        days: æ£€æŸ¥çš„å¤©æ•°èŒƒå›´
        
    Returns:
        Tuple[bool, int, List[str]]: 
            - æ˜¯å¦æœ‰æ¶¨åœ
            - æ¶¨åœæ¬¡æ•°
            - æ¶¨åœæ—¥æœŸåˆ—è¡¨
    """
    try:
        end_date = datetime.today().strftime('%Y%m%d')
        start_date = (datetime.today() - timedelta(days=days)).strftime('%Y%m%d')
        
        # è·å–è‚¡ç¥¨è¿‘æœŸè¡Œæƒ…
        df = safe_api_call(
            pro.daily, 
            ts_code=ts_code,
            start_date=start_date,
            end_date=end_date,
            fields='ts_code,trade_date,pct_chg,close,limit_status'
        )
        
        if df.empty:
            return False, 0, []
        
        # å¦‚æœæ¥å£ç›´æ¥æä¾›limit_statuså­—æ®µ
        if 'limit_status' in df.columns:
            limit_up_days = df[df['limit_status'] == 'U']['trade_date'].tolist()
            has_limit_up = len(limit_up_days) > 0
            return has_limit_up, len(limit_up_days), limit_up_days
        
        # å¦‚æœæ²¡æœ‰limit_statuså­—æ®µï¼Œåˆ™ç”¨æ¶¨å¹…åˆ¤æ–­(9.5%ä»¥ä¸Šè§†ä¸ºæ¶¨åœ)
        limit_up_days = df[df['pct_chg'] >= 9.5]['trade_date'].tolist()
        has_limit_up = len(limit_up_days) > 0
        return has_limit_up, len(limit_up_days), limit_up_days
        
    except Exception as e:
        logger.warning(f"æ£€æŸ¥ {ts_code} è¿‘æœŸæ¶¨åœæ•°æ®å¤±è´¥: {str(e)}")
        return False, 0, []

def evaluate_skydiving_strength(df):
    """è¯„ä¼°é«˜å°è·³æ°´ä¼ç¨³å½¢æ€çš„è´¨é‡"""
    close = df["close"]
    low = df["low"]
    vol = df["volume"]
    
    # ä¸‹è·Œå¹…åº¦
    drop_pct = close.shift(1) / close.shift(2) - 1
    
    # åå¼¹å¹…åº¦
    rebound_pct = close / low - 1
    
    # æˆäº¤é‡å˜åŒ–
    vol_change = vol / vol.shift(1)
    
    # è¯„ä»·æ ‡å‡†
    if drop_pct.iloc[-1] < -0.07 and rebound_pct.iloc[-1] > 0.04 and vol_change.iloc[-1] > 1.0:
        return "ğŸ”¥é«˜è´¨é‡ä¼ç¨³"
    elif drop_pct.iloc[-1] < -0.05 and rebound_pct.iloc[-1] > 0.02:
        return "âš ï¸ä¸€èˆ¬ä¼ç¨³"
    else:
        return "âŒå¼±åŠ¿ä¼ç¨³"

def evaluate_consolidation_breakout_strength(df):
    """è¯„ä¼°åº•éƒ¨ç›˜æ•´çªç ´å½¢æ€çš„è´¨é‡"""
    close = df["close"]
    high = df["high"]
    vol = df["volume"]
    
    # çªç ´å¹…åº¦
    breakout_pct = close / close.rolling(5).max().shift(1) - 1
    
    # æˆäº¤é‡æ”¾å¤§ç¨‹åº¦
    vol_expand = vol / vol.rolling(5).mean()
    
    # è¯„ä»·æ ‡å‡†
    if breakout_pct.iloc[-1] > 0.04 and vol_expand.iloc[-1] > 2.0:
        return "ğŸ”¥å¼ºåŠ¿çªç ´"
    elif breakout_pct.iloc[-1] > 0.02 and vol_expand.iloc[-1] > 1.5:
        return "âš ï¸ä¸­ç­‰çªç ´"
    else:
        return "âŒå¼±åŠ¿çªç ´"

def evaluate_volume_price_divergence_strength(df):
    """è¯„ä¼°é‡ä»·èƒŒç¦»çªç ´å½¢æ€çš„è´¨é‡"""
    close = df["close"]
    vol = df["volume"]
    
    # çªç ´å¹…åº¦
    breakout_pct = close / close.shift(1) - 1
    
    # æ–°ä½åç¦»ç¨‹åº¦
    price_divergence = close.shift(1) / close.rolling(10).min().shift(2)
    
    # æˆäº¤é‡å¯¹æ¯”
    vol_divergence = vol.shift(1) / vol.rolling(10).min().shift(2)
    
    # è¯„ä»·æ ‡å‡†
    if breakout_pct.iloc[-1] > 0.03 and price_divergence.iloc[-1] < 1.02 and vol_divergence.iloc[-1] > 2.0:
        return "ğŸ”¥æ˜¾è‘—èƒŒç¦»"
    elif breakout_pct.iloc[-1] > 0.02 and vol_divergence.iloc[-1] > 1.5:
        return "âš ï¸ä¸€èˆ¬èƒŒç¦»"
    else:
        return "âŒå¼±åŠ¿èƒŒç¦»"


def analyze_stocks(stock_list_with_turnover: Tuple[List[Tuple[str, str]], Dict[str, float]],
                   strategies: List[str],
                   custom_weights: Dict[str, int],
                   max_stocks: int,
                   strategy_mode: str,
                   trade_date: Optional[str] = None,
                   export_watchlist: bool = True,
                   top_n: int = 10) -> List[Tuple]:
    stock_list, turnover_map = stock_list_with_turnover

    if trade_date:
        trade_date = datetime.strptime(trade_date, '%Y%m%d')
    else:
        trade_date = datetime.today()

    actual_trade_date = get_valid_trade_date(api_func=pro.daily, date_field='trade_date', base_date=trade_date)
    if not actual_trade_date:
        logger.error("âŒ æ— æ³•è·å–æœ‰æ•ˆäº¤æ˜“æ—¥ï¼Œç»“æŸåˆ†æï¼")
        return []

    logger.info(f"ğŸš€ åˆ†æå¯åŠ¨ï¼š{len(stock_list)} æ”¯è‚¡ç¥¨ ï½œ æ¨¡å¼ï¼š{strategy_mode} ï½œ æ•°æ®æ—¥æœŸï¼š{actual_trade_date}")
    
    # è·å–å¸‚åœºçŠ¶æ€ä¿¡æ¯
    market_data = _get_market_indicators(datetime.strptime(actual_trade_date, '%Y%m%d') if isinstance(actual_trade_date, str) else actual_trade_date)
    is_bull_market = False
    market_status = "æœªçŸ¥"
    if market_data:
        _, _, _, market_status, _ = market_data
        is_bull_market = market_status in ["ç‰›å¸‚", "æç«¯ç‰›å¸‚", "æ¸©å’Œç‰›å¸‚"]
        logger.info(f"ğŸ“Š å½“å‰å¸‚åœºçŠ¶æ€: {market_status}, ç‰›å¸‚ç¯å¢ƒ: {is_bull_market}")
    
    # âœ… æ¿å—çƒ­åº¦è¯„åˆ†ç³»ç»Ÿé›†æˆéƒ¨åˆ†
    if isinstance(actual_trade_date, datetime):
        trade_date_str = actual_trade_date.strftime('%Y%m%d')
    else:
        trade_date_str = actual_trade_date  # è‹¥å·²ä¸ºå­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
    
    # ä¿®æ”¹ï¼šå›æµ‹æ¨¡å¼ä¸‹è·³è¿‡æ¿å—è¯„åˆ†
    if IS_BACKTEST:
        logger.info(f"ğŸ”™ å›æµ‹æ¨¡å¼ï¼šè·³è¿‡æ¿å—çƒ­åº¦è¯„åˆ†")
        sector_scores = {}
        concept_map = {}
        concept_name_to_ts_code = {}
    else:
        logger.info(f"ğŸ“… å¼€å§‹è·å–æ¿å—æ•°æ®ï¼Œæ—¥æœŸ: {trade_date_str}")
        
        sector_scores = get_sector_strength_scores(trade_date_str)
        logger.info(f"ğŸ“Š æ¿å—è¯„åˆ†ç»“æœæ•°é‡: {len(sector_scores)}")
        if sector_scores:
            # æ‰“å°å‰5ä¸ªæ¿å—çš„è¯„åˆ†
            sample_scores = dict(list(sector_scores.items())[:5])
            logger.info(f"ğŸ“Š æ¿å—è¯„åˆ†æ ·ä¾‹: {sample_scores}")
        else:
            logger.warning("âš ï¸ æ¿å—è¯„åˆ†ä¸ºç©ºï¼å¯èƒ½æ¥å£è°ƒç”¨å¤±è´¥")
        
        concept_map = load_concept_to_stock_map()
        logger.info(f"ğŸ“š åŠ è½½æ¦‚å¿µè‚¡ç¥¨æ˜ å°„: {len(concept_map)} ä¸ªæ¦‚å¿µ")
        if concept_map:
            # æ‰“å°ä¸€ä¸ªæ ·ä¾‹
            sample_concept = list(concept_map.keys())[0]
            sample_stocks = concept_map[sample_concept][:3]
            logger.info(f"ğŸ“š æ¦‚å¿µæ˜ å°„æ ·ä¾‹: {sample_concept} -> {sample_stocks}")
        
        concept_name_to_ts_code = load_concept_name_to_code()  # ä»æ–‡ä»¶åŠ è½½æ˜ å°„
        logger.info(f"ğŸ”— åŠ è½½æ¦‚å¿µä»£ç æ˜ å°„: {len(concept_name_to_ts_code)} ä¸ªæ˜ å°„")
        if concept_name_to_ts_code:
            # æ‰“å°å‰3ä¸ªæ˜ å°„
            sample_mappings = dict(list(concept_name_to_ts_code.items())[:3])
            logger.info(f"ğŸ”— æ¦‚å¿µä»£ç æ˜ å°„æ ·ä¾‹: {sample_mappings}")
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæç¤ºç”¨æˆ·è¿è¡Œæ„å»ºè„šæœ¬
        if not concept_map or not concept_name_to_ts_code:
            logger.warning("âš ï¸ æ¦‚å¿µæ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ build_concept_mapping.py æ„å»ºæ˜ å°„")
            concept_name_to_ts_code = {}

    if not IS_BACKTEST:
        concept_data = get_concept_trends(trade_date)
        concept_trend_score = calculate_concept_trend_score(concept_data, trade_date)
    else:
        concept_trend_score = 0  # å›æµ‹æ¨¡å¼ä¸‹ï¼Œè·³è¿‡æ¦‚å¿µè¶‹åŠ¿å¾—åˆ†çš„è®¡ç®—ï¼Œè®¾ç½®ä¸º0
        
    scored_stocks = []
    ts_codes = [ts_code for ts_code, _ in stock_list]

    # Initialize various data
    initialize_industry_and_concept(ts_codes)
    initialize_moneyflow_scores(ts_codes)
    initialize_risk_data(ts_codes)
    initialize_stk_limit(ts_codes)
    initialize_block_trade(ts_codes)
    initialize_top_inst()
    initialize_share_float_data(ts_codes)
    initialize_holdernumber_data(ts_codes)
    initialize_express_data(ts_codes=ts_codes)
    
    current_suspend = set(pro.suspend_d(trade_date=actual_trade_date)['ts_code'].str.upper())
    ts_codes = [code for code in ts_codes if code not in current_suspend]

    # è·å–å¸‚åœºçŠ¶æ€è°ƒæ•´åçš„æƒé‡
    type_weights = STRATEGY_TYPE_WEIGHTS.copy()

    if strategy_mode == "ç¨³å¥å‹":
        type_weights["è¶‹åŠ¿å‹"] *= 1.3
        type_weights["åŠ¨é‡å‹"] *= 0.8
        type_weights["åè½¬å‹"] *= 0.9
        type_weights["å¸‚åœºä¸­æ€§å‹"] *= 1.2
        type_weights["ç©¿çº¿å‹"] *= 0.3   
       
    elif strategy_mode == "æ¿€è¿›å‹":
        type_weights["è¶‹åŠ¿å‹"] *= 0.6
        type_weights["åŠ¨é‡å‹"] *= 1.3
        type_weights["åè½¬å‹"] *= 1.1
        type_weights["å¸‚åœºä¸­æ€§å‹"] *= 1.0
        type_weights["ç©¿çº¿å‹"] *= 0.3  
       
    elif strategy_mode == "ç©¿çº¿å‹":
        # ç©¿çº¿å‹ç­–ç•¥ç‰¹æ®Šè°ƒæ•´
        type_weights["ç©¿çº¿å‹"] *= 2.0  
        type_weights["è¶‹åŠ¿å‹"] *= 0.3  
        type_weights["åŠ¨é‡å‹"] *= 0.3
        type_weights["åè½¬å‹"] *= 0.3
        type_weights["å¸‚åœºä¸­æ€§å‹"] *= 1.0
      
        
    # Step 2: å†æ ¹æ®å¸‚åœºçŠ¶æ€åŠ¨æ€è°ƒæ•´æƒé‡
    if IS_BACKTEST and custom_weights:
        logger.info("ğŸ¯ ä½¿ç”¨å›æµ‹ä¼ å…¥çš„å¸‚åœºæ‰°åŠ¨æƒé‡")
        for key, market_weight in custom_weights.items():
            type_weights[key] = type_weights.get(key, 1.0) * float(market_weight)
    else:
        market_weights = adjust_strategy_weights_by_market(trade_date=actual_trade_date)
        logger.info("ğŸ“¡ ä½¿ç”¨å®æ—¶å¸‚åœºæ‰°åŠ¨æƒé‡")
        for key, market_weight in market_weights.items():
            type_weights[key] = type_weights.get(key, 1.0) * float(market_weight)

    # Step 3: æœ€ç»ˆåˆå¹¶æƒé‡
    merged_weights = type_weights
    logger.info(f"âš–ï¸ æœ€ç»ˆç­–ç•¥æƒé‡ (ç­–ç•¥æ¨¡å¼: {strategy_mode}):\n" +
                "\n".join([f"- {k}: {v:.2f}" for k, v in merged_weights.items()]))

    daily_info_df = safe_api_call(pro.daily, trade_date=actual_trade_date, fields='ts_code,pct_chg')
    
    # æ£€æŸ¥ 'pct_chg' åˆ—æ˜¯å¦å­˜åœ¨
    if 'pct_chg' in daily_info_df.columns:
        pct_chg_map = daily_info_df.set_index('ts_code')['pct_chg'].to_dict()
    else:
        logger.warning("âŒ 'pct_chg' åˆ—åœ¨æ•°æ®æ¡†ä¸­æœªæ‰¾åˆ°")
        pct_chg_map = {}  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›ç©ºå­—å…¸

    removal_stats = defaultdict(int)

    # è®°å½•å·²å¤„ç†çš„è‚¡ç¥¨ï¼Œé¿å…é‡å¤
    seen_stocks = set()

    def process_stock(ts_code_name):
        ts_code, name = ts_code_name
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¯¥è‚¡ç¥¨ï¼Œé¿å…é‡å¤
            if ts_code in seen_stocks:
                return None
            seen_stocks.add(ts_code)  # æ ‡è®°è¯¥è‚¡ç¥¨å·²å¤„ç†

            if check_earnings_warning(ts_code):
                removal_stats["é£é™©é¢„è­¦"] += 1
                logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šé£é™©é¢„è­¦")
                return None

            df = StockAnalyzer.get_k_data(ts_code, days=60, end_date=actual_trade_date)
            if df is None or len(df) < Config.MIN_DATA_DAYS:
                removal_stats["æ•°æ®ä¸è¶³"] += 1
                logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šæ•°æ®ä¸è¶³")
                return None

            indicators, df = StockAnalyzer.calculate_technical_indicators(df)

            financial_score = evaluate_financials(ts_code)
            score = 0
            score_details = {}
            score += financial_score * 1
            score_details['åŸºæœ¬é¢å¾—åˆ†'] = financial_score * 1

            all_strategies = [s for group in STRATEGY_GROUPS.values() for s in group]
            matched = [s for s in all_strategies if s in indicators and indicators[s].iloc[-1]]

                

            if strategy_mode == "ç©¿çº¿å‹":
                # æ£€æŸ¥æ‰€æœ‰ç©¿çº¿ç±»å‹æŒ‡æ ‡
                yang_cross = "ä¸€é˜³ç©¿ä¸‰çº¿" in indicators and indicators["ä¸€é˜³ç©¿ä¸‰çº¿"].iloc[-1]
                rising_sun = "æ—­æ—¥ä¸œå‡" in indicators and indicators["æ—­æ—¥ä¸œå‡"].iloc[-1]
                limit_pullback = "æ¶¨åœå›è¸©" in indicators and indicators["æ¶¨åœå›è¸©"].iloc[-1]
                strong_pullback = "å¼ºåŠ¿å›è¸©" in indicators and indicators["å¼ºåŠ¿å›è¸©"].iloc[-1]
                skydiving = "é«˜å°è·³æ°´ä¼ç¨³" in indicators and indicators["é«˜å°è·³æ°´ä¼ç¨³"].iloc[-1]
                consolidation = "åº•éƒ¨ç›˜æ•´çªç ´" in indicators and indicators["åº•éƒ¨ç›˜æ•´çªç ´"].iloc[-1]
                vol_price_divergence = "é‡ä»·èƒŒç¦»çªç ´" in indicators and indicators["é‡ä»·èƒŒç¦»çªç ´"].iloc[-1]
                
                # åˆ›å»ºå½¢æ€æ˜ å°„
                pattern_matched = {
                    "ä¸€é˜³ç©¿ä¸‰çº¿": yang_cross,
                    "æ—­æ—¥ä¸œå‡": rising_sun,
                    "æ¶¨åœå›è¸©": limit_pullback,
                    "å¼ºåŠ¿å›è¸©": strong_pullback,
                    "é«˜å°è·³æ°´ä¼ç¨³": skydiving,
                    "åº•éƒ¨ç›˜æ•´çªç ´": consolidation,
                    "é‡ä»·èƒŒç¦»çªç ´": vol_price_divergence
                }
                
                # ç©¿çº¿å½¢æ€ä¼˜å…ˆçº§é…ç½®
                crossline_priority = {
                    "æ¶¨åœå›è¸©": 10,
                    "æ—­æ—¥ä¸œå‡": 9,
                    "é‡ä»·èƒŒç¦»çªç ´": 8,
                    "ä¸€é˜³ç©¿ä¸‰çº¿": 7,
                    "å¼ºåŠ¿å›è¸©": 6,
                    "é«˜å°è·³æ°´ä¼ç¨³": 5,
                    "åº•éƒ¨ç›˜æ•´çªç ´": 4
                }
                
                # åˆ¤æ–­æ˜¯å¦æœ‰è‡³å°‘ä¸€ç§ç©¿çº¿å½¢æ€
                has_cross_pattern = any(pattern_matched.values())
                
                # æ‰¾å‡ºæœ€ä¼˜å…ˆçº§çš„ç©¿çº¿å½¢æ€
                best_pattern = None
                best_priority = 0
                
                for pattern, is_matched in pattern_matched.items():
                    if is_matched and crossline_priority.get(pattern, 0) > best_priority:
                        best_pattern = pattern
                        best_priority = crossline_priority.get(pattern, 0)
                
                # æ·»åŠ åˆ°å¾—åˆ†è¯¦æƒ…ä¸­
                if best_pattern:
                    score_details['æœ€ä¼˜ç©¿çº¿å½¢æ€'] = best_pattern
                    # ç»™äºˆæœ€ä¼˜å½¢æ€é¢å¤–åŠ åˆ†
                    score += 3
                    score_details['æœ€ä¼˜å½¢æ€åŠ åˆ†'] = 3
                
                # å¸¸è§„ç©¿çº¿ä¿¡å·åˆ¤æ–­
                if has_cross_pattern:
                    # ç»Ÿè®¡åŒ¹é…çš„å½¢æ€æ•°é‡å’Œç±»å‹
                    matched_patterns = [pattern for pattern, is_matched in pattern_matched.items() if is_matched]
                    matched_count = len(matched_patterns)
                    score_details['åŒ¹é…å½¢æ€æ•°é‡'] = matched_count
                    score_details['åŒ¹é…å½¢æ€åˆ—è¡¨'] = matched_patterns
                
                    # åˆ¤æ–­å¸‚åœºç¯å¢ƒï¼Œä¸ºä¸åŒå½¢æ€æä¾›ç¯å¢ƒåŠ åˆ†
                    is_uptrend = (df['ma5'].iloc[-1] > df['ma20'].iloc[-1]) & (df['ma20'].iloc[-1] > df['ma60'].iloc[-1])
                    is_downtrend = (df['ma5'].iloc[-1] < df['ma20'].iloc[-1]) & (df['ma20'].iloc[-1] < df['ma60'].iloc[-1])
                    
                    if is_uptrend and is_bull_market:
                        # ä¸Šå‡è¶‹åŠ¿ä¸­ä¼˜å…ˆè€ƒè™‘å›è¸©ç±»å½¢æ€
                        if limit_pullback or strong_pullback:
                            score += 5
                            score_details['è¶‹åŠ¿ç¯å¢ƒåŠ åˆ†'] = "ä¸Šå‡è¶‹åŠ¿ä¸­çš„å›è¸©ä¹°ç‚¹ +5"
                    elif is_downtrend:
                        # ä¸‹è·Œè¶‹åŠ¿ä¸­ä¼˜å…ˆè€ƒè™‘åè½¬ç±»å½¢æ€
                        if skydiving or vol_price_divergence:
                            score += 3
                            score_details['è¶‹åŠ¿ç¯å¢ƒåŠ åˆ†'] = "ä¸‹è·Œè¶‹åŠ¿ä¸­çš„åè½¬ä¹°ç‚¹ +3"
                    else:
                        # éœ‡è¡è¶‹åŠ¿ä¸­ä¼˜å…ˆè€ƒè™‘çªç ´ç±»å½¢æ€
                        if yang_cross or rising_sun or consolidation:
                            score += 3
                            score_details['è¶‹åŠ¿ç¯å¢ƒåŠ åˆ†'] = "éœ‡è¡è¶‹åŠ¿ä¸­çš„çªç ´ä¹°ç‚¹ +3"
                    
                    # è®°å½•å„å½¢æ€çš„åŸå§‹å¾—åˆ†ï¼Œç”¨äºåç»­åº”ç”¨è¡°å‡ç³»æ•°
                    pattern_scores = []
                    
                    # ä¸€é˜³ç©¿ä¸‰çº¿åˆ¤æ–­
                    if yang_cross:
                        quality = evaluate_yang_cross_strength(df)
                        if quality == "âŒå¼±ç©¿çº¿":
                            removal_stats["ç©¿çº¿ä¿¡å·å¼±"] += 1
                            logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šç©¿çº¿ä¿¡å·å¼ºåº¦ä¸è¶³ï¼ˆå¼±ç©¿çº¿ï¼‰")
                            return None
                            
                        if "ä¸€é˜³ç©¿ä¸‰çº¿" not in matched:
                            matched.append("ä¸€é˜³ç©¿ä¸‰çº¿")
                        score_details['ç©¿çº¿è¯„åˆ†'] = quality
                        
                        # è®°å½•åŸå§‹åˆ†å€¼
                        if quality == "ğŸ”¥é«˜è´¨é‡ç©¿çº¿":
                            pattern_score = 5
                            pattern_scores.append(("ä¸€é˜³ç©¿ä¸‰çº¿", pattern_score, quality))
                        elif quality == "âš ï¸ä¸­ç­‰ç©¿çº¿":
                            pattern_score = 3
                            pattern_scores.append(("ä¸€é˜³ç©¿ä¸‰çº¿", pattern_score, quality))

                    # æ—­æ—¥ä¸œå‡åˆ¤æ–­
                    if rising_sun:
                        quality = evaluate_rising_sun_strength(df)
                        if quality == "âŒå¼±åŠ¿çªç ´":
                            removal_stats["çªç ´ä¿¡å·å¼±"] += 1
                            logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šæ—­æ—¥ä¸œå‡ä¿¡å·å¼ºåº¦ä¸è¶³ï¼ˆå¼±åŠ¿çªç ´ï¼‰")
                            return None
                            
                        if "æ—­æ—¥ä¸œå‡" not in matched:
                            matched.append("æ—­æ—¥ä¸œå‡")
                        score_details['çªç ´è¯„åˆ†'] = quality
                        
                        # è®°å½•åŸå§‹åˆ†å€¼
                        if quality == "ğŸ”¥å¼ºåŠ¿çªç ´":
                            pattern_score = 5
                            pattern_scores.append(("æ—­æ—¥ä¸œå‡", pattern_score, quality))
                        elif quality == "âš ï¸ä¸€èˆ¬çªç ´":
                            pattern_score = 3
                            pattern_scores.append(("æ—­æ—¥ä¸œå‡", pattern_score, quality))
                    
                    # é«˜å°è·³æ°´ä¼ç¨³åˆ¤æ–­
                    if skydiving:
                        quality = evaluate_skydiving_strength(df)
                        if quality == "âŒå¼±åŠ¿ä¼ç¨³":
                            removal_stats["ä¼ç¨³ä¿¡å·å¼±"] += 1
                            logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šé«˜å°è·³æ°´ä¼ç¨³ä¿¡å·å¼ºåº¦ä¸è¶³ï¼ˆå¼±åŠ¿ä¼ç¨³ï¼‰")
                            return None
                            
                        if "é«˜å°è·³æ°´ä¼ç¨³" not in matched:
                            matched.append("é«˜å°è·³æ°´ä¼ç¨³")
                        score_details['ä¼ç¨³è¯„åˆ†'] = quality
                        
                        # è®°å½•åŸå§‹åˆ†å€¼
                        if quality == "ğŸ”¥é«˜è´¨é‡ä¼ç¨³":
                            pattern_score = 8
                            pattern_scores.append(("é«˜å°è·³æ°´ä¼ç¨³", pattern_score, quality))
                        elif quality == "âš ï¸ä¸€èˆ¬ä¼ç¨³":
                            pattern_score = 5
                            pattern_scores.append(("é«˜å°è·³æ°´ä¼ç¨³", pattern_score, quality))
                    
                    # åº•éƒ¨ç›˜æ•´çªç ´åˆ¤æ–­
                    if consolidation:
                        quality = evaluate_consolidation_breakout_strength(df)
                        if quality == "âŒå¼±åŠ¿çªç ´":
                            removal_stats["çªç ´ä¿¡å·å¼±"] += 1
                            logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šåº•éƒ¨ç›˜æ•´çªç ´ä¿¡å·å¼ºåº¦ä¸è¶³ï¼ˆå¼±åŠ¿çªç ´ï¼‰")
                            return None
                            
                        if "åº•éƒ¨ç›˜æ•´çªç ´" not in matched:
                            matched.append("åº•éƒ¨ç›˜æ•´çªç ´")
                        score_details['ç›˜æ•´çªç ´è¯„åˆ†'] = quality
                        
                        # è®°å½•åŸå§‹åˆ†å€¼
                        if quality == "ğŸ”¥å¼ºåŠ¿çªç ´":
                            pattern_score = 8
                            pattern_scores.append(("åº•éƒ¨ç›˜æ•´çªç ´", pattern_score, quality))
                        elif quality == "âš ï¸ä¸­ç­‰çªç ´":
                            pattern_score = 5
                            pattern_scores.append(("åº•éƒ¨ç›˜æ•´çªç ´", pattern_score, quality))
                    
                    # é‡ä»·èƒŒç¦»çªç ´åˆ¤æ–­
                    if vol_price_divergence:
                        quality = evaluate_volume_price_divergence_strength(df)
                        if quality == "âŒå¼±åŠ¿èƒŒç¦»":
                            removal_stats["èƒŒç¦»ä¿¡å·å¼±"] += 1
                            logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šé‡ä»·èƒŒç¦»çªç ´ä¿¡å·å¼ºåº¦ä¸è¶³ï¼ˆå¼±åŠ¿èƒŒç¦»ï¼‰")
                            return None
                            
                        if "é‡ä»·èƒŒç¦»çªç ´" not in matched:
                            matched.append("é‡ä»·èƒŒç¦»çªç ´")
                        score_details['èƒŒç¦»è¯„åˆ†'] = quality
                        
                        # è®°å½•åŸå§‹åˆ†å€¼
                        if quality == "ğŸ”¥æ˜¾è‘—èƒŒç¦»":
                            pattern_score = 8
                            pattern_scores.append(("é‡ä»·èƒŒç¦»çªç ´", pattern_score, quality))
                        elif quality == "âš ï¸ä¸€èˆ¬èƒŒç¦»":
                            pattern_score = 5
                            pattern_scores.append(("é‡ä»·èƒŒç¦»çªç ´", pattern_score, quality))
                    
                    # è®¡ç®—å¹¶åº”ç”¨å¤šå½¢æ€è¡°å‡ç³»æ•°
                    if len(pattern_scores) > 0:
                        # ä¿å­˜åŸå§‹å½¢æ€è¯„åˆ†æ˜ç»†
                        score_details['å½¢æ€åŸå§‹è¯„åˆ†'] = [(p, s) for p, s, _ in pattern_scores]
                        
                        # æŒ‰ä¼˜å…ˆçº§æ’åº
                        sorted_patterns = sorted(pattern_scores, 
                                            key=lambda x: crossline_priority.get(x[0], 0), 
                                            reverse=True)
                        
                        # åº”ç”¨è¡°å‡ç³»æ•°è®¡ç®—æœ€ç»ˆå¾—åˆ†
                        total_pattern_score = 0
                        decay_details = []
                        
                        for i, (pattern_name, pattern_score, quality) in enumerate(sorted_patterns):
                            # è¡°å‡ç³»æ•°ï¼šé¦–ä¸ªå½¢æ€100%ï¼Œç¬¬äºŒä¸ª70%ï¼Œç¬¬ä¸‰ä¸ª50%ï¼Œç¬¬å››ä¸ªåŠä»¥å30%
                            if i == 0:
                                decay = 1.0
                            elif i == 1:
                                decay = 0.7
                            elif i == 2:
                                decay = 0.5
                            else:
                                decay = 0.3
                            
                            decayed_score = pattern_score * decay
                            total_pattern_score += decayed_score
                            decay_details.append(f"{pattern_name}({quality}): {pattern_score} Ã— {decay:.1f} = {decayed_score:.1f}")
                        
                        # è®°å½•è¡°å‡è¯¦æƒ…
                        original_total = sum(s for _, s, _ in pattern_scores)
                        score_details['å½¢æ€åŸå§‹æ€»åˆ†'] = original_total
                        score_details['å½¢æ€è¡°å‡è¯¦æƒ…'] = decay_details
                        score_details['å½¢æ€è¡°å‡åæ€»åˆ†'] = total_pattern_score
                        
                        # åº”ç”¨åˆ°æ€»åˆ†
                        score += total_pattern_score
                        logger.info(f"ğŸ”¶ {ts_code} {name} åŒ¹é…{len(pattern_scores)}ç§å½¢æ€ï¼ŒåŸå§‹åˆ†{original_total}ï¼Œè¡°å‡å{total_pattern_score:.1f}")
                    
                    # åˆ†æKçº¿å½¢æ€ï¼Œé¢„æµ‹æ¬¡æ—¥è¡¨ç°
                    close = df["close"].iloc[-1]
                    open_price = df["open"].iloc[-1]
                    high = df["high"].iloc[-1]
                    low = df["low"].iloc[-1]
                    
                    body_ratio = abs(close - open_price) / (high - low)
                    upper_shadow = (high - max(close, open_price)) / (high - low)
                    lower_shadow = (min(close, open_price) - low) / (high - low)
                    
                    # åˆ†ææ—¥å†…èµ°åŠ¿ç‰¹å¾ (æ ¹æ®å¼€é«˜ä½æ”¶æ¨¡æ‹Ÿæ—¥å†…èµ°åŠ¿)
                    is_yang = close > open_price
                    if upper_shadow > 0.3 and close < (high + low) / 2:
                        # ä¸Šå½±çº¿é•¿ï¼Œæ”¶ç›˜é ä¸‹ - æ¬¡æ—¥å¯èƒ½é«˜å¼€å›è½
                        t1_pattern = "ä¸Šå½±é•¿æ”¶ç›˜å¼±"
                        t1_advice = "æ¬¡æ—¥å»ºè®®ä½å¸ï¼Œå…³æ³¨æ—©ç›˜å›è°ƒ"
                        t1_risk = "ä¸­é«˜"
                    elif lower_shadow > 0.3 and close > (high + low) / 2:
                        # ä¸‹å½±çº¿é•¿ï¼Œæ”¶ç›˜é ä¸Š - æ¬¡æ—¥å¯èƒ½ä½å¼€èµ°é«˜
                        t1_pattern = "ä¸‹å½±é•¿æ”¶ç›˜å¼º"
                        t1_advice = "æ¬¡æ—¥å»ºè®®å¼€ç›˜ä¹°å…¥ï¼Œè€å¿ƒæŒæœ‰"
                        t1_risk = "ä¸­ä½"
                    elif body_ratio > 0.7 and is_yang:
                        # å®ä½“å¤§é˜³çº¿ - æ¬¡æ—¥å¯èƒ½é«˜å¼€å†²é«˜
                        t1_pattern = "å¤§é˜³å®ä½“å¼º"
                        t1_advice = "æ¬¡æ—¥å»ºè®®é«˜æŠ›ä½å¸ï¼Œæ³¨æ„é«˜å¼€é£é™©"
                        t1_risk = "ä¸­ç­‰"
                    else:
                        t1_pattern = "å¸¸è§„Kçº¿"
                        t1_advice = "å¸¸è§„æ“ä½œ"
                        t1_risk = "ä¸€èˆ¬"
                    
                    # æ·»åŠ åˆ°äº¤æ˜“æ¨¡å¼ä¿¡æ¯ä¸­
                    if 'trading_pattern' not in score_details:
                        score_details['trading_pattern'] = {}
                    
                    score_details['trading_pattern']['t1_pattern'] = t1_pattern
                    score_details['trading_pattern']['t1_advice'] = t1_advice
                    score_details['trading_pattern']['t1_risk'] = t1_risk
                
                    # æ·»åŠ è¿‘æœŸæ¶¨åœæ£€æŸ¥å’ŒåŠ åˆ† (å¯¹æ‰€æœ‰ç©¿çº¿å‹è‚¡ç¥¨éƒ½è¿›è¡Œæ£€æŸ¥)
                    end_date = datetime.strptime(actual_trade_date, '%Y%m%d') if isinstance(actual_trade_date, str) else actual_trade_date
                    start_date = (end_date - timedelta(days=10)).strftime('%Y%m%d')
                    
                    try:
                        # è·å–è‚¡ç¥¨è¿‘æœŸè¡Œæƒ…
                        recent_df = safe_api_call(
                            pro.daily, 
                            ts_code=ts_code,
                            start_date=start_date,
                            end_date=end_date.strftime('%Y%m%d') if isinstance(end_date, datetime) else end_date,
                            fields='ts_code,trade_date,pct_chg'
                        )
                        
                        if not recent_df.empty:
                            # ä½¿ç”¨æ¶¨å¹…åˆ¤æ–­(9.5%ä»¥ä¸Šè§†ä¸ºæ¶¨åœ)
                            limit_up_days = recent_df[recent_df['pct_chg'] >= 9.5]['trade_date'].tolist()
                            limit_up_count = len(limit_up_days)
                            
                            if limit_up_count > 0:
                                # æ£€æŸ¥æ˜¯å¦å½“å¤©æ¶¨åœ
                                end_date_str = end_date.strftime('%Y%m%d') if isinstance(end_date, datetime) else end_date
                                is_today_limit_up = False
                                
                                if limit_up_days and max(limit_up_days) == end_date_str:
                                    is_today_limit_up = True
                                    days_since = 0
                                elif limit_up_days:
                                    latest_limit_up = max(limit_up_days)
                                    days_since = (datetime.strptime(end_date_str, '%Y%m%d') - datetime.strptime(latest_limit_up, '%Y%m%d')).days
                                else:
                                    days_since = 999
                                
                                score_details['æœ€è¿‘æ¶¨åœ'] = f"{days_since}å¤©å‰"
                                
                                # å½“å¤©æ¶¨åœç›´æ¥è¿‡æ»¤æ‰ï¼ˆé€‚åˆT+1ç­–ç•¥ï¼‰
                                if is_today_limit_up:
                                    removal_stats["å½“æ—¥æ¶¨åœ"] += 1
                                    logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šå½“æ—¥å·²æ¶¨åœï¼Œä¸é€‚åˆT+1")
                                    return None
                                
                                # å¯¹äºæ˜¨æ—¥æ¶¨åœï¼ˆ1å¤©å‰ï¼‰ï¼Œç‰¹æ®Šå¤„ç†
                                if days_since == 1:
                                    # æ·»åŠ é£é™©è­¦å‘Š
                                    if 'risk_warnings' not in score_details:
                                        score_details['risk_warnings'] = []
                                    score_details['risk_warnings'].append(f"æ˜¨æ—¥æ¶¨åœï¼Œæ³¨æ„é«˜å¼€å›è½é£é™©")
                                    
                                    # æ¶¨åœåç¬¬ä¸€å¤©å¾—åˆ†æƒ©ç½š
                                    score_penalty = -20  
                                    score += score_penalty
                                    score_details['æ˜¨æ—¥æ¶¨åœæƒ©ç½š'] = score_penalty
                                    logger.info(f"âš ï¸ {ts_code} æ˜¨æ—¥æ¶¨åœï¼Œè¯„åˆ†æƒ©ç½š: {score_penalty}")
                                    
                                # 2-3å¤©å‰æ¶¨åœï¼Œè½»å¾®æƒ©ç½š
                                elif 2 <= days_since <= 3:
                                    if 'risk_warnings' not in score_details:
                                        score_details['risk_warnings'] = []
                                    score_details['risk_warnings'].append(f"æœ€è¿‘{days_since}å¤©å†…æ¶¨åœï¼Œæ³¢åŠ¨å¯èƒ½è¾ƒå¤§")
                                    
                                    # è½»å¾®å¾—åˆ†æƒ©ç½š
                                    score_penalty = -10
                                    score += score_penalty
                                    score_details['è¿‘æœŸæ¶¨åœæƒ©ç½š'] = score_penalty
                                    logger.info(f"âš ï¸ {ts_code} {days_since}å¤©å‰æ¶¨åœï¼Œè¯„åˆ†æƒ©ç½š: {score_penalty}")
                                # æ¶¨åœå·²è¿‡3å¤©ï¼Œå¯ä»¥ç»™äºˆåŠ åˆ†
                                else:
                                    # æ ¹æ®æ¶¨åœæ¬¡æ•°ç»™äºˆåŠ åˆ†
                                    if limit_up_count >= 3:
                                        limit_bonus = 5  
                                    elif limit_up_count == 2:
                                        limit_bonus = 3  
                                    else:
                                        limit_bonus = 2  
                                        
                                    score += limit_bonus
                                    score_details['æ¶¨åœåŠ åˆ†'] = limit_bonus
                                    score_details['æ¶¨åœæ¬¡æ•°'] = limit_up_count
                                    logger.info(f"ğŸš€ {ts_code} {name} è¿‘{limit_up_count}æ¬¡æ¶¨åœï¼ŒåŠ åˆ†{limit_bonus}")
                                
                    except Exception as e:
                        logger.warning(f"æ£€æŸ¥ {ts_code} è¿‘æœŸæ¶¨åœå¤±è´¥: {str(e)}")
                        
                    # æ£€æŸ¥æŠ€æœ¯é£é™©ä¿¡å·
                    risk_signals = [detail for detail in score_details.get('æŠ€æœ¯é¢å¾—åˆ†ç»†èŠ‚', []) 
                                  if '-' in detail.split(':')[1].strip().split(' ')[0]]
                    
                    if risk_signals:
                        # æå–æ‰€æœ‰è´Ÿé¢æŠ€æœ¯ä¿¡å·
                        negative_signals = []
                        total_risk_score = 0
                        
                        for signal in risk_signals:
                            # è§£æä¿¡å·åç§°å’Œæ‰£åˆ†å€¼
                            signal_parts = signal.split(':')
                            signal_name = signal_parts[0].strip()
                            signal_score_str = signal_parts[1].strip().split(' ')[0]
                            signal_score = float(signal_score_str)
                            
                            negative_signals.append(f"{signal_name}({signal_score})")
                            total_risk_score += abs(signal_score)
                        
                        # å°†é£é™©ä¿¡å·æ·»åŠ åˆ°é£é™©è­¦å‘Šä¸­
                        if 'risk_warnings' not in score_details:
                            score_details['risk_warnings'] = []
                        
                        risk_desc = f"æŠ€æœ¯é£é™©ä¿¡å·: {', '.join(negative_signals)}"
                        score_details['risk_warnings'].append(risk_desc)
                        
                        # å¯¹äºç‰¹åˆ«ä¸¥é‡çš„é£é™©ä¿¡å·ï¼Œå¢åŠ ç©¿çº¿å‹ç­–ç•¥ä¸“å±çš„é¢å¤–æƒ©ç½š
                        if total_risk_score >= 20:  # å¦‚æœé£é™©æ‰£åˆ†æ€»å’Œè¶…è¿‡20åˆ†
                            # å¯¹ç©¿çº¿å½¢æ€å¾—åˆ†è¿›è¡Œé¢å¤–æƒ©ç½šï¼ˆåŸå§‹ç©¿çº¿å½¢æ€å¾—åˆ†çš„15%ï¼‰
                            extra_penalty = min(8, total_pattern_score * 0.15)  # æœ€å¤šä¸è¶…è¿‡8åˆ†
                            score -= extra_penalty
                            score_details['ä¸¥é‡é£é™©é¢å¤–æƒ©ç½š'] = -extra_penalty
                            
                            # é™ä½è¯¥è‚¡ç¥¨çš„æ“ä½œå»ºè®®ç½®ä¿¡åº¦
                            if 'trading_pattern' in score_details and 'confidence' in score_details['trading_pattern']:
                                original_confidence = score_details['trading_pattern']['confidence']
                                score_details['trading_pattern']['confidence'] = max(50, original_confidence - 20)
                                
                            # æ·»åŠ æ›´æ˜ç¡®çš„é£é™©æç¤ºåˆ°æ“ä½œå»ºè®®ä¸­
                            if 'trading_pattern' in score_details and 'operation_advice' in score_details['trading_pattern']:
                                original_advice = score_details['trading_pattern']['operation_advice']
                                risk_advice = f"{original_advice}ã€‚âš ï¸å­˜åœ¨æ˜æ˜¾æŠ€æœ¯é£é™©ä¿¡å·ï¼Œå»ºè®®é™ä½ä»“ä½ï¼Œè®¾ç½®è¾ƒç´§æ­¢æŸ"
                                score_details['trading_pattern']['operation_advice'] = risk_advice
                                
                            # å°†é£é™©ç­‰çº§æé«˜
                            if 'trading_pattern' in score_details and 'risk_level' in score_details['trading_pattern']:
                                score_details['trading_pattern']['risk_level'] = "é«˜é£é™©"
                        
                        # æ·»åŠ é£é™©ä¿¡å·è¯¦æƒ…åˆ°è¯„åˆ†è¯¦æƒ…ä¸­ï¼Œä½¿å…¶æ›´æ˜æ˜¾
                        score_details['æŠ€æœ¯é£é™©ä¿¡å·'] = negative_signals
                        score_details['æŠ€æœ¯é£é™©æ‰£åˆ†æ€»å’Œ'] = -total_risk_score
                        
                elif not matched:
                    # å¦‚æœæ˜¯ç©¿çº¿å‹ç­–ç•¥æ¨¡å¼ä½†æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å½¢æ€ï¼Œåˆ™è·³è¿‡
                    removal_stats["ä¸æ»¡è¶³ç©¿çº¿æ¡ä»¶"] += 1
                    logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šç©¿çº¿å‹ç­–ç•¥æ¨¡å¼ä¸‹ä¸æ»¡è¶³ç©¿çº¿æ¡ä»¶")
                    return None

            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•ç­–ç•¥ï¼Œåˆ™è·³è¿‡
            if not matched:
                removal_stats["æ— åŒ¹é…ç­–ç•¥"] += 1
                logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šæ— åŒ¹é…ç­–ç•¥")
                return None

            # æƒé‡è®¡ç®—åŠç­–ç•¥å¾—åˆ†
            weights = {s: STRATEGY_WEIGHTS.get(s, 10) * merged_weights.get(get_strategy_type(s), 1.0) for s in STRATEGY_WEIGHTS}
            weights.update(custom_weights)

            matched = sorted(matched, key=lambda s: weights.get(s, 0), reverse=True)


            tech_score = 0
            score_details['æŠ€æœ¯é¢å¾—åˆ†ç»†èŠ‚'] = []

            type_count = defaultdict(int)  # æ¯ç±»ç­–ç•¥è®¡æ•°å™¨

            for s in matched:
                strategy_type = get_strategy_type(s)
                type_count[strategy_type] += 1

                # è¡°å‡ç³»æ•°ï¼šç›¸åŒç­–ç•¥ç±»å‹ï¼Œæ¯å¤š1ä¸ªï¼Œä¹˜ä»¥0.9
                decay_factor = 0.9 ** (type_count[strategy_type] - 1)

                base_score = weights.get(s, 10) * merged_weights.get(strategy_type, 1.0)
                final_score = base_score * decay_factor

                tech_score += final_score
                score_details['æŠ€æœ¯é¢å¾—åˆ†ç»†èŠ‚'].append(f"{s}: {final_score:.1f} (Ã—{decay_factor:.2f})")

            score += tech_score
            score_details['æŠ€æœ¯é¢å¾—åˆ†'] = tech_score
            


            market_neutral_weight = merged_weights.get("å¸‚åœºä¸­æ€§å‹", 1.0)
            rs_score = MarketNeutralAnalyzer.calculate_relative_strength(ts_code, actual_trade_date)
            neutral_bonus = rs_score * 10
            neutral_bonus_weighted = min(12, neutral_bonus * market_neutral_weight * 0.4) 
            score += neutral_bonus_weighted
            score_details['å¸‚åœºä¸­æ€§å¾—åˆ†'] = neutral_bonus_weighted
            
            # å…¶ä»–è¯„åˆ†é€»è¾‘
            
            old_score = score
            # ä¿®æ”¹ï¼šå›æµ‹æ¨¡å¼ä¸‹è·³è¿‡æ¿å—çƒ­åº¦åŠ åˆ†
            if IS_BACKTEST:
                logger.debug(f"ğŸ”™ å›æµ‹æ¨¡å¼ï¼š{ts_code} è·³è¿‡æ¿å—çƒ­åº¦åŠ åˆ†")
                score_details['æ¿å—çƒ­åº¦åŠ åˆ†'] = 0
            else:
                score = inject_sector_score(score, ts_code, concept_name_to_ts_code, sector_scores, concept_map, weight=0.3)
                score_details['æ¿å—çƒ­åº¦åŠ åˆ†'] = round(score - old_score, 2)

            risk_penalty = evaluate_risk_factors(ts_code)  # é£é™©å› å­
            score -= risk_penalty
            logger.debug(f"ğŸ”´ {ts_code} é£é™©æ‰£åˆ†: {risk_penalty}")

            share_float_penalty = evaluate_share_float(ts_code)  # é™å”®
            score += share_float_penalty
            logger.debug(f"ğŸ’¸ {ts_code} æœªæ¥é™å”®è§£ç¦å¾—åˆ†: {share_float_penalty}")

            holdernumber_score = evaluate_holdernumber(ts_code)  # è‚¡ä¸œäººæ•°å˜åŒ–
            score += holdernumber_score
            logger.debug(f"ğŸ‘¥ {ts_code} è‚¡ä¸œäººæ•°å˜åŒ–å¾—åˆ†: {holdernumber_score}")

            express_score = evaluate_express(ts_code)  # å¿«é€Ÿè´¢æŠ¥è¯„åˆ†
            score += express_score
            logger.debug(f"ğŸ“ˆ {ts_code} å¿«é€Ÿè´¢æŠ¥å¾—åˆ†: {express_score}")

            top_inst_score = check_top_inst(ts_code)  # ä¸»åŠ›èµ„é‡‘è¯„åˆ†
            score += top_inst_score
            logger.debug(f"ğŸ¦ {ts_code} ä¸»åŠ›èµ„é‡‘å¾—åˆ†: {top_inst_score}")
            
            # åŠ å…¥èµ„é‡‘æµå‘è¯„åˆ†
            moneyflow_score = evaluate_moneyflow(ts_code)
            score += moneyflow_score
            logger.debug(f"ğŸ’° {ts_code} èµ„é‡‘æµå‘å¾—åˆ†: {moneyflow_score}")
            score_details['èµ„é‡‘æµå‘å¾—åˆ†'] = moneyflow_score

            score += concept_trend_score
            score_details['æ¦‚å¿µè¶‹åŠ¿å¾—åˆ†'] = concept_trend_score

            # å…¶ä»–æ‰£åˆ†é€»è¾‘
            current_price = df['close'].iloc[-1]
            limit_info = stk_limit_cache.get(ts_code)
            if limit_info and current_price <= limit_info['down_limit'] * 1.005:
                removal_stats["æ¥è¿‘è·Œåœ"] += 1
                logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šæ¥è¿‘è·Œåœ")
                return None
            turnover = turnover_map.get(ts_code)
            if turnover is None:
                removal_stats["æ¢æ‰‹ç‡è¿‡ä½"] += 1
                logger.info(f"ğŸ›‘ {ts_code} è¢«ç­›é™¤ï¼ŒåŸå› ï¼šæ¢æ‰‹ç‡è¿‡ä½")
                return None
            
            # ä½¿ç”¨æ–°çš„æ¢æ‰‹ç‡è¯„åˆ†å‡½æ•°
            turnover_score, turnover_eval = evaluate_turnover(ts_code, turnover, strategy_mode)
            score += turnover_score
            score_details['æ¢æ‰‹ç‡åŠ åˆ†'] = turnover_score
            score_details['æ¢æ‰‹ç‡è¯„ä»·'] = turnover_eval
            
            day_volatility = (df['high'].iloc[-1] - df['low'].iloc[-1]) / df['close'].iloc[-2]
            if day_volatility > 0.15:  # å•æ—¥æ³¢åŠ¨è¶…15%
                removal_stats["å¼‚å¸¸æ³¢åŠ¨"] += 1
                return None
            
            # ===== æ–°å¢ï¼šè®¡ç®—äº¤æ˜“æ¨¡å¼åˆ†æ =====
            trading_pattern = analyze_trading_pattern(matched, df, score_details, strategy_mode)
            score_details['trading_pattern'] = trading_pattern

            # æœ€åè¿”å›å¾—åˆ†
            return (score, ts_code, name, matched, df['close'].pct_change(5).iloc[-1] * 100, df, score_details)

        except Exception as e:
            logger.error(f"{ts_code} åˆ†æå¼‚å¸¸: {e}")
            return None

    # å¤„ç†è‚¡ç¥¨æ•°æ®
    with concurrent.futures.ThreadPoolExecutor(max_workers=Config.MAX_WORKERS) as executor:
        futures = [executor.submit(process_stock, stock) for stock in stock_list[:max_stocks]]
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            if result:
                scored_stocks.append(result)

    # ç¡®ä¿æ‰€æœ‰çš„ç§»é™¤åŸå› éƒ½è¢«è®¡æ•°ï¼Œé¿å…åç»­å¼•ç”¨ä¸å­˜åœ¨çš„é”®
    required_reasons = [
        "é£é™©é¢„è­¦", "å‘½ä¸­é£é™©ç­–ç•¥", "æ•°æ®ä¸è¶³", "æ— åŒ¹é…ç­–ç•¥",
        "ç©¿çº¿ä¿¡å·å¼±", "çªç ´ä¿¡å·å¼±", "ä¼ç¨³ä¿¡å·å¼±", "èƒŒç¦»ä¿¡å·å¼±", "ä¸æ»¡è¶³ç©¿çº¿æ¡ä»¶",
        "æ¥è¿‘è·Œåœ", "æ¢æ‰‹ç‡è¿‡ä½", "å¼‚å¸¸æ³¢åŠ¨"
    ]
    for reason in required_reasons:
        if reason not in removal_stats:
            removal_stats[reason] = 0

    # ç»“æœç»Ÿè®¡å’Œå»é‡
    logger.info(f"âœ… åˆ†æå®Œæˆï¼šæ€»{len(stock_list)}æ”¯ï¼Œå€™é€‰{len(scored_stocks)}æ”¯")
    for reason, count in removal_stats.items():
        logger.info(f"âš ï¸ è¢«ç­›é™¤çš„åŸå› ç»Ÿè®¡ï¼š{reason}ï¼š{count}æ”¯")

    # å…ˆè¿›è¡Œåˆæ­¥é€‰æ‹©ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    pre_selected_stocks = []
    
    if strategy_mode == "ç©¿çº¿å‹":
        # æå–æ»¡è¶³ç©¿çº¿å‹æ¡ä»¶çš„è‚¡ç¥¨ï¼ˆåŒ…å«ç©¿çº¿å‹ä¸‹çš„æ‰€æœ‰æŒ‡æ ‡ï¼‰
        cross_line_stocks = [stock for stock in scored_stocks 
                             if any(s in stock[3] for s in STRATEGY_GROUPS["ç©¿çº¿å‹"])]
        
        if cross_line_stocks:
            logger.info(f"ğŸ¯ æ‰¾åˆ°æ»¡è¶³ç©¿çº¿å½¢æ€çš„è‚¡ç¥¨ï¼š{len(cross_line_stocks)}æ”¯")
            
            # ä¸ºæ¯åªè‚¡ç¥¨æ·»åŠ T+1äº¤æ˜“é€‚åˆåº¦è¯„åˆ†
            t1_scored_stocks = []
            for stock in cross_line_stocks:
                score, ts_code, name, matched, pct_change, df, score_details = stock
                
                # æå–æˆ–è®¡ç®—T+1ç›¸å…³æŒ‡æ ‡
                turnover = turnover_map.get(ts_code, 0)
                recent_volatility = df['high'].pct_change().rolling(5).std().iloc[-1] * 100  # æœ€è¿‘5æ—¥æ³¢åŠ¨ç‡
                
                # è®¡ç®—T+1å¾—åˆ†
                t1_score = 0
                
                # æ¢æ‰‹ç‡å› ç´  (0-10åˆ†)
                if turnover >= 5.0:
                    t1_score += 10
                elif turnover >= 3.0:
                    t1_score += 7
                elif turnover >= 1.5:
                    t1_score += 4
                
                # æ³¢åŠ¨ç‡å› ç´  (0-6åˆ†)
                if 1.5 <= recent_volatility <= 4.0:  # é€‚ä¸­æ³¢åŠ¨ç‡æœ€ç†æƒ³
                    t1_score += 6
                elif recent_volatility < 1.0:  # æ³¢åŠ¨å¤ªå°
                    t1_score += 2
                elif recent_volatility > 6.0:  # æ³¢åŠ¨å¤ªå¤§
                    t1_score += 1
                else:
                    t1_score += 4
                
                # æˆäº¤é‡è¿ç»­æ€§ (0-4åˆ†)
                vol_stability = df['volume'].pct_change().rolling(3).std().iloc[-1]
                if vol_stability < 0.3:  # æˆäº¤é‡ç¨³å®š
                    t1_score += 4
                elif vol_stability < 0.5:
                    t1_score += 2
                
                # å°†T+1å¾—åˆ†æ·»åŠ åˆ°åŸå§‹åˆ†æ•°ä¸­ï¼ŒæŒ‰ç…§åŠ æƒåˆ†æ•°æ’åº
                weighted_score = score * 0.7 + t1_score * 3  # T+1å› ç´ æƒé‡æ›´é«˜
                
                t1_scored_stocks.append((weighted_score, score, ts_code, name, matched, pct_change, df, score_details, t1_score))
            
            # æ ¹æ®åŠ æƒåˆ†æ•°æ’åº
            t1_scored_stocks.sort(key=lambda x: x[0], reverse=True)
            
            # æ—¥å¿—è¾“å‡ºT+1ç›¸å…³ä¿¡æ¯
            for weighted_score, orig_score, ts_code, name, matched, pct_change, df, score_details, t1_score in t1_scored_stocks[:top_n]:
                logger.info(f"ğŸ“Š {ts_code} {name} åŸå§‹å¾—åˆ†: {orig_score:.1f}, T+1ç‰¹æ€§å¾—åˆ†: {t1_score:.1f}, åŠ æƒæ€»åˆ†: {weighted_score:.1f}")
            
            # å°†ç»“æœè½¬å›åŸæ ¼å¼ï¼Œä½†ä¿ç•™T+1æ’åº
            pre_selected_stocks = [(orig_score, ts_code, name, matched, pct_change, df, score_details) 
                                  for weighted_score, orig_score, ts_code, name, matched, pct_change, df, score_details, t1_score 
                                  in t1_scored_stocks[:top_n*2]]
            
            # åœ¨ç‰›å¸‚ç¯å¢ƒä¸‹ï¼Œä¼˜å…ˆé€‰æ‹©æ¶¨åœå›è¸©å’Œå¼ºåŠ¿å›è¸©çš„è‚¡ç¥¨
            if is_bull_market:
                premium_stocks = [stock for stock in pre_selected_stocks 
                                 if any(s in stock[3] for s in ["æ¶¨åœå›è¸©", "å¼ºåŠ¿å›è¸©"])]
                if premium_stocks and len(premium_stocks) >= top_n // 2:
                    logger.info(f"ğŸ”¥ ç‰›å¸‚ç¯å¢ƒä¸‹ï¼Œä¼˜å…ˆé€‰æ‹©å›è¸©å½¢æ€è‚¡ç¥¨ï¼š{len(premium_stocks)}æ”¯")
                    # ä¼˜å…ˆå–å›è¸©å½¢æ€çš„è‚¡ç¥¨ï¼Œå‰©ä½™åé¢è¡¥å……å…¶ä»–ç©¿çº¿å‹
                    premium_stocks = sorted(premium_stocks, key=lambda x: x[0], reverse=True)
                    other_stocks = [s for s in pre_selected_stocks if s not in premium_stocks]
                    other_stocks = sorted(other_stocks, key=lambda x: x[0], reverse=True)
                    
                    # åˆå¹¶ç»“æœï¼Œä¿è¯å›è¸©å½¢æ€è‚¡ç¥¨ä¼˜å…ˆ
                    pre_selected_stocks = premium_stocks[:top_n//2] + other_stocks[:top_n-len(premium_stocks[:top_n//2])]
                    pre_selected_stocks = sorted(pre_selected_stocks, key=lambda x: x[0], reverse=True)
        else:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°æ»¡è¶³ç©¿çº¿æ¡ä»¶çš„è‚¡ç¥¨ï¼Œå°†ä½¿ç”¨æ™®é€šæ’åº")
            pre_selected_stocks = sorted(scored_stocks, key=lambda x: x[0], reverse=True)[:top_n*2]
    elif strategy_mode == "ç¨³å¥å‹":
        pre_selected_stocks = diversify_recommendations(scored_stocks, max_recommend=top_n*2)
    else:
        pre_selected_stocks = sorted(scored_stocks, key=lambda x: x[0], reverse=True)[:top_n*2]

    seen_codes = set()
    ordered_pre_selected = []
    for stock in pre_selected_stocks:
        if stock[1] not in seen_codes:
            seen_codes.add(stock[1])
            ordered_pre_selected.append(stock)

    # æœ€ç»ˆé€‰æ‹©ä¸æ’åº
    final_stocks = ordered_pre_selected[:top_n]
    # ä¿è¯æœ€ç»ˆæ¨èæŒ‰è¯„åˆ†æ’åº
    final_stocks = sorted(final_stocks, key=lambda x: x[0], reverse=True)
    
    # è¾“å‡ºä¼˜åŒ–åçš„é£é™©åˆ†å¸ƒå’Œä¹°ç‚¹ç±»å‹ç»Ÿè®¡
    risk_counts = {}
    pattern_counts = {}
    
    for stock in final_stocks:
        _, _, _, _, _, _, score_details = stock
        risk_level = "æœªçŸ¥"
        pattern_type = "æœªçŸ¥"
        
        if isinstance(score_details, dict) and 'trading_pattern' in score_details:
            pattern = score_details['trading_pattern']
            if isinstance(pattern, dict):
                if 'risk_level' in pattern:
                    risk_level = pattern['risk_level']
                if 'pattern_type' in pattern:
                    pattern_type = pattern['pattern_type']
                # æ£€æŸ¥æ˜¯å¦æœ‰T+1ç‰¹å®šå­—æ®µ
                if 't1_risk' in pattern:
                    risk_level = pattern['t1_risk']
                if 't1_pattern' in pattern:
                    pattern_type = pattern['t1_pattern']
        
        if risk_level not in risk_counts:
            risk_counts[risk_level] = 0
        risk_counts[risk_level] += 1
        
        if pattern_type not in pattern_counts:
            pattern_counts[pattern_type] = 0
        pattern_counts[pattern_type] += 1
    
    logger.info(f"ğŸ”„ é£é™©åˆ†å¸ƒä¼˜åŒ–åï¼š{risk_counts}")
    logger.info(f"ğŸ”„ ä¹°ç‚¹ç±»å‹ä¼˜åŒ–åï¼š{pattern_counts}")

    # è¾“å‡ºè¯¦ç»†ä¿¡æ¯
    for score, ts_code, name, matched, pct_change, df, score_details in final_stocks:
        logger.info(f"ğŸ‡ {ts_code} {name} æ€»åˆ†: {score:.1f} | ç»„æˆ: {score_details}")

    if export_watchlist:
        tracker.clear()
        # å¯¼å‡ºè‚¡ç¥¨åˆ—è¡¨æ—¶ï¼Œå¦‚æœæ˜¯ç©¿çº¿å‹ç­–ç•¥ä¸”æ•°é‡è¿‡å¤šï¼Œåªå¯¼å‡ºå‰top_nåª
        export_stocks = final_stocks
        if strategy_mode == "ç©¿çº¿å‹" and len(final_stocks) > top_n:
            logger.info(f"ğŸ”„ ç©¿çº¿å‹ç­–ç•¥æ£€æµ‹åˆ°{len(final_stocks)}æ”¯è‚¡ç¥¨ï¼Œä½†åªå¯¼å‡ºå¾—åˆ†æœ€é«˜çš„{top_n}æ”¯")
            # ç¡®ä¿å¯¼å‡ºçš„æ˜¯è¯„åˆ†æœ€é«˜çš„å‰top_nåª    
            export_stocks = sorted(final_stocks, key=lambda x: x[0], reverse=True)[:top_n]
        else:
        # å¯¹æ‰€æœ‰ç­–ç•¥éƒ½ç¡®ä¿æŒ‰è¯„åˆ†æ’åº
            export_stocks = sorted(export_stocks, key=lambda x: x[0], reverse=True)
            
        for score, ts_code, name, matched, pct_change, df, score_details in export_stocks:
            # æå–é£é™©è­¦å‘Šï¼Œå¦‚æœå­˜åœ¨
            risk_warnings = score_details.get('risk_warnings', [])
            # æå–äº¤æ˜“æ¨¡å¼ä¿¡æ¯
            trading_pattern = score_details.get('trading_pattern', {})
            pattern_type = trading_pattern.get('pattern_type', '')
            operation_advice = trading_pattern.get('operation_advice', '')
            risk_level = trading_pattern.get('risk_level', 'æœªçŸ¥')
            
            # ä¼˜å…ˆä½¿ç”¨T+1ç‰¹å®šä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            t1_pattern = trading_pattern.get('t1_pattern', '')
            t1_advice = trading_pattern.get('t1_advice', '')
            t1_risk = trading_pattern.get('t1_risk', '')
            
            if t1_pattern:
                pattern_type = t1_pattern
            if t1_advice:
                operation_advice = t1_advice
            if t1_risk:
                risk_level = t1_risk
            
            tracker.add_recommendation({
                'ts_code': ts_code,
                'name': name,
                'strategies': matched,
                'score': score,
                'price': df['close'].iloc[-1],
                'position': calculate_position(score, pct_change, risk_warnings, strategy_mode),
                'pattern_type': pattern_type,
                'operation_advice': operation_advice,
                'risk_level': risk_level,
                'is_top': True
            })
        #tracker.export_to_watchlist()


    final_stocks = sorted(final_stocks, key=lambda x: x[0], reverse=True)
    logger.info(f"ğŸ“Š æŒ‰è¯„åˆ†æ’åºçš„æœ€ç»ˆæ¨èç»“æœï¼š")
    for rank, (score, ts_code, name, matched, pct_change, df, score_details) in enumerate(final_stocks, 1):
        logger.info(f"ğŸ† ç¬¬{rank}å: {ts_code} {name} è¯„åˆ†: {score:.1f}")
    
    logger.info(f"ğŸ“¢ æœ€ç»ˆæ¨èï¼š{[ts_code for _, ts_code, *_ in final_stocks]}")
    
    return final_stocks            




def chat_interface(user_input: str, market_type: List[str], max_stocks: int, strategy_mode: str, history: List) -> Tuple[List, List]:
    default_trigger_phrases = ["æ¨èè‚¡ç¥¨", "å¸®æˆ‘æ¨è", "é€‰è‚¡", "ç»™æˆ‘æ¨è", "æ‰¾è‚¡ç¥¨"]
    markets_str = ", ".join(market_type)

    # å¯ç”¨å…¨ç­–ç•¥ï¼ˆä¸»åŠ¨å‰”é™¤é£é™©å‹ç­–ç•¥ï¼‰
    strategy_items = [s for s in STRATEGY_WEIGHTS.keys() if get_strategy_type(s) != "é£é™©å‹"]
    custom_weights = {s: w for s, w in STRATEGY_WEIGHTS.items() if get_strategy_type(s) != "é£é™©å‹"}

    if strategy_mode == "ç¨³å¥å‹":
        explanation = "ğŸ“˜ ã€ç¨³å¥å‹ã€‘ï¼šè¶‹åŠ¿å‹ä¸ºä¸»ï¼Œé€‚åº¦ä¿ç•™åŠ¨é‡ä¸åå¼¹ï¼Œè§„é¿é£é™©ã€‚"
       
    elif strategy_mode == "æ¿€è¿›å‹":
        explanation = "ğŸš€ ã€æ¿€è¿›å‹ã€‘ï¼šçªå‡ºçŸ­çº¿åŠ¨é‡ä¸é‡èƒ½æœºä¼šï¼Œè¶‹åŠ¿é€‚å½“é™ä½ï¼Œé£é™©ç­–ç•¥å·²éš”ç¦»ã€‚"
        
    elif strategy_mode == "ç©¿çº¿å‹":
        explanation = "ğŸŒŸ ã€ç©¿çº¿å‹ã€‘ï¼šä¸“æ³¨äºæ•æ‰çªç ´ä¿¡å·ï¼ŒåŒ…æ‹¬ä¸€é˜³ç©¿ä¸‰çº¿å’Œæ—­æ—¥ä¸œå‡å½¢æ€ï¼ŒåŒæ—¶å…³æ³¨è¿‘æœŸæœ‰è¿‡æ¶¨åœçš„å¼ºåŠ¿è‚¡ã€‚"
        
    elif any(phrase in user_input for phrase in default_trigger_phrases):
        explanation = "ğŸ¤– æ³›åŒ–è¯·æ±‚ï¼šå‡è¡¡å¯ç”¨ç­–ç•¥ï¼Œå·²è‡ªåŠ¨å‰”é™¤é£é™©ç­–ç•¥ï¼Œç»¼åˆè¯„ä¼°æœºä¼šã€‚"
    else:
        response = DeepSeekAPI.call_deepseek(user_input)
        strategy_items, explanation, custom_weights = DeepSeekAPI.parse_strategies(response)

        if not strategy_items:
            error_msg = f"âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆç­–ç•¥\n{explanation}"
            history.append((user_input, error_msg))
            return history, history

    try:
        logger.info(f"ğŸ“‹ å¯ç”¨ç­–ç•¥æ•°ï¼š{len(strategy_items)}ï¼Œå¸‚åœºï¼š{markets_str}")
        history.append((user_input, f"ğŸ“‹ ç­–ç•¥æ˜ç»†ï¼š\n{explanation}\n\nğŸ” æ­£åœ¨æ‰«æ {markets_str} (æœ€å¤šåˆ†æ {max_stocks} æ”¯)..."))

        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = StockAnalyzer.get_stock_list(
            tuple(market_type),
            max_count=max_stocks,
            strategy_mode=strategy_mode
        )
        if not stock_list:
            history.append(("", "âš ï¸ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥"))
            return history, history

        scored_stocks = analyze_stocks(stock_list, strategy_items, custom_weights, max_stocks, strategy_mode)

        if not scored_stocks:
            history.append(("", "âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨"))
        else:
            result_msg = "âœ… æ¨èè‚¡ç¥¨ (æŒ‰åˆ†æ•°æ’åº):\n"
            
            # æ·»åŠ é’ˆå¯¹ç©¿çº¿å‹ç­–ç•¥çš„ç‰¹æ®Šæç¤º
            if strategy_mode == "ç©¿çº¿å‹":
                # ç»Ÿè®¡ä¸åŒä¿¡å·ç±»å‹çš„è‚¡ç¥¨æ•°é‡
                yang_cross_count = sum(1 for _, _, _, matched, _, _, _ in scored_stocks if "ä¸€é˜³ç©¿ä¸‰çº¿" in matched)
                rising_sun_count = sum(1 for _, _, _, matched, _, _, _ in scored_stocks if "æ—­æ—¥ä¸œå‡" in matched)
                limit_up_count = sum(1 for _, _, _, _, _, _, details in scored_stocks if isinstance(details, dict) and 'æ¶¨åœæ¬¡æ•°' in details and details['æ¶¨åœæ¬¡æ•°'] > 0)
                
                if yang_cross_count > 0 or rising_sun_count > 0:
                    signal_info = []
                    if yang_cross_count > 0:
                        signal_info.append(f"ä¸€é˜³ç©¿ä¸‰çº¿: {yang_cross_count}æ”¯")
                    if rising_sun_count > 0:
                        signal_info.append(f"æ—­æ—¥ä¸œå‡: {rising_sun_count}æ”¯")
                    if limit_up_count > 0:
                        signal_info.append(f"è¿‘æœŸæ¶¨åœ: {limit_up_count}æ”¯")
                    
                    result_msg += f"ğŸ” ç©¿çº¿å‹ç­–ç•¥å‘ç° {len(scored_stocks)} æ”¯ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ ({', '.join(signal_info)})ï¼Œæ˜¾ç¤ºå¾—åˆ†æœ€é«˜çš„{len(scored_stocks)}æ”¯\n"
            
            # ä¿æŒåŸå§‹æ ¼å¼çš„è¡¨å¤´
            result_msg += "æ’å | ä»£ç  | åç§° | å¾—åˆ† | 5æ—¥æ¶¨å¹… | ä»“ä½ | åŒ¹é…ç­–ç•¥ | é£é™©æç¤º\n"
            result_msg += "-" * 100 + "\n"
            
            # å¦‚æœæ˜¯ç©¿çº¿å‹ç­–ç•¥ä¸”ç»“æœè¿‡å¤šï¼Œè€ƒè™‘åˆ†é¡µæ˜¾ç¤ºæˆ–é™åˆ¶ç»“æœè¡Œæ•°é¿å…UIæ˜¾ç¤ºé—®é¢˜
            max_display = len(scored_stocks)
            if max_display > 50:
                max_display = 50  # UIæ˜¾ç¤ºé™åˆ¶ï¼Œæœ€å¤šæ˜¾ç¤º50è¡Œ
            
            # ========== ä¿æŒåŸå§‹æ ¼å¼çš„ç»“æœè¾“å‡º ==========
            valid_strategies = list(STRATEGY_WEIGHTS.keys()) 
            for i, (score, ts_code, name, matched, pct_change, _, score_details) in enumerate(scored_stocks[:max_display], 1):
                # æ¸…æ´—ç­–ç•¥åˆ—è¡¨
                clean_matched = [s for s in matched if s in valid_strategies]

                # å¦‚æœåŒ…å«"ä¸€é˜³ç©¿ä¸‰çº¿"ï¼Œåœ¨å…¶åæ·»åŠ è¯„åˆ†æ ‡ç­¾
                if "ä¸€é˜³ç©¿ä¸‰çº¿" in clean_matched and isinstance(score_details, dict):
                    quality = score_details.get("ç©¿çº¿è¯„åˆ†", "")
                    if quality:
                        index = clean_matched.index("ä¸€é˜³ç©¿ä¸‰çº¿")
                        clean_matched[index] = f"ä¸€é˜³ç©¿ä¸‰çº¿ï¼ˆ{quality}ï¼‰"
                
                # å¦‚æœåŒ…å«"æ—­æ—¥ä¸œå‡"ï¼Œåœ¨å…¶åæ·»åŠ è¯„åˆ†æ ‡ç­¾
                if "æ—­æ—¥ä¸œå‡" in clean_matched and isinstance(score_details, dict):
                    quality = score_details.get("çªç ´è¯„åˆ†", "")
                    if quality:
                        index = clean_matched.index("æ—­æ—¥ä¸œå‡")
                        clean_matched[index] = f"æ—­æ—¥ä¸œå‡ï¼ˆ{quality}ï¼‰"

                # æ·»åŠ æ¶¨åœä¿¡æ¯æ˜¾ç¤º
                limit_up_info = ""
                if isinstance(score_details, dict) and 'æ¶¨åœæ¬¡æ•°' in score_details and score_details['æ¶¨åœæ¬¡æ•°'] > 0:
                    limit_up_info = f"âš¡{score_details['æ¶¨åœæ¬¡æ•°']}æ¬¡æ¶¨åœ"
                    if 'æœ€è¿‘æ¶¨åœ' in score_details:
                        limit_up_info += f"({score_details['æœ€è¿‘æ¶¨åœ']})"

                # æå–é£é™©æç¤º
                risk_warnings = []
                if isinstance(score_details, dict) and 'risk_warnings' in score_details:
                    risk_warnings = score_details['risk_warnings']
                risk_info = " | ".join(risk_warnings) if risk_warnings else "æ— "

                # è®¡ç®—ä»“ä½
                position = calculate_position(score, pct_change, risk_warnings, strategy_mode)

                # è¾“å‡ºç»“æœè¡Œï¼Œä¿æŒåŸå§‹æ ¼å¼
                strategy_display = f"{', '.join(clean_matched[:3])}"
                if limit_up_info:
                    strategy_display += f" {limit_up_info}"
                
                result_msg += (
                    f"{i:2d}. {ts_code.split('.')[0]} {name[:10]} | "
                    f"ğŸ“Š{int(score)} | "
                    f"ğŸ“ˆ{pct_change:.1f}% | "
                    f"âš–ï¸{position} | "
                    f"{strategy_display} | "
                    f"{risk_info}\n"
                )

            # å¦‚æœæœ‰æ›´å¤šç»“æœæœªæ˜¾ç¤ºï¼Œæ·»åŠ æç¤º
            if len(scored_stocks) > max_display:
                result_msg += f"\n... è¿˜æœ‰ {len(scored_stocks) - max_display} æ”¯æ»¡è¶³æ¡ä»¶çš„è‚¡ç¥¨æœªæ˜¾ç¤º (æ€»å…± {len(scored_stocks)} æ”¯) ..."
                
            history.append(("", result_msg))

    except Exception as e:
        logger.error(f"ç•Œé¢äº¤äº’é”™è¯¯: {str(e)}", exc_info=True)
        history.append(("", f"âš ï¸ ç³»ç»Ÿé”™è¯¯: {str(e)}"))

    return history, history


def analyze_trading_pattern(matched_strategies, technical_data, score_details, strategy_mode):
    """
    æ ¹æ®åŒ¹é…çš„ç­–ç•¥å’ŒæŠ€æœ¯æŒ‡æ ‡åˆ†æä¹°ç‚¹ç±»å‹å’Œæ“ä½œå»ºè®®ï¼Œé€‚åº”å¤šç­–ç•¥å‘½ä¸­æƒ…å†µ
    
    å‚æ•°:
    matched_strategies: åŒ¹é…çš„ç­–ç•¥åˆ—è¡¨
    technical_data: è‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼ˆDataFrameï¼‰
    score_details: å¾—åˆ†è¯¦æƒ…
    strategy_mode: ç­–ç•¥æ¨¡å¼ï¼ˆç¨³å¥å‹ã€æ¿€è¿›å‹ã€ç©¿çº¿å‹ï¼‰
    
    è¿”å›:
    dict: åŒ…å«ä¹°ç‚¹ç±»å‹å’Œæ“ä½œå»ºè®®çš„å­—å…¸
    """
    # åˆå§‹åŒ–ç»“æœ
    result = {
        "pattern_type": "",  # ä¹°ç‚¹ç±»å‹
        "operation_advice": "",  # æ“ä½œå»ºè®®
        "stop_loss": 0,      # æ­¢æŸä½
        "risk_level": "",    # é£é™©ç­‰çº§
        "confidence": 0,     # ä¿¡å¿ƒæŒ‡æ•°ï¼ˆ0-100ï¼‰
    }
    
    # è½¬æ¢ç­–ç•¥åˆ—è¡¨åˆ°é›†åˆï¼Œæ–¹ä¾¿æ£€æŸ¥
    strategies = set(matched_strategies)
    
    # æå–æœ€è¿‘çš„ä»·æ ¼å’ŒæŒ‡æ ‡æ•°æ®
    if 'close' in technical_data.columns:
        close = technical_data['close'].iloc[-1]
        open_price = technical_data['open'].iloc[-1] if 'open' in technical_data.columns else close * 0.99
        high = technical_data['high'].iloc[-1] if 'high' in technical_data.columns else close * 1.01
        low = technical_data['low'].iloc[-1] if 'low' in technical_data.columns else close * 0.99
        
        # è®¡ç®—æ³¢åŠ¨ç‡ - ç”¨äºé£é™©è¯„ä¼°
        volatility = technical_data['close'].pct_change().std() * 100 if len(technical_data) > 5 else 2.0
        
        # è·å–å‡çº¿æ•°æ®
        ma5 = technical_data['ma5'].iloc[-1] if 'ma5' in technical_data.columns else None
        ma10 = technical_data['ma10'].iloc[-1] if 'ma10' in technical_data.columns else None
        ma20 = technical_data['ma20'].iloc[-1] if 'ma20' in technical_data.columns else None
        ma30 = technical_data['ma30'].iloc[-1] if 'ma30' in technical_data.columns else None
    else:
        # å¦‚æœæ²¡æœ‰åŸºæœ¬æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
        close = 100
        open_price = 99
        high = 101
        low = 98
        volatility = 2.0
        ma5 = ma10 = ma20 = ma30 = None
    
    # ä»score_detailsä¸­è·å–æ›´ä¸°å¯Œçš„ä¿¡æ¯
    risk_warnings = []
    if isinstance(score_details, dict) and 'risk_warnings' in score_details:
        risk_warnings = score_details['risk_warnings']
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ¶¨åœä¿¡æ¯
    has_limit_up = False
    recent_limit_up = False
    limit_up_days_ago = 999
    
    if isinstance(score_details, dict):
        if 'æ¶¨åœåŠ åˆ†' in score_details and score_details['æ¶¨åœåŠ åˆ†'] > 0:
            has_limit_up = True
        if 'æœ€è¿‘æ¶¨åœ' in score_details and 'å¤©å‰' in score_details['æœ€è¿‘æ¶¨åœ']:
            try:
                days_text = score_details['æœ€è¿‘æ¶¨åœ']
                limit_up_days_ago = int(days_text.split('å¤©å‰')[0])
                if limit_up_days_ago <= 3:  # 3å¤©å†…æœ‰æ¶¨åœ
                    recent_limit_up = True
            except:
                pass
    
    # === åˆ†æåŒ¹é…ç­–ç•¥çš„ç»„åˆï¼Œç¡®å®šä¸»å¯¼ä¹°ç‚¹ç±»å‹ ===
    
    # è·å–æŠ€æœ¯é¢å¾—åˆ†è¯¦æƒ…ï¼ŒæŸ¥çœ‹å“ªäº›ç­–ç•¥å¾—åˆ†æœ€é«˜
    top_strategies = []
    if isinstance(score_details, dict) and 'æŠ€æœ¯é¢å¾—åˆ†ç»†èŠ‚' in score_details:
        # å°è¯•ä»å¾—åˆ†ç»†èŠ‚ä¸­æå–æœ€é‡è¦çš„ç­–ç•¥
        strategy_scores = []
        
        for strategy_score in score_details['æŠ€æœ¯é¢å¾—åˆ†ç»†èŠ‚']:
            try:
                # è§£ææ ¼å¼å¦‚ "ç­–ç•¥å: åˆ†æ•° (Ã—æƒé‡)"
                parts = strategy_score.split(':')
                if len(parts) >= 2:
                    strategy_name = parts[0].strip()
                    score_part = parts[1].strip().split('(')[0].strip()
                    score_value = float(score_part)
                    strategy_scores.append((strategy_name, score_value))
            except:
                continue
        
        # æŒ‰å¾—åˆ†æ’åºå¹¶è·å–å‰3ä¸ªç­–ç•¥
        strategy_scores.sort(key=lambda x: x[1], reverse=True)
        top_strategies = [s[0] for s in strategy_scores[:3]]
    
    # å¦‚æœæ²¡æœ‰ä»å¾—åˆ†ç»†èŠ‚è·å–åˆ°æ•°æ®ï¼Œå°±ä½¿ç”¨åŒ¹é…çš„ç­–ç•¥
    if not top_strategies:
        top_strategies = list(strategies)[:3] if strategies else []
    
    # æ›´æ–°ç­–ç•¥åˆ†ç±»ä»¥åŒ¹é…æœ€æ–°çš„STRATEGY_GROUPS
    trend_strategies = ["å‡çº¿å¤šå¤´æ’åˆ—", "è¶‹åŠ¿çªç ´ç¡®è®¤", "å‡çº¿çªç ´ï¼ˆ5/20/30æ—¥ï¼‰", "MACDé›¶è½´å…±æŒ¯", "KDJåŒå‘ä¸Šæ¶¨"]
    momentum_strategies = ["é‡ä»·é½å‡", "ä¸»åŠ›èµ„é‡‘å…±æŒ¯", "OBVåŠ¨é‡å¼•æ“", "KDJé‡‘å‰", "çŸ­æœŸçªç ´"]
    reversal_strategies = ["è¶…è·Œåå¼¹ï¼ˆRSI+BOLLï¼‰", "åº•éƒ¨åè½¬ç¡®è®¤", "MACDåº•èƒŒç¦»", "KDJè¶…å–åè½¬"]
    crossline_strategies = ["ä¸€é˜³ç©¿ä¸‰çº¿", "æ—­æ—¥ä¸œå‡", "æ¶¨åœå›è¸©", "å¼ºåŠ¿å›è¸©"]
    risk_strategies = ["MACDé¡¶èƒŒç¦»", "è¶‹åŠ¿ç ´ä½ï¼ˆMA60+MACDæ­»å‰ï¼‰", "é«˜ä½æ»æ¶¨é£é™©"]
    
    # ç»Ÿè®¡å„ç±»ç­–ç•¥çš„æ•°é‡ï¼ˆä½¿ç”¨æ‰€æœ‰åŒ¹é…çš„ç­–ç•¥ï¼Œä¸ä»…ä»…æ˜¯top3ï¼‰
    trend_count = sum(1 for s in strategies if s in trend_strategies)
    momentum_count = sum(1 for s in strategies if s in momentum_strategies)
    reversal_count = sum(1 for s in strategies if s in reversal_strategies)
    crossline_count = sum(1 for s in strategies if s in crossline_strategies)
    risk_count = sum(1 for s in strategies if s in risk_strategies)
    
    # === æ£€æµ‹æ··åˆå‹ä¹°ç‚¹ - ä¿®æ”¹ä¸ºæ›´å¤šæ ·åŒ–çš„ä¹°ç‚¹ç±»å‹ ===
    is_mixed_pattern = False
    mixed_type = ""
    
    # ç‰¹å®šç­–ç•¥ç»„åˆçš„æ··åˆå‹åˆ¤æ–­ - ä¿æŒåŸæœ‰é€»è¾‘
    if "åº•éƒ¨åè½¬ç¡®è®¤" in strategies and "å‡çº¿å¤šå¤´æ’åˆ—" in strategies:
        is_mixed_pattern = True
        mixed_type = "åè½¬è¶‹åŠ¿æ··åˆå‹"
    elif "è¶…è·Œåå¼¹ï¼ˆRSI+BOLLï¼‰" in strategies and "MACDé›¶è½´å…±æŒ¯" in strategies:
        is_mixed_pattern = True
        mixed_type = "åå¼¹è¶‹åŠ¿å…±æŒ¯å‹"
    elif "KDJè¶…å–åè½¬" in strategies and "è¶‹åŠ¿çªç ´ç¡®è®¤" in strategies:
        is_mixed_pattern = True
        mixed_type = "KDJåè½¬çªç ´å‹"
    elif "åº•éƒ¨åè½¬ç¡®è®¤" in strategies and "ä¸€é˜³ç©¿ä¸‰çº¿" in strategies:
        is_mixed_pattern = True
        mixed_type = "åº•éƒ¨ç©¿çº¿å¤åˆå‹"
    elif "MACDåº•èƒŒç¦»" in strategies and "æ—­æ—¥ä¸œå‡" in strategies:
        is_mixed_pattern = True
        mixed_type = "èƒŒç¦»æ—­æ—¥ç ´å±€å‹"
    
    # é€šç”¨æ··åˆå‹åˆ¤æ–­ - æ”¹è¿›ä¸ºæ›´ç»†åˆ†çš„ç±»å‹
    elif reversal_count >= 1 and trend_count >= 2:
        is_mixed_pattern = True
        mixed_type = "åè½¬è¶‹åŠ¿å…±æŒ¯å‹"
    elif reversal_count >= 1 and momentum_count >= 2:
        is_mixed_pattern = True
        mixed_type = "åè½¬åŠ¨èƒ½å¯åŠ¨å‹"
    # ä¿®æ”¹ç©¿çº¿è¶‹åŠ¿åŠ¨èƒ½å…¨é¢å…±æŒ¯å‹çš„åˆ¤æ–­æ¡ä»¶ï¼Œä½¿å…¶æ›´ä¸¥æ ¼ï¼Œå¹¶åˆ†å‡ºæ›´å¤šç±»å‹
    elif crossline_count >= 1 and trend_count >= 1 and momentum_count >= 1:
        # ç»†åˆ†ä¸åŒçš„ç»„åˆç±»å‹ï¼Œé¿å…å…¨éƒ¨å½’ä¸ºä¸€ç§
        if crossline_count >= 1 and trend_count >= 2 and momentum_count >= 2:
            # è¦æ±‚æ›´å¤šçš„ç»„åˆæ‰èƒ½åˆ¤å®šä¸ºå…¨é¢å…±æŒ¯å‹
            is_mixed_pattern = True
            mixed_type = "ç©¿çº¿è¶‹åŠ¿åŠ¨èƒ½å…¨é¢å…±æŒ¯å‹"
        elif "ä¸€é˜³ç©¿ä¸‰çº¿" in strategies and "MACDé›¶è½´å…±æŒ¯" in strategies:
            is_mixed_pattern = True
            mixed_type = "ä¸€é˜³ç©¿MACDå…±æŒ¯å‹"
        elif "æ—­æ—¥ä¸œå‡" in strategies and "é‡ä»·é½å‡" in strategies:
            is_mixed_pattern = True
            mixed_type = "æ—­æ—¥é‡ä»·å¯åŠ¨å‹"
        elif "æ¶¨åœå›è¸©" in strategies and any(s in strategies for s in trend_strategies):
            is_mixed_pattern = True
            mixed_type = "æ¶¨åœå›è¸©è¶‹åŠ¿ç¡®è®¤å‹"
        elif "å¼ºåŠ¿å›è¸©" in strategies and any(s in strategies for s in momentum_strategies):
            is_mixed_pattern = True
            mixed_type = "å¼ºåŠ¿å›è¸©åŠ¨èƒ½å¼ºåŒ–å‹"
        elif crossline_count >= 1 and trend_count >= 1:
            is_mixed_pattern = True
            mixed_type = "ç©¿çº¿è¶‹åŠ¿é…åˆå‹"
        elif crossline_count >= 1 and momentum_count >= 1:
            is_mixed_pattern = True
            mixed_type = "ç©¿çº¿åŠ¨èƒ½åŠ é€Ÿå‹"
        else:
            is_mixed_pattern = True
            mixed_type = "æŠ€æœ¯å¤šå› å­å…±æŒ¯å‹"
    
    # === ç­–ç•¥ç»„åˆè¯„åˆ†æœºåˆ¶ ===
    combination_score = 0
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¼ºåŠ›ç»„åˆ
    has_trend_momentum = trend_count > 0 and momentum_count > 0  # è¶‹åŠ¿+åŠ¨é‡ç»„åˆ
    has_reversal_volume = reversal_count > 0 and "é‡ä»·é½å‡" in strategies  # åè½¬+é‡èƒ½ç»„åˆ
    has_crossline_trend = crossline_count > 0 and trend_count > 0  # ç©¿çº¿+è¶‹åŠ¿ç»„åˆ
    
    if has_trend_momentum:
        combination_score += 10
    if has_reversal_volume:
        combination_score += 8
    if has_crossline_trend:
        combination_score += 12
    
    # === ç¡®å®šä¸»å¯¼ç­–ç•¥ç±»å‹ ===
    dominant_type = ""
    max_count = max(trend_count, momentum_count, reversal_count, crossline_count, 0)  # åŠ 0æ˜¯ä¸ºäº†å¤„ç†æ‰€æœ‰è®¡æ•°éƒ½ä¸º0çš„æƒ…å†µ
    
    if max_count > 0:
        if crossline_count == max_count:
            dominant_type = "ç©¿çº¿"
        elif trend_count == max_count:
            dominant_type = "è¶‹åŠ¿"
        elif momentum_count == max_count:
            dominant_type = "åŠ¨é‡"
        elif reversal_count == max_count:
            dominant_type = "åè½¬"
    else:
        dominant_type = "ç»¼åˆ"
    
    # === ç‰¹æ®Šå¼ºåŠ›ç»„åˆæ£€æµ‹ - æ‰©å±•æ›´å¤šç‰¹æ®Šç»„åˆç±»å‹ ===
    special_combo = ""
    if "æ—­æ—¥ä¸œå‡" in strategies and "é‡ä»·é½å‡" in strategies:
        special_combo = "æ—­æ—¥ä¸œå‡+é‡ä»·é½å‡"
        combination_score += 15
    elif "ä¸€é˜³ç©¿ä¸‰çº¿" in strategies and "MACDé›¶è½´å…±æŒ¯" in strategies:
        special_combo = "ä¸€é˜³ç©¿ä¸‰çº¿+MACDé›¶è½´å…±æŒ¯"
        combination_score += 12
    elif "æ¶¨åœå›è¸©" in strategies and "å‡çº¿å¤šå¤´æ’åˆ—" in strategies:
        special_combo = "æ¶¨åœå›è¸©+å‡çº¿å¤šå¤´"
        combination_score += 10
    elif "å¼ºåŠ¿å›è¸©" in strategies and "OBVåŠ¨é‡å¼•æ“" in strategies:
        special_combo = "å¼ºåŠ¿å›è¸©+OBVåŠ¨é‡"
        combination_score += 10
    # æ–°å¢ç‰¹æ®Šç»„åˆ
    elif "MACDé›¶è½´å…±æŒ¯" in strategies and "å‡çº¿å¤šå¤´æ’åˆ—" in strategies:
        special_combo = "MACDå‡çº¿è¶‹åŠ¿ç»„åˆ"
        combination_score += 10
    elif "KDJåŒå‘ä¸Šæ¶¨" in strategies and "OBVåŠ¨é‡å¼•æ“" in strategies:
        special_combo = "KDJ+OBVåŒæŒ‡æ ‡ç¡®è®¤"
        combination_score += 8
    elif "KDJé‡‘å‰" in strategies and "çŸ­æœŸçªç ´" in strategies:
        special_combo = "KDJé‡‘å‰çŸ­çº¿çªç ´"
        combination_score += 9
    
    # å¦‚æœæ˜¯æ··åˆå‹ä¹°ç‚¹ï¼Œå…ˆå¤„ç†
    if is_mixed_pattern:
        result["pattern_type"] = mixed_type
        result["confidence"] = 85  # å¤šé‡ç¡®è®¤ï¼Œä¿¡å¿ƒæŒ‡æ•°è¾ƒé«˜
        
        if mixed_type == "åè½¬è¶‹åŠ¿æ··åˆå‹":
            result["operation_advice"] = "åº•éƒ¨åè½¬ä¿¡å·å·²å¾—åˆ°è¶‹åŠ¿ç¡®è®¤ï¼Œå»ºè®®åˆ†æ‰¹ä¹°å…¥å¹¶æŒæœ‰ï¼Œå›è¸©ä¸ç ´å‡çº¿å¯åŠ ä»“"
            result["risk_level"] = "ä¸­ä½é£é™©"
            result["stop_loss"] = ma10 * 0.97 if ma10 else low * 0.97
        elif mixed_type == "åå¼¹è¶‹åŠ¿å…±æŒ¯å‹":
            result["operation_advice"] = "è¶…è·Œåå¼¹ä¼´éšMACDé›¶è½´å…±æŒ¯ï¼Œå¼ºåŠ¿ä¿¡å·ï¼Œå¯é€‚é‡ä¹°å…¥å¹¶è®¾ç½®æµ®åŠ¨æ­¢ç›ˆ"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = ma5 * 0.97 if ma5 else low * 0.96
        elif mixed_type == "KDJåè½¬çªç ´å‹":
            result["operation_advice"] = "KDJåè½¬é…åˆä»·æ ¼çªç ´ï¼Œå¼ºåŠ›ä¹°ç‚¹ï¼Œå»ºè®®åŠæ—¶æŠŠæ¡ï¼Œè®¾ç½®å‰ä½æ­¢æŸ"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = low * 0.97
        elif mixed_type == "åº•éƒ¨ç©¿çº¿å¤åˆå‹":
            result["operation_advice"] = "åº•éƒ¨åè½¬ä¿¡å·ä¸ç©¿çº¿å½¢æ€å…±æŒ¯ï¼Œå¼ºåŠ›ä¹°ç‚¹ï¼Œå»ºè®®åˆ†æ‰¹ä¹°å…¥ï¼Œä¸¥æ§é£é™©"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = min(open_price, (open_price + close) / 2)
        elif mixed_type == "èƒŒç¦»æ—­æ—¥ç ´å±€å‹":
            result["operation_advice"] = "MACDåº•èƒŒç¦»é…åˆæ—­æ—¥ä¸œå‡çªç ´ï¼Œå¼ºåŠ›ä¹°ç‚¹ï¼Œå¯æ€è·¯æ€§å»ºä»“ï¼Œè®¾ç½®è¾ƒå®½æ­¢æŸ"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = low * 0.95
        elif mixed_type == "åè½¬åŠ¨èƒ½å¯åŠ¨å‹":
            result["operation_advice"] = "åº•éƒ¨åè½¬é…åˆåŠ¨èƒ½æŒ‡æ ‡å¯åŠ¨ï¼Œå¯èƒ½æ˜¯å¼ºåŠ¿è¡Œæƒ…èµ·ç‚¹ï¼Œå»ºè®®åˆ†æ‰¹è·Ÿè¿›"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = ma5 * 0.97 if ma5 else low * 0.97
        elif mixed_type == "ç©¿çº¿è¶‹åŠ¿åŠ¨èƒ½å…¨é¢å…±æŒ¯å‹":
            result["operation_advice"] = "çªç ´ã€è¶‹åŠ¿ä¸åŠ¨èƒ½ä¸‰é‡å…±æŒ¯ï¼Œå¼ºåŠ¿ä¹°ç‚¹ï¼Œå¯ç§¯æå»ºä»“ï¼Œå›è¸©åŠ ä»“"
            result["risk_level"] = "ä¸­ä½é£é™©"
            result["stop_loss"] = ma5 * 0.98 if ma5 else low * 0.98
            result["confidence"] = 90  # ä¸‰é‡å…±æŒ¯ï¼Œéå¸¸é«˜çš„ä¿¡å¿ƒ
        elif mixed_type == "ä¸€é˜³ç©¿MACDå…±æŒ¯å‹":
            result["operation_advice"] = "ä¸€é˜³ç©¿ä¸‰çº¿é…åˆMACDé›¶è½´å…±æŒ¯ï¼Œè¶‹åŠ¿ç¡®è®¤æ€§å¼ºï¼Œå¯ç«‹è¶³ä½ç‚¹ç§¯æå¸ƒå±€"
            result["risk_level"] = "ä¸­ä½é£é™©"
            result["stop_loss"] = min(open_price, (open_price + close) / 2)
            result["confidence"] = 82
        elif mixed_type == "æ—­æ—¥é‡ä»·å¯åŠ¨å‹":
            result["operation_advice"] = "æ—­æ—¥ä¸œå‡å½¢æ€é…åˆé‡ä»·é½å‡ï¼Œå¼ºåŠ¿çªç ´ï¼Œå»ºè®®å›è¸©æ—¶ç§¯æè·Ÿè¿›"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = low * 0.97
            result["confidence"] = 84
        elif mixed_type == "æ¶¨åœå›è¸©è¶‹åŠ¿ç¡®è®¤å‹":
            result["operation_advice"] = "æ¶¨åœå›è¸©å¾—åˆ°è¶‹åŠ¿ç¡®è®¤ï¼Œå¯å›è¸©æ—¶é€‚é‡å¸ƒå±€ï¼Œæ³¨æ„è§‚å¯Ÿé‡èƒ½é…åˆ"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = ma5 * 0.98 if ma5 else low * 0.97
            result["confidence"] = 80
        elif mixed_type == "å¼ºåŠ¿å›è¸©åŠ¨èƒ½å¼ºåŒ–å‹":
            result["operation_advice"] = "å¼ºåŠ¿è‚¡å›è¸©é…åˆåŠ¨èƒ½æŒ‡æ ‡ï¼Œèµ„é‡‘æ´»è·ƒï¼Œé€‚é‡å¸ƒå±€"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = ma5 * 0.97 if ma5 else low * 0.98
            result["confidence"] = 78
        elif mixed_type == "ç©¿çº¿è¶‹åŠ¿é…åˆå‹":
            result["operation_advice"] = "ç©¿çº¿ä¿¡å·é…åˆè¶‹åŠ¿æŒ‡æ ‡ï¼Œå»ºè®®æ‹©æœºä»‹å…¥ï¼Œè®¾ç½®åˆç†æ­¢æŸ"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = ma10 * 0.97 if ma10 else low * 0.97
            result["confidence"] = 75
        elif mixed_type == "ç©¿çº¿åŠ¨èƒ½åŠ é€Ÿå‹":
            result["operation_advice"] = "ç©¿çº¿ä¿¡å·é…åˆåŠ¨èƒ½æŒ‡æ ‡ï¼Œå¯çŸ­çº¿å¸ƒå±€ï¼ŒåŠæ—¶è·åˆ©äº†ç»“"
            result["risk_level"] = "ä¸­é«˜é£é™©"
            result["stop_loss"] = low * 0.96
            result["confidence"] = 72
        elif mixed_type == "æŠ€æœ¯å¤šå› å­å…±æŒ¯å‹":
            result["operation_advice"] = "å¤šæŒ‡æ ‡è”åˆå…±æŒ¯ï¼Œå¯å®¡æ…è·Ÿè¿›ï¼Œæ³¨æ„è®¾ç½®æ­¢æŸ"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = ma10 * 0.96 if ma10 else low * 0.96
            result["confidence"] = 75
        elif "åè½¬è¶‹åŠ¿å…±æŒ¯å‹" in mixed_type:
            result["operation_advice"] = "åº•éƒ¨åè½¬é…åˆè¶‹åŠ¿ç¡®è®¤ï¼Œå»ºè®®å›è¸©æ”¯æ’‘ä½ä¹°å…¥ï¼Œè®¾ç½®5%æ­¢æŸ"
            result["risk_level"] = "ä¸­é£é™©"
            result["stop_loss"] = ma10 * 0.97 if ma10 else low * 0.97
    
    # ç‰¹æ®Šå¼ºåŠ›ç»„åˆå¤„ç†
    elif special_combo:
        if special_combo == "æ—­æ—¥ä¸œå‡+é‡ä»·é½å‡":
            result["pattern_type"] = "å¼ºåŠ¿çªç ´å¯åŠ¨å‹"
            result["confidence"] = 88
            result["operation_advice"] = "æ—­æ—¥ä¸œå‡é…åˆé‡ä»·é½å‡ï¼Œå¼ºåŠ²ä¸Šæ”»ä¿¡å·ï¼Œå»ºè®®ç§¯æè·Ÿè¿›ï¼Œå›è¸©ä¹°å…¥"
            result["stop_loss"] = low * 0.96
            result["risk_level"] = "ä¸­é£é™©"
        elif special_combo == "ä¸€é˜³ç©¿ä¸‰çº¿+MACDé›¶è½´å…±æŒ¯":
            result["pattern_type"] = "ç©¿çº¿è¶‹åŠ¿å…±æŒ¯å‹"
            result["confidence"] = 85
            result["operation_advice"] = "ä¸€é˜³ç©¿ä¸‰çº¿é…åˆMACDé›¶è½´å…±æŒ¯ï¼Œè¶‹åŠ¿ç¡®è®¤åº¦é«˜ï¼Œå¯ç«‹è¶³ä½ç‚¹ç§¯æè¿›åœº"
            result["stop_loss"] = min(open_price, (open_price + close) / 2)
            result["risk_level"] = "ä¸­é£é™©"
        elif special_combo == "æ¶¨åœå›è¸©+å‡çº¿å¤šå¤´":
            result["pattern_type"] = "æ¶¨åœå›è¸©ç¡®è®¤å‹"
            result["confidence"] = 82
            result["operation_advice"] = "æ¶¨åœå›è¸©ç¡®è®¤å‡çº¿æ”¯æ’‘ï¼Œå¯å›è¸©ä¹°å…¥ï¼Œè®¾ç½®å‰ä½æ­¢æŸ"
            result["stop_loss"] = ma5 * 0.98 if ma5 else low * 0.97
            result["risk_level"] = "ä¸­é£é™©"
        elif special_combo == "å¼ºåŠ¿å›è¸©+OBVåŠ¨é‡":
            result["pattern_type"] = "å¼ºåŠ¿å›è¸©åŠ¨é‡å‹"
            result["confidence"] = 80
            result["operation_advice"] = "å¼ºåŠ¿è‚¡å›è¸©é…åˆOBVåŠ¨é‡ç¡®è®¤ï¼Œèµ„é‡‘ä¿æŒæ´»è·ƒï¼Œå¯èƒŒé å‡çº¿åˆ†æ‰¹ä¹°å…¥"
            result["stop_loss"] = ma5 * 0.97 if ma5 else low * 0.97
            result["risk_level"] = "ä¸­é£é™©"
        # æ–°å¢ç‰¹æ®Šç»„åˆå¤„ç†
        elif special_combo == "MACDå‡çº¿è¶‹åŠ¿ç»„åˆ":
            result["pattern_type"] = "å‡çº¿MACDå…±æŒ¯å‹"
            result["confidence"] = 83
            result["operation_advice"] = "å‡çº¿å¤šå¤´é…åˆMACDé›¶è½´å…±æŒ¯ï¼Œè¶‹åŠ¿æ€§å¼ºï¼Œå»ºè®®æ³¢æ®µæ“ä½œ"
            result["stop_loss"] = ma10 * 0.97 if ma10 else low * 0.97
            result["risk_level"] = "ä¸­ä½é£é™©"
        elif special_combo == "KDJ+OBVåŒæŒ‡æ ‡ç¡®è®¤":
            result["pattern_type"] = "KDJ-OBVåŠ¨èƒ½å‹"
            result["confidence"] = 76
            result["operation_advice"] = "KDJåŒå‘ä¸Šæ¶¨é…åˆOBVåŠ¨é‡ç¡®è®¤ï¼Œè¿‘æœŸèµ„é‡‘é¢è‰¯å¥½ï¼Œå¯åˆ†æ‰¹ä»‹å…¥"
            result["stop_loss"] = ma5 * 0.96 if ma5 else low * 0.96
            result["risk_level"] = "ä¸­é£é™©"
        elif special_combo == "KDJé‡‘å‰çŸ­çº¿çªç ´":
            result["pattern_type"] = "é‡‘å‰çªç ´å‹"
            result["confidence"] = 73
            result["operation_advice"] = "KDJé‡‘å‰å åŠ çŸ­æœŸçªç ´ï¼Œé€‚åˆçŸ­çº¿æ“ä½œï¼Œæ³¨æ„åŠæ—¶æ­¢ç›ˆ"
            result["stop_loss"] = low * 0.96
            result["risk_level"] = "ä¸­é«˜é£é™©"
    
    # æ¶¨åœå›è¸©ç­–ç•¥ç‰¹æ®Šå¤„ç†
    elif "æ¶¨åœå›è¸©" in strategies or recent_limit_up:
        result["pattern_type"] = "æ¶¨åœå›è¸©å‹"
        result["confidence"] = 70
        result["operation_advice"] = "æ¶¨åœæ¬¡æ—¥æ”¯æ’‘å›è¸©ä¹°ç‚¹ï¼Œå»ºè®®å›è¸©ç¨³å®šåå°‘é‡è¯•ä»“ï¼Œæ³¨æ„è§‚å¯Ÿé‡èƒ½é…åˆ"
        result["stop_loss"] = low * 0.97
        result["risk_level"] = "ä¸­é«˜é£é™©"
    
    # å¼ºåŠ¿å›è¸©ç­–ç•¥ç‰¹æ®Šå¤„ç†
    elif "å¼ºåŠ¿å›è¸©" in strategies:
        result["pattern_type"] = "å¼ºåŠ¿å›è¸©å‹"
        result["confidence"] = 75
        result["operation_advice"] = "å¼ºåŠ¿è‚¡å›è¸©å‡çº¿æ”¯æ’‘ï¼Œå¯èƒŒé å‡çº¿ä¹°å…¥ï¼Œæ­¢æŸè®¾ç½®åœ¨å‡çº¿ä¸‹æ–¹"
        result["stop_loss"] = ma5 * 0.97 if ma5 else low * 0.98
        result["risk_level"] = "ä¸­é£é™©"
    
    # ä¸€é˜³ç©¿ä¸‰çº¿ç­–ç•¥ç‰¹æ®Šå¤„ç†
    elif "ä¸€é˜³ç©¿ä¸‰çº¿" in strategies:
        result["pattern_type"] = "çªç ´åè½¬å‹"
        
        # æ£€æŸ¥ç©¿çº¿è´¨é‡
        if isinstance(score_details, dict) and "ç©¿çº¿è¯„åˆ†" in score_details:
            quality = score_details["ç©¿çº¿è¯„åˆ†"]
            if "é«˜è´¨é‡" in quality or "å¼ºåŠ¿" in quality:
                result["confidence"] = 85
                result["operation_advice"] = "é«˜è´¨é‡ç©¿çº¿ä¿¡å·ï¼Œå»ºè®®æ¬¡æ—¥å›è¸©æ—¶åˆ†æ‰¹ä¹°å…¥ï¼Œæ­¢æŸè®¾ç½®åœ¨å½“æ—¥é˜³çº¿å®ä½“ä¸‹æ–¹"
                result["stop_loss"] = min(open_price, (open_price + close) / 2)
                result["risk_level"] = "ä¸­é£é™©"
            else:
                result["confidence"] = 65
                result["operation_advice"] = "å»ºè®®ç­‰å¾…å›è¸©5æ—¥çº¿ç¡®è®¤åå°‘é‡ä¹°å…¥ï¼Œæ³¨æ„é‡èƒ½é…åˆ"
                result["stop_loss"] = ma5 * 0.97 if ma5 else low * 0.98
                result["risk_level"] = "ä¸­é«˜é£é™©"
        else:
            result["confidence"] = 75
            result["operation_advice"] = "ç©¿ä¸‰çº¿ä¿¡å·æ˜ç¡®ï¼Œå»ºè®®æ¬¡æ—¥è§‚å¯Ÿå¼€ç›˜åŠå°æ—¶èµ°åŠ¿ï¼Œå¼ºåŠ¿çªç ´å‰é«˜å¯è·Ÿè¿›"
            result["stop_loss"] = low * 0.97
            result["risk_level"] = "ä¸­é£é™©"
    
    # æ—­æ—¥ä¸œå‡ç­–ç•¥ç‰¹æ®Šå¤„ç†
    elif "æ—­æ—¥ä¸œå‡" in strategies:
        result["pattern_type"] = "çªç ´èµ·åŠ¿å‹"
        
        # æ£€æŸ¥çªç ´è´¨é‡
        if isinstance(score_details, dict) and "çªç ´è¯„åˆ†" in score_details:
            quality = score_details["çªç ´è¯„åˆ†"]
            if "å¼ºåŠ¿" in quality:
                result["confidence"] = 85
                result["operation_advice"] = "å¼ºåŠ¿çªç ´ä¿¡å·ï¼Œå»ºè®®å°¾ç›˜å°‘é‡å¸ç­¹ï¼Œæ¬¡æ—¥å†²é«˜éœ‡è¡å¯åŠ ä»“ï¼Œæ³¨æ„ä¸»åŠ›èµ„é‡‘åŠ¨å‘"
                result["stop_loss"] = low * 0.97
                result["risk_level"] = "ä¸­é£é™©"
            else:
                result["confidence"] = 70
                result["operation_advice"] = "å»ºè®®æ¬¡æ—¥è§‚å¯Ÿç¡®è®¤ï¼Œè‹¥æƒ¯æ€§ä¸Šæ”»åˆ™è¿½å…¥ï¼Œå›è¸©ä¸ç ´å½“æ—¥ä½ç‚¹å¯åˆ†æ‰¹ä¹°å…¥"
                result["stop_loss"] = low * 0.96
                result["risk_level"] = "ä¸­é«˜é£é™©"
        else:
            result["confidence"] = 80
            result["operation_advice"] = "æ—­æ—¥ä¸œå‡å½¢æ€çªç ´å‹åŠ›ä½ï¼Œå»ºè®®å°‘é‡å…ˆä¹°ï¼Œå›è¸©ä¸ç ´5æ—¥çº¿å¯åŠ ä»“"
            result["stop_loss"] = ma5 * 0.97 if ma5 else low * 0.96
            result["risk_level"] = "ä¸­é£é™©"
    
    # å¦‚æœè¿˜æ²¡æœ‰ç¡®å®šä¹°ç‚¹ç±»å‹ï¼Œåˆ™æ ¹æ®ä¸»å¯¼ç­–ç•¥ç±»å‹ç¡®å®š
    elif not result["pattern_type"]:
        # è¶‹åŠ¿å‹ç­–ç•¥å¤„ç†
        if dominant_type == "è¶‹åŠ¿" or trend_count >= 2:
            result["pattern_type"] = "è¶‹åŠ¿ç¡®è®¤å‹"
            result["confidence"] = 80
            
            if "KDJåŒå‘ä¸Šæ¶¨" in strategies:
                result["operation_advice"] = "KDJä¸‰çº¿åŒå‘ä¸Šè¡Œï¼Œé…åˆå‡çº¿å¤šå¤´æ’åˆ—ï¼Œå»ºè®®é€‚é‡ä¹°å…¥ï¼Œè®¾ç½®5%æ­¢æŸ"
                result["confidence"] = 82
            elif "çŸ­æœŸçªç ´" in strategies:
                result["operation_advice"] = "çŸ­æœŸçªç ´åå¯èƒ½ç»§ç»­ä¸Šæ”»ï¼Œå»ºè®®æ¬¡æ—¥é«˜å¼€ä¸è¶…3%å¯ä»‹å…¥ï¼Œä¸¥æ§é£é™©"
                result["confidence"] = 75
            elif "å‡çº¿å¤šå¤´æ’åˆ—" in strategies and "MACDé›¶è½´å…±æŒ¯" in strategies:
                result["operation_advice"] = "å‡çº¿å¤šå¤´æ’åˆ—é…åˆMACDé›¶è½´å…±æŒ¯ï¼Œå¼ºåŠ¿æ ¼å±€ï¼Œå¯åˆ†æ‰¹è¿½å…¥ï¼Œä¸¥æ ¼è®¾ç½®æ­¢æŸ"
                result["confidence"] = 85
            else:
                result["operation_advice"] = "è¶‹åŠ¿è‰¯å¥½ï¼Œå»ºè®®å›è¸©5æ—¥çº¿æ—¶ä¹°å…¥ï¼Œæ­¢æŸè®¾ç½®åœ¨5æ—¥çº¿ä¸‹æ–¹"
            
            result["stop_loss"] = ma5 * 0.98 if ma5 else close * 0.95
            result["risk_level"] = "ä¸­ä½é£é™©"
        
        # åŠ¨é‡å‹ç­–ç•¥å¤„ç†
        elif dominant_type == "åŠ¨é‡" or momentum_count >= 2:
            result["pattern_type"] = "é‡ä»·å…±æŒ¯å‹"
            result["confidence"] = 75
            
            if "KDJé‡‘å‰" in strategies:
                result["operation_advice"] = "KDJé‡‘å‰æŒ‡æ ‡å‘å¥½ï¼ŒçŸ­æœŸåŠ¨èƒ½å¼ºï¼Œå»ºè®®åˆ†æ‰¹è·Ÿè¿›ï¼Œè®¾ç½®5%æ­¢æŸ"
            elif "ä¸»åŠ›èµ„é‡‘å…±æŒ¯" in strategies:
                result["operation_advice"] = "ä¸»åŠ›èµ„é‡‘ç§¯æä»‹å…¥ï¼Œå¯èƒŒé å‡çº¿é€‚é‡ä¹°å…¥ï¼Œæ³¨æ„æˆäº¤é‡é…åˆ"
                result["confidence"] = 80
            elif "OBVåŠ¨é‡å¼•æ“" in strategies and "é‡ä»·é½å‡" in strategies:
                result["operation_advice"] = "é‡ä»·ä¸OBVå…±åŒä¸Šå‡ï¼Œèµ„é‡‘æµå…¥æ˜æ˜¾ï¼ŒçŸ­çº¿å¯é€‚é‡è·Ÿè¿›ï¼Œéšæ—¶è®¾å¥½æ­¢æŸ"
                result["confidence"] = 82
            else:
                result["operation_advice"] = "é‡ä»·é…åˆè‰¯å¥½ï¼Œå»ºè®®æ¬¡æ—¥ä½å¼€æ—¶åŠ ä»“ï¼Œå›è¸©ä¸ç ´10æ—¥çº¿"
            
            result["stop_loss"] = ma10 * 0.98 if ma10 else close * 0.93
            result["risk_level"] = "ä¸­é£é™©"
        
        # åè½¬å‹ç­–ç•¥å¤„ç†
        elif dominant_type == "åè½¬" or reversal_count >= 1:
            result["pattern_type"] = "åº•éƒ¨åè½¬å‹"
            result["confidence"] = 70
            
            if "MACDåº•èƒŒç¦»" in strategies:
                result["operation_advice"] = "MACDåº•èƒŒç¦»æ˜¾ç¤ºå¯èƒ½è§¦åº•ï¼Œå»ºè®®å°‘é‡è¯•æ¢æ€§ä¹°å…¥ï¼Œä¸¥æ ¼è®¾ç½®æ­¢æŸ"
                result["confidence"] = 75
            elif "KDJè¶…å–åè½¬" in strategies:
                result["operation_advice"] = "KDJè¶…å–åè½¬ä¿¡å·ï¼Œå»ºè®®åˆ†æ‰¹è¯•æ¢æ€§ä¹°å…¥ï¼Œæ³¨é‡ä»“ä½æ§åˆ¶"
                result["confidence"] = 65
            else:
                result["operation_advice"] = "å¯èƒ½è§¦åº•åå¼¹ï¼Œå»ºè®®åˆ†æ‰¹å°ä»“ä½è¯•æ¢æ€§ä¹°å…¥ï¼Œæ³¨æ„æ­¢æŸä¿æŠ¤"
            
            result["stop_loss"] = low * 0.97
            result["risk_level"] = "ä¸­é«˜é£é™©"
        
        # å¼ºåŠ›ç»„åˆç­–ç•¥
        elif has_trend_momentum and combination_score > 15:
            result["pattern_type"] = "è¶‹åŠ¿åŠ¨èƒ½å¤åˆå‹"
            result["confidence"] = 88
            result["operation_advice"] = "è¶‹åŠ¿ä¸åŠ¨èƒ½åŒé‡ç¡®è®¤ï¼Œå»ºè®®æ¬¡æ—¥æ—©ç›˜é€‚é‡ä¹°å…¥ï¼Œé€¢å›è°ƒåŠ ä»“ï¼Œè®¾ç½®5%æ­¢æŸ"
            result["stop_loss"] = ma10 * 0.95 if ma10 else close * 0.95
            result["risk_level"] = "ä¸­ä½é£é™©"
        
        # æ··åˆå‹æˆ–å…¶ä»–æƒ…å†µ
        else:
            result["pattern_type"] = "ç»¼åˆä¿¡å·å‹"
            result["confidence"] = 65 + min(combination_score, 15)  # æœ€é«˜æå‡15ç‚¹ä¿¡å¿ƒ
            result["operation_advice"] = "å¤šæŒ‡æ ‡å…±æŒ¯ï¼Œå»ºè®®æ¬¡æ—¥è§‚å¯Ÿå¼€ç›˜èµ°åŠ¿ï¼Œä»·æ ¼ç«™ç¨³å‡çº¿åå°‘é‡ä»‹å…¥"
            result["stop_loss"] = ma10 * 0.97 if ma10 else close * 0.94
            result["risk_level"] = "ä¸­é£é™©"
    
    # === æ ¹æ®é£é™©è­¦å‘Šè°ƒæ•´å»ºè®® ===
    if risk_count > 0:
        result["confidence"] = max(40, result["confidence"] - 15)
        result["operation_advice"] = f"{result['operation_advice']}ï¼Œæ³¨æ„å­˜åœ¨æŠ€æœ¯é£é™©ä¿¡å·ï¼Œå»ºè®®é™ä½ä»“ä½"
        result["risk_level"] = "é«˜é£é™©"
    
    for warning in risk_warnings:
        if "æ¶¨åœ" in warning and "è¿½é«˜é£é™©" in warning:
            result["confidence"] = max(40, result["confidence"] - 10)
            result["operation_advice"] = "è¿‘æœŸæ¶¨åœï¼Œè¿½é«˜é£é™©å¤§ï¼Œå»ºè®®ç­‰å¾…å›è°ƒä¼ç¨³åå†è€ƒè™‘è¿›å…¥"
            result["risk_level"] = "é«˜é£é™©"
            break
    
    # === æ ¹æ®æ¢æ‰‹ç‡è¯„ä»·è°ƒæ•´å»ºè®® ===
    if isinstance(score_details, dict) and 'æ¢æ‰‹ç‡è¯„ä»·' in score_details:
        turnover_eval = score_details['æ¢æ‰‹ç‡è¯„ä»·']
        
        if 'è¿‡é«˜' in turnover_eval:
            result["confidence"] = max(40, result["confidence"] - 5)
            result["operation_advice"] += "ï¼Œæ¢æ‰‹ç‡è¿‡é«˜æ³¨æ„çŸ­æœŸé£é™©"
        elif 'ç†æƒ³' in turnover_eval and 'é«˜äºå†å²' in turnover_eval:
            result["confidence"] = min(95, result["confidence"] + 5)
            if 'æ˜æ˜¾ä¸Šå‡' in turnover_eval:
                result["operation_advice"] += "ï¼Œæ¢æ‰‹æ´»è·ƒåº¦å¼ºï¼Œèµ„é‡‘å…³æ³¨åº¦é«˜"
    
    # === æ ¹æ®ç­–ç•¥æ¨¡å¼è°ƒæ•´æœ€ç»ˆå»ºè®® ===
    if strategy_mode == "ç©¿çº¿å‹" and not any(s in strategies for s in crossline_strategies):
        result["operation_advice"] += "ï¼Œä¸ç¬¦åˆç©¿çº¿ç­–ç•¥æ ¸å¿ƒæ¡ä»¶ï¼Œå»ºè®®è°¨æ…"
        result["confidence"] = max(40, result["confidence"] - 10)
    
    elif strategy_mode == "ç¨³å¥å‹" and result["confidence"] < 70:
        result["operation_advice"] = f"ç¨³å¥ç­–ç•¥ä¸‹{result['operation_advice']}ï¼Œå»ºè®®é™ä½ä»“ä½æˆ–è§‚æœ›"
        result["confidence"] = max(40, result["confidence"] - 5)
    
    elif strategy_mode == "æ¿€è¿›å‹" and result["confidence"] > 65:
        if result["confidence"] >= 80:
            result["operation_advice"] += "ï¼Œæ¿€è¿›ç­–ç•¥å¯é€‚åº¦æé«˜ä»“ä½"
            result["confidence"] = min(95, result["confidence"] + 5)
    
    # === æ–°å¢ï¼šæ·»åŠ ä½é£é™©è‚¡ç¥¨è¯†åˆ«é€»è¾‘ ===
    # 1. ç¨³å¥å‹ç­–ç•¥çš„ä½é£é™©è¯†åˆ«ï¼ˆåå‘è¶‹åŠ¿å‹ï¼‰
    if strategy_mode == "ç¨³å¥å‹":
        # æœ‰è¶‹åŠ¿å‹æŒ‡æ ‡ï¼Œä¸”æ— é£é™©è­¦å‘Šï¼Œä¸”æ³¢åŠ¨ç‡è¾ƒä½ï¼Œå¯å‡çº§ä¸ºä½é£é™©
        if (dominant_type == "è¶‹åŠ¿" or trend_count >= 2) and result["risk_level"] == "ä¸­ä½é£é™©":
            trend_low_risk_conditions = [
                # å‡çº¿å¤šå¤´æ’åˆ—æ˜¯ä½é£é™©è¶‹åŠ¿ä¿¡å·
                "å‡çº¿å¤šå¤´æ’åˆ—" in strategies,
                # MACDé›¶è½´å…±æŒ¯ä¹Ÿæ˜¯å¯é ç¡®è®¤ä¿¡å·
                "MACDé›¶è½´å…±æŒ¯" in strategies,
                # æ²¡æœ‰é£é™©è­¦å‘Š
                len(risk_warnings) == 0,
                # ç›¸å¯¹å¼ºåº¦å¥½
                isinstance(score_details, dict) and score_details.get('å¸‚åœºä¸­æ€§å¾—åˆ†', 0) > 5,
                # æ³¢åŠ¨ç‡è¾ƒä½
                volatility < 2.0
            ]
            
            # æ»¡è¶³è‡³å°‘3ä¸ªæ¡ä»¶ï¼Œè¯„ä¸ºä½é£é™©
            if sum(1 for c in trend_low_risk_conditions if c) >= 3:
                result["risk_level"] = "ä½é£é™©"
                result["operation_advice"] = f"ç¨³å¥è¶‹åŠ¿å‹ä½é£é™©æœºä¼šï¼š{result['operation_advice']}"
                result["confidence"] = min(95, result["confidence"] + 5)
                
    # 2. æ¿€è¿›å‹ç­–ç•¥çš„ä½é£é™©è¯†åˆ«
    elif strategy_mode == "æ¿€è¿›å‹":
        # åŠ¨é‡å‹çš„ä½é£é™©æ¡ä»¶ - å³ä½¿åœ¨æ¿€è¿›å‹ç­–ç•¥ä¸­ï¼ŒæŸäº›ç»„åˆä¹Ÿå¯ä»¥æ˜¯ä½é£é™©
        if (dominant_type == "åŠ¨é‡" or momentum_count >= 2) and result["risk_level"] == "ä¸­ä½é£é™©":
            momentum_low_risk_conditions = [
                # ä¸»åŠ›èµ„é‡‘å…±æŒ¯ä½†æ³¢åŠ¨ç‡å—æ§
                "ä¸»åŠ›èµ„é‡‘å…±æŒ¯" in strategies and volatility < 2.5,
                # é‡ä»·é½å‡ä¸”ä»·æ ¼åœ¨å‡çº¿ä¸Šæ–¹
                "é‡ä»·é½å‡" in strategies and ma20 and technical_data['close'].iloc[-1] > ma20 if 'close' in technical_data.columns and ma20 else False,
                # æ²¡æœ‰é£é™©è­¦å‘Š
                len(risk_warnings) == 0,
                # æŠ€æœ¯ç¡®è®¤åº¦é«˜
                result["confidence"] >= 85
            ]
            
            if sum(1 for c in momentum_low_risk_conditions if c) >= 3:
                result["risk_level"] = "ä½é£é™©"
                result["operation_advice"] = f"æ¿€è¿›ç­–ç•¥ä¸‹çš„æ§åˆ¶é£é™©æœºä¼šï¼š{result['operation_advice']}"
    
    # 3. ç©¿çº¿å‹ç­–ç•¥çš„ä½é£é™©è¯†åˆ«
    elif strategy_mode == "ç©¿çº¿å‹":
        # ç©¿çº¿å‹é€šå¸¸ä¸æ˜¯ä½é£é™©ï¼Œä½†å¦‚æœæœ‰å¼ºæœ‰åŠ›çš„ç¡®è®¤ï¼Œä¹Ÿå¯ä»¥é™ä½é£é™©è¯„çº§
        if crossline_count >= 1 and trend_count >= 2 and result["risk_level"] == "ä¸­ä½é£é™©":
            crossline_low_risk_conditions = [
                # ä¸€é˜³ç©¿ä¸‰çº¿ä¸”è´¨é‡é«˜
                "ä¸€é˜³ç©¿ä¸‰çº¿" in strategies and isinstance(score_details, dict) and score_details.get("ç©¿çº¿è¯„åˆ†", "") == "ğŸ”¥é«˜è´¨é‡ç©¿çº¿",
                # è¾…åŠ©è¶‹åŠ¿ç¡®è®¤
                "å‡çº¿å¤šå¤´æ’åˆ—" in strategies or "MACDé›¶è½´å…±æŒ¯" in strategies,
                # æ²¡æœ‰é£é™©è­¦å‘Š
                len(risk_warnings) == 0,
                # ä¿¡å¿ƒæŒ‡æ•°é«˜
                result["confidence"] >= 88
            ]
            
            if sum(1 for c in crossline_low_risk_conditions if c) >= 3:
                result["risk_level"] = "ä½é£é™©"
                result["operation_advice"] = f"é«˜ç¡®è®¤åº¦ç©¿çº¿ä½é£é™©æœºä¼šï¼š{result['operation_advice']}"
    
    # 4. é€šç”¨ä½é£é™©æƒ…å†µè¯†åˆ« - é€‚ç”¨äºæ‰€æœ‰ç­–ç•¥æ¨¡å¼
    # æŸäº›æŠ€æœ¯ç‰¹å¾ç»„åˆå¤©ç„¶é£é™©è¾ƒä½
    if all(s in strategies for s in ["å‡çº¿å¤šå¤´æ’åˆ—", "MACDé›¶è½´å…±æŒ¯"]) and len(risk_warnings) == 0:
        if result["confidence"] >= 85 and (result["risk_level"] == "ä¸­ä½é£é™©" or result["risk_level"] == "ä¸­é£é™©"):
            result["risk_level"] = "ä½é£é™©"
            result["operation_advice"] = f"æŠ€æœ¯é¢ç¨³å¥æ€§å¼ºï¼Œ{result['operation_advice']}"
    
    # ä½æ³¢åŠ¨ç‡+è‰¯å¥½åŸºæœ¬é¢è¯„åˆ†ä¿ƒä½¿ä½é£é™©
    if volatility < 1.5 and isinstance(score_details, dict) and score_details.get('åŸºæœ¬é¢å¾—åˆ†', 0) > 8:
        if result["risk_level"] == "ä¸­ä½é£é™©" and len(risk_warnings) == 0:
            result["risk_level"] = "ä½é£é™©"
            result["operation_advice"] = f"åŸºæœ¬é¢è¯„åˆ†ä¼˜å¼‚ä¸”æ³¢åŠ¨å°ï¼Œ{result['operation_advice']}"
    
    # æ ¼å¼åŒ–æ­¢æŸä½æ˜¾ç¤ºï¼Œä¿ç•™ä¸¤ä½å°æ•°
    result["stop_loss"] = round(result["stop_loss"], 2)
    
    return result




















# ===== ä¸ªè‚¡æŸ¥è¯¢ Tab æ›´æ–°ï¼šæ·»åŠ è¯¦ç»†åˆ†æ =====
def query_stock(ts_code: str) -> str:
    stock_info = StockAnalyzer.get_single_stock_info(ts_code)
    if not stock_info:
        return "âŒ æœªæ‰¾åˆ°è¯¥è‚¡ç¥¨æˆ–æ•°æ®è·å–å¤±è´¥"
    
    basic = stock_info['basic_info']
    price = stock_info['price_info']
    signals = stock_info['technical_signals']
    signal_msgs = [f"ğŸ”¹ {s}: {'âœ…' if v else 'âŒ'}" for s, v in signals.items() if v]
    

    
    result = f"""
ğŸ“ˆ è‚¡ç¥¨ä¿¡æ¯ [{basic['ts_code']}]
----------------------------
åç§°ï¼š{basic['name']}
è¡Œä¸šï¼š{basic.get('industry', 'N/A')}
ä¸Šå¸‚æ—¥æœŸï¼š{basic['list_date']}
å¸‚åœºï¼š{basic['market']}

ğŸ’µ æœ€æ–°è¡Œæƒ…ï¼ˆ{price['trade_date']}ï¼‰
----------------------------
æ”¶ç›˜ä»·ï¼š{price['close']}
æ¶¨è·Œå¹…ï¼š{price['pct_chg']}%
æˆäº¤é‡ï¼š{price['vol']/10000:.2f}ä¸‡æ‰‹
æˆäº¤é¢ï¼š{price['amount']/10000:.2f}ä¸‡å…ƒ

ğŸ“Š æŠ€æœ¯ä¿¡å·
----------------------------
{'\n'.join(signal_msgs) if signal_msgs else 'âš ï¸ æœªè§¦å‘ä»»ä½•æŠ€æœ¯ä¿¡å·'}


"""
    return result

# ===== é»˜è®¤å€¼é…ç½® =====
DEFAULT_TURNOVER = 8000   # ä»Šæ—¥æˆäº¤é¢é»˜è®¤å€¼ï¼ˆäº¿å…ƒï¼‰
DEFAULT_AVG_TURNOVER = 9000  # è¿‘30æ—¥å¹³å‡æˆäº¤é¢é»˜è®¤å€¼ï¼ˆäº¿å…ƒï¼‰
# ===== æ¶¨åœæ•°æ®æ–‡ä»¶ç¼“å­˜ =====
LIMIT_UP_CACHE_FILE = 'limit_up_cache.json'

# å¯åŠ¨æ—¶åŠ è½½ç¼“å­˜
if os.path.exists(LIMIT_UP_CACHE_FILE):
    with open(LIMIT_UP_CACHE_FILE, 'r', encoding='utf-8') as f:
        _limit_up_cache = json.load(f)
else:
    _limit_up_cache = {}

# ===== ç¼“å­˜ä»Šæ—¥è¡Œæƒ…æ•°æ®ï¼Œé¿å…é‡å¤è°ƒç”¨ =====
_daily_data_cache = None
def get_last_trade_date() -> str:
    """è·å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥"""
    today = datetime.today()
    while today.weekday() >= 5:  # å‘¨å…­æ—¥
        today -= timedelta(days=1)
    return today.strftime('%Y%m%d')

def get_daily_data(trade_date: str):
    global _daily_data_cache
    if _daily_data_cache is None or _daily_data_cache.get('date') != trade_date:
        df = safe_api_call(pro.daily, trade_date=trade_date, fields='ts_code,pct_chg')
        _daily_data_cache = {'date': trade_date, 'data': df}
    return _daily_data_cache['data'] if _daily_data_cache else pd.DataFrame()

def get_up_stock_count(trade_date: str) -> int:
    try:
        df = get_daily_data(trade_date)
        return (df['pct_chg'] > 0).sum() if not df.empty else 0
    except:
        return 0

def get_down_stock_count(trade_date: str) -> int:
    try:
        df = get_daily_data(trade_date)
        return (df['pct_chg'] < 0).sum() if not df.empty else 0
    except:
        return 0

def get_today_turnover(trade_date: str) -> float:
    """è·å–ä¸Šè¯æŒ‡æ•°çš„æˆäº¤é¢ï¼ˆäº¿å…ƒï¼‰"""
    try:
        df = safe_api_call(pro.index_daily, ts_code='000001.SH', trade_date=trade_date, fields='trade_date,vol,amount')
        if not df.empty and 'amount' in df.columns:
            return df['amount'].iloc[0] / 10000  # æ¢ç®—ä¸ºäº¿å…ƒ
        return DEFAULT_TURNOVER
    except:
        return DEFAULT_TURNOVER

def get_avg_turnover_30d(trade_date: str) -> float:
    """è·å–ä¸Šè¯æŒ‡æ•°è¿‘30æ—¥å¹³å‡æˆäº¤é¢ï¼ˆäº¿å…ƒï¼‰"""
    try:
        end = datetime.strptime(trade_date, '%Y%m%d')
        start = end - timedelta(days=40)
        df = safe_api_call(pro.index_daily, ts_code='000001.SH', start_date=start.strftime('%Y%m%d'), end_date=end.strftime('%Y%m%d'), fields='trade_date,amount')
        if not df.empty:
            return df['amount'].mean() / 10000
        return DEFAULT_AVG_TURNOVER
    except:
        return DEFAULT_AVG_TURNOVER


def get_limit_up_count(trade_date: str) -> int:
    """è·å–å½“æ—¥æ¶¨åœè‚¡æ•°é‡ï¼Œå¸¦æ–‡ä»¶ç¼“å­˜"""
    if trade_date in _limit_up_cache:
        logger.info(f"[æ¶¨åœç»Ÿè®¡] ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼š{trade_date} æ¶¨åœè‚¡æ•°é‡ï¼š{_limit_up_cache[trade_date]}")
        return _limit_up_cache[trade_date]

    try:
        df = safe_api_call(
            pro.limit_list_d,
            trade_date=trade_date,
            limit_type='U',
            fields='ts_code'
        )
        if df is None or df.empty:
            logger.warning(f"[æ¶¨åœç»Ÿè®¡] {trade_date} æ— æ¶¨åœæ•°æ®è¿”å›ï¼Œç¼“å­˜ä¸º0")
            _limit_up_cache[trade_date] = 0
            save_limit_up_cache()
            return 0

        count = len(df)
        _limit_up_cache[trade_date] = count
        save_limit_up_cache()
        logger.info(f"[æ¶¨åœç»Ÿè®¡] {trade_date} æ¶¨åœè‚¡æ•°é‡ï¼š{count}")
        return count

    except Exception as e:
        logger.error(f"[æ¶¨åœç»Ÿè®¡] è·å–æ¶¨åœæ•°æ®å¤±è´¥ï¼š{e}ï¼Œç¼“å­˜ä¸º0")
        _limit_up_cache[trade_date] = 0
        save_limit_up_cache()
        return 0


def save_limit_up_cache():
    with open(LIMIT_UP_CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(_limit_up_cache, f, ensure_ascii=False, indent=2)

# ===== æ–°å¢ï¼šå¼ºåˆ¶åˆ·æ–°å¸‚åœºæƒ…ç»ª =====
def refresh_market_sentiment() -> str:
    global _last_sentiment_date, _cached_sentiment, _limit_up_cache
    # 1) æ¸…æ‰ä»Šæ—¥æƒ…ç»ªç¼“å­˜
    _last_sentiment_date = None
    _cached_sentiment = None

    # 2) æ¸…æ‰å½“æ—¥æ¶¨åœè‚¡æ–‡ä»¶ç¼“å­˜ï¼Œè®© get_limit_up_count é‡æ–°æ‹‰å–
    today = datetime.today().strftime('%Y%m%d')
    trade_date = get_last_trade_date() if datetime.today().weekday() >= 5 else today
    if trade_date in _limit_up_cache:
        del _limit_up_cache[trade_date]
        save_limit_up_cache()

    # 3) å†æ¬¡è¿”å›æœ€æ–°çš„å¸‚åœºæƒ…ç»ª
    return get_market_sentiment_ui()

# ===== å¸‚åœºæƒ…ç»ªç¼“å­˜æœºåˆ¶ =====
_last_sentiment_date = None
_cached_sentiment = None

def get_market_sentiment_ui():
    global _last_sentiment_date, _cached_sentiment
    today = datetime.today().strftime('%Y%m%d')

    # åˆ¤æ–­æ˜¯å¦ä¼‘å¸‚
    is_weekend = datetime.today().weekday() >= 5
    trade_date = get_last_trade_date() if is_weekend else today

    if _last_sentiment_date == today and _cached_sentiment:
        sentiment, description = _cached_sentiment
    else:
        sentiment, description = calculate_market_sentiment()
        _cached_sentiment = (sentiment, description)
        _last_sentiment_date = today

    # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
    display_date = datetime.strptime(trade_date, '%Y%m%d').strftime('%Y-%m-%d')
    notice = f"ğŸ“… æ•°æ®æ—¥æœŸï¼š{display_date}"
    if is_weekend:
        notice += " ï¼ˆä»Šæ—¥ä¼‘å¸‚ï¼Œå±•ç¤ºæœ€è¿‘äº¤æ˜“æ—¥æ•°æ®ï¼‰"

    return f"{notice}\n\nğŸ“Š å½“å‰å¸‚åœºæƒ…ç»ªï¼š**{sentiment}**\n\n{description}"


def calculate_market_sentiment() -> Tuple[str, str]:
    # åˆ¤æ–­æ˜¯å¦ä¼‘å¸‚
    is_weekend = datetime.today().weekday() >= 5
    trade_date = get_last_trade_date() if is_weekend else datetime.today().strftime('%Y%m%d')

    if is_weekend:
        logger.info(f"[å¸‚åœºæƒ…ç»ª] ä»Šæ—¥ä¼‘å¸‚ï¼Œä½¿ç”¨æœ€è¿‘äº¤æ˜“æ—¥æ•°æ®ï¼š{trade_date}")
    else:
        logger.info(f"[å¸‚åœºæƒ…ç»ª] ä½¿ç”¨ä»Šæ—¥æ•°æ®ï¼š{trade_date}")

    # è·å–æ•°æ®ï¼ˆè¿™é‡Œä½ éœ€è¦æ”¹é€ å„ä¸ªæ–¹æ³•æ”¯æŒä¼ å…¥ trade_dateï¼‰
    up_count = get_up_stock_count(trade_date)
    down_count = get_down_stock_count(trade_date)
    turnover = get_today_turnover(trade_date)
    avg_turnover = get_avg_turnover_30d(trade_date)
    limit_up_count = get_limit_up_count(trade_date)

    logger.info(f"[å¸‚åœºæƒ…ç»ª] æŒ‡æ ‡ => ä¸Šæ¶¨: {up_count} | ä¸‹è·Œ: {down_count} | æˆäº¤é¢: {turnover:.2f} äº¿ | 30æ—¥å‡é‡: {avg_turnover:.2f} äº¿ | æ¶¨åœæ•°: {limit_up_count}")

    score = 0
    up_down_score = (up_count / (down_count + 1)) * 20
    turnover_score = (turnover / avg_turnover) * 30
    limit_up_score = min(limit_up_count, 50) * 1.5

    score = up_down_score + turnover_score + limit_up_score

    logger.info(f"[å¸‚åœºæƒ…ç»ª] è¯„åˆ† => æ¶¨è·Œæ¯”: {up_down_score:.2f} | æˆäº¤é¢: {turnover_score:.2f} | æ¶¨åœ: {limit_up_score:.2f} | æ€»åˆ†: {score:.2f}")

    if score > 100:
        sentiment = "ä¹è§‚"
        description = "ğŸ˜„ å½“å‰å¸‚åœºæ´»è·ƒï¼Œé¢˜æè½®åŠ¨åŠ å¿«ï¼Œé€‚åˆçŸ­çº¿æ“ä½œ"
    elif score < 60:
        sentiment = "æ‚²è§‚"
        description = "ğŸ˜Ÿ å¸‚åœºä½è¿·ï¼Œæ³¨æ„æ§åˆ¶é£é™©ï¼Œé˜²å®ˆä¸ºä¸»"
    else:
        sentiment = "éœ‡è¡"
        description = "ğŸ˜ å¸‚åœºè§‚æœ›æƒ…ç»ªæµ“åšï¼Œç²¾é€‰ä¼˜è´¨æ ‡çš„"

    logger.info(f"[å¸‚åœºæƒ…ç»ª] æœ€ç»ˆåˆ¤æ–­ï¼š{sentiment}ï¼ˆ{score:.2f} åˆ†ï¼‰")

    return sentiment, description

# ===== åˆ›å»ºGradioç•Œé¢ =====
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ“ˆ é‡åŒ–é€‰è‚¡å·¥å…· (V25.5.19)
    **åŠŸèƒ½**:
    - ä½¿ç”¨Tushareè·å–å½“æ—¥æ•°æ®ï¼ˆæ™šä¸Š8ç‚¹å·¦å³æ›´æ–°å®Œæ¯•ï¼‰            
    - æ”¯æŒè‡ªç„¶è¯­è¨€ç­–ç•¥è¾“å…¥
    - æŠ€æœ¯æŒ‡æ ‡åˆ†æ
    - æ¨èå†å²è®°å½•ç®¡ç†
    - ä¸ªè‚¡è¯¦æƒ…æŸ¥è¯¢
    """)

    # ===== å¸‚åœºæƒ…ç»ªå±•ç¤º =====
    with gr.Row():
        sentiment_box = gr.Markdown(get_market_sentiment_ui())
        refresh_sentiment_btn = gr.Button("ğŸ”„ åˆ·æ–°å¸‚åœºæƒ…ç»ª")
        refresh_sentiment_btn.click(fn=refresh_market_sentiment, outputs=sentiment_box)

    with gr.Row():
        with gr.Column(scale=3):
            # é€‰è‚¡åˆ†æç»“æœçª—å£ï¼ˆä¿ç•™ï¼‰
            chatbot = gr.Chatbot(height=500, label="é€‰è‚¡åˆ†æ")
            
            # è¾“å…¥æ¡†ï¼ˆç§»é™¤æˆ–éšè—ï¼‰
            # txt = gr.Textbox(label="è¾“å…¥é€‰è‚¡ç­–ç•¥", 
            #                  placeholder="ä¾‹å¦‚: æ‰¾å‡ºMACDé‡‘å‰ä¸”æˆäº¤é‡æ”¾å¤§çš„è‚¡ç¥¨ï¼Œå¦‚æœä½ æƒ³ç›´æ¥è·å–æ™ºèƒ½æ¨èï¼Œå¯ä»¥è¾“å…¥"æ¨èè‚¡ç¥¨"",
            #                  visible=False)  # æˆ–è€…ç›´æ¥æ³¨é‡Šæ‰
            
        with gr.Column(scale=1):
            market_type = gr.CheckboxGroup(
                choices=list(MARKET_SECTORS.keys()),
                value=["ä¸»æ¿"],
                label="é€‰æ‹©å¸‚åœº/æ¿å—"
            )
            with gr.Accordion("é«˜çº§é€‰é¡¹", open=True):
                max_stocks = gr.Slider(
                    minimum=100,
                    maximum=5500,
                    step=100,
                    value=Config.MAX_STOCKS_TO_ANALYZE,
                    label="æœ€å¤§åˆ†æè‚¡ç¥¨æ•°é‡"
                )
                strategy_mode = gr.Radio(
                    choices=["ç¨³å¥å‹", "æ¿€è¿›å‹", "ç©¿çº¿å‹"], 
                    value="ç¨³å¥å‹",
                    label="ç­–ç•¥æ¨¡å¼é€‰æ‹©"
                )
            clear_btn = gr.Button("æ¸…é™¤è®°å½•", variant="secondary")
            analyze_btn = gr.Button("å¼€å§‹åˆ†æ", variant="primary")

    # ===== æ¨èå†å² Tab =====
    with gr.Tab("ğŸ“Š æ¨èå†å²"):
        tracking_html = gr.HTML(value=get_tracking_html())
        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ¨èå†å²", variant="primary")
        refresh_btn.click(fn=get_tracking_html, outputs=tracking_html)

        with gr.Row():
            delete_code = gr.Textbox(label="è¾“å…¥è¦åˆ é™¤çš„è‚¡ç¥¨ä»£ç ", placeholder="ä¾‹å¦‚: 000001 æˆ– 000001.SZ", scale=4)
            delete_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤", variant="stop", scale=1)

        with gr.Row():
            clear_all_btn = gr.Button("ğŸ’£ æ¸…ç©ºæ‰€æœ‰è®°å½•", variant="stop")

        confirm_clear = gr.Checkbox(label="ç¡®è®¤æ¸…ç©ºæ‰€æœ‰è®°å½•", visible=False)
        status_msg = gr.Textbox(visible=False)
        delete_msg = gr.Textbox(visible=False)

        delete_btn.click(
            fn=lambda code: tracker.remove_stock(code),
            inputs=delete_code,
            outputs=delete_msg
        ).then(fn=lambda: "", outputs=delete_code).then(fn=get_tracking_html, outputs=tracking_html)

        def toggle_confirm_clear():
            return {"visible": True}, "è¯·å‹¾é€‰ç¡®è®¤æ¡†åå†æ¬¡ç‚¹å‡»æ¸…ç©ºæŒ‰é’®"

        clear_all_btn.click(fn=toggle_confirm_clear, outputs=[confirm_clear, status_msg])

        def handle_clear_confirmation(confirmed):
            if confirmed:
                tracker.clear_all_recommendations(confirmation=True)
                return {"visible": False}, "âœ… å·²æ¸…ç©ºæ‰€æœ‰è®°å½•", get_tracking_html()
            else:
                return {"visible": False}, "âŒ æ¸…ç©ºæ“ä½œå·²å–æ¶ˆ", get_tracking_html()

        confirm_clear.change(
            fn=handle_clear_confirmation,
            inputs=confirm_clear,
            outputs=[confirm_clear, status_msg, tracking_html]
        )

    # ===== ä¸ªè‚¡æŸ¥è¯¢ Tab =====
    with gr.Tab("ğŸ” ä¸ªè‚¡æŸ¥è¯¢"):
        stock_query = gr.Textbox(label="è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000006æˆ–000006.SZï¼‰")
        query_btn = gr.Button("æŸ¥è¯¢")
        stock_output = gr.Textbox(label="æŸ¥è¯¢ç»“æœ", interactive=False)
        query_btn.click(fn=query_stock, inputs=stock_query, outputs=stock_output)

    history = gr.State([])

    # ä¿®æ”¹åˆ†ææŒ‰é’®çš„å¤„ç†å‡½æ•°ï¼Œç›´æ¥è°ƒç”¨æ¨èè‚¡ç¥¨
    def analyze_without_input(market_type, max_stocks, strategy_mode, history):
        return chat_interface("æ¨èè‚¡ç¥¨", market_type, max_stocks, strategy_mode, history)

    # ç»‘å®šäº‹ä»¶å¤„ç†
    analyze_btn.click(
        analyze_without_input, 
        [market_type, max_stocks, strategy_mode, history], 
        [chatbot, history]
    )
    
    clear_btn.click(lambda: ([], []), None, [chatbot, history])



# ===== å¯åŠ¨æœåŠ¡ =====
if __name__ == "__main__":
    demo.launch(server_port=7860, share=False)
    
